# Human-in-the-loop Active Learning to improve goal-oriented molecular optimization
Human-in-the-loop Active Learning framework to enable continuous training and updating of predictive machine learning models used as reward scoring functions in RL-based algorithms for molecular optimization.

Description of the workflow (actually not that small):

1. You have REINVENT that produces many molecules. Those molecules are then passed to a "scoring model". The scoring model or other scoring criteria are defined on the config.json. Basically when you a run a REINVENT experiment, you type python input.py config.json. The input.py will call the REINVENT process and all scoring model information, number of steps etc. are specified in the config.json. In your project, the molecules produced by REINVENT should be scored by a "human". We don't have access to a real human so instead, we will use a model of the human. That model is your Bradley Terry model, and you need to specify one in the config.json.

2. The Bradley Terry model needs to be trained on some data. You used the DRD2 activity data, which contains a number of molecules (SMILES) with their activity labels (1 and 0). A Bradley Terry model, by definition, compares a pair of objects and outputs a value that represents if object 1 is better than object 2. So we need to modify the DRD2 activity data so that each molecule in the dataset is compared to all others, and each pair then gets a label (1 if molecule1 is better than molecule2, 0 otherwise). Then you will have a Bradley model trained to compare 2 molecules. You will use it as "prior knowledge" of the human because then you will make it better during a REINVENT run.


3. Now you are inside REINVENT, thousands of molecules are being produced and passed to your Bradley Terry model. In your Bradley Terry container (the file you already started creating in reinvent_scoring), you have the function predict_from_fingerprints that will score the produced molecules based on the Bradley Terry model. So you have to take that list of produced molecules, and for each molecule in the list, you compare it to all others molecules in the list and output the mean of predicted preferences (for example, molecule 1 is better than molecule 2, better than molecule 3, not better than molecule 4 would give a mean of 1+1+0/3 = 0.66 and that's the score of molecule 1). Then you will have scores for all molecules and that what you give to REINVENT so it can improve itself.


4. After running 100 steps of REINVENT (because you specified n_steps = 100 if I remember correctly), then you will query the human model aka the Bradley Terry model. So from the list of produced molecules by REINVENT, you select n_queries pairs of molecules based on thompson sampling or uncertainty or whatever acquisition you choose, and present them to the human. Note that the acquisition needs to select pairs of 2 objects and not one object, maybe there exist some acquisition functions that deal with pairs and that you can implement directly. Then you should label those molecules, it's better to use the oracle here (the same one you used to generate the comparison labels to train the Bradley model) and that's how you label those molecules. Then you concatenate those new labelled molecules to your existing training set, and retrain the Bradley Terry model.

5. After this "human update", you save the retrained Bradley model, replace it in config.json, also replace the REINVENT model checkpoint (you put the new path to "Agent.ckpt" that is usually saved automatically after a REINVENT run ends) and then you start a new REINVENT run (that's your round 2).

