{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run this code with the kernel reinvent.v3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle\n",
    "import subprocess\n",
    "\n",
    "from utils import fingerprints_from_mol\n",
    "from scripts.write_config_bradley_terry import write_REINVENT_config_bradley_terry\n",
    "from models.RandomForest import RandomForestReg, RandomForestClf\n",
    "from scripts.acquisition import select_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install the custom reinvent scoring package to support the Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# print python version\n",
    "import sys\n",
    "\n",
    "# Print Python version\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: reinvent-scoring\n",
      "Version: 0.0.73\n",
      "Summary: Scoring functions for Reinvent\n",
      "Home-page: https://github.com/MolecularAI/reinvent-scoring.git\n",
      "Author: MolecularAI\n",
      "Author-email: patronov@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install scikit-learn=0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If there already exists reinvent_scoring, we should uninstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: reinvent-scoring 0.0.73\n",
      "Uninstalling reinvent-scoring-0.0.73:\n",
      "  Successfully uninstalled reinvent-scoring-0.0.73\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y reinvent_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we install the custom reinvent scoring package\n",
    "##### The flag -e means that the package is installed in editable mode, so that changes to the code will be immediately available without reinstalling the package. All package info is stored in the setup.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-chemistry\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-chemistry\n",
      "  Attempting uninstall: reinvent-chemistry\n",
      "    Found existing installation: reinvent-chemistry 0.0.51\n",
      "    Uninstalling reinvent-chemistry-0.0.51:\n",
      "      Successfully uninstalled reinvent-chemistry-0.0.51\n",
      "  Running setup.py develop for reinvent-chemistry\n",
      "Successfully installed reinvent-chemistry-0.0.51\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-models\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-models\n",
      "  Attempting uninstall: reinvent-models\n",
      "    Found existing installation: reinvent-models 0.0.15rc1\n",
      "    Uninstalling reinvent-models-0.0.15rc1:\n",
      "      Successfully uninstalled reinvent-models-0.0.15rc1\n",
      "  Running setup.py develop for reinvent-models\n",
      "Successfully installed reinvent-models-0.0.15rc1\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-chemistry\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y scikit-learn=0.21.3\n",
    "! pip list | grep reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install PyTDC\n",
    "# ! pip install chemprop\n",
    "# ! pip install absl-py==1.1.0\n",
    "# ! pip install astor==0.8.1\n",
    "# ! pip install cloudpickle==2.1.0\n",
    "# ! pip install dataclasses==0.6\n",
    "# ! pip install deprecated==1.2.13\n",
    "# ! pip install dm-tree==0.1.7\n",
    "# ! pip install flatbuffers==1.12\n",
    "# ! pip install future==0.18.2\n",
    "# ! pip install gast==0.3.2\n",
    "# ! pip install gpflow==2.3.1\n",
    "# ! pip install grpcio==1.27.2\n",
    "# ! pip install keras==2.7.0\n",
    "# ! pip install keras-applications==1.0.8\n",
    "# ! pip install libclang==14.0.1\n",
    "# ! pip install markdown==3.2.1\n",
    "# ! pip install multipledispatch==0.6.0\n",
    "# ! pip install opt-einsum==3.2.0\n",
    "# ! pip install protobuf==3.11.3\n",
    "# ! pip install reinvent-chemistry==0.0.51\n",
    "# ! pip install reinvent-models==0.0.15rc1\n",
    "# ! pip install tabulate==0.8.9\n",
    "# ! pip install tensorboard==2.9.1\n",
    "# ! pip install tensorboard-data-server==0.6.1\n",
    "# ! pip install tensorflow==2.7.0\n",
    "# ! pip install tensorflow-estimator==2.7.0\n",
    "# ! pip install tensorflow-io-gcs-filesystem==0.26.0\n",
    "# ! pip install tensorflow-probability==0.17.0\n",
    "# ! pip install werkzeug==2.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ECFP_dataset(init_train_set_path, num_train_samples):\n",
    "    \"\"\"\n",
    "        Load background training data used to pre-train the predictive model    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading D0\")\n",
    "    train_set = pd.read_csv(init_train_set_path)\n",
    "    feature_cols = [f\"bit{i}\" for i in range(2048)]\n",
    "    target_col = [\"activity\"]\n",
    "    smiles_train = train_set[\"smiles\"].values.reshape(-1)\n",
    "    x_train = train_set[feature_cols].values\n",
    "    y_train = train_set[target_col].values.reshape(-1)\n",
    "    sample_weight = np.array([1. for i in range(len(x_train))])\n",
    "    print(\"The feature matrix shape: \", x_train.shape)\n",
    "    print(\"The labels shape: \", y_train.shape)\n",
    "\n",
    "    train_sample = train_set[train_set[\"activity\"] == 1].sample(num_train_samples).smiles.tolist()\n",
    "    return x_train, y_train, sample_weight, smiles_train, train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "\n",
    "def run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env,\n",
    "        feedback_type, # score, compare, rank\n",
    "        init_model_path, \n",
    "        init_train_set_path, \n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        num_train_samples, # number of training samples to select from the training set\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        train_similarity, # if True, use the similarity of the training set to select queries\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    "        ):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng = default_rng(seed)\n",
    "\n",
    "    if acquisition:\n",
    "        jobname = \"fine-tune predictive component HITL\"\n",
    "        jobid = f\"{dirname}_rounds_{num_rounds}_iters_{num_iters}_queries_{num_queries}_{acquisition}_noise_{sigma_noise}\"\n",
    "        output_dir = f\"{jobid}_seed_{seed}\"\n",
    "    else:\n",
    "        jobname = \"fine-tune predictive component no HITL\"\n",
    "        jobid = f\"{dirname}_rounds_{num_rounds}_None\"\n",
    "        output_dir = f\"{jobid}_seed_{seed}\"\n",
    "    \n",
    "    # initial configuration\n",
    "    conf_filename = \"config.json\"\n",
    "\n",
    "    # create root output dir\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "    print(f\"Creating output directory: {output_dir}.\")\n",
    "    if feedback_type == \"scoring\":\n",
    "        raise NotImplementedError(\"Score feedback not implemented yet.\")\n",
    "    elif feedback_type == \"comparing\":\n",
    "        configuration_JSON_path = write_REINVENT_config_bradley_terry(reinvent_dir, reinvent_env, output_dir, conf_filename, jobid, jobname)\n",
    "    elif feedback_type == \"ranking\":\n",
    "        raise NotImplementedError(\"Rank feedback not implemented yet.\")\n",
    "    \n",
    "    print(f\"Creating config file: {configuration_JSON_path}.\")\n",
    "\n",
    "    configuration = json.load(open(os.path.join(output_dir, conf_filename)))\n",
    "\n",
    "    # write specified number of RL optimization steps in configuration\n",
    "    # (example: if num_rounds = 5 (rounds) and Reinvent REINVENT_n_steps = 100, we will do 5*100 RL optimization steps)\n",
    "    configuration[\"parameters\"][\"reinforcement_learning\"][\"n_steps\"] = REINVENT_n_steps\n",
    "\n",
    "    # write initial model path in configuration\n",
    "    configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "    \n",
    "    for i in range(len(configuration_scoring_function)):\n",
    "        configuration_scoring_function[i][\"specific_parameters\"][\"model_path\"] = init_model_path\n",
    "        if feedback_type == \"scoring\":\n",
    "            raise NotImplementedError(\"Score feedback not implemented yet.\")\n",
    "        elif feedback_type == \"comparing\":\n",
    "            configuration_scoring_function[i][\"specific_parameters\"][\"bradley_terry\"] = \"classification\"\n",
    "            predictive_model_name = \"bradley_terry_model\"\n",
    "        elif feedback_type == \"ranking\":\n",
    "            raise NotImplementedError(\"Rank feedback not implemented yet.\")\n",
    "        \n",
    "    # write the updated configuration file to the disc\n",
    "    configuration_JSON_path = f\"{os.getcwd()}/{output_dir}/{conf_filename}\"\n",
    "    print(\"The configuration file path: \", configuration_JSON_path)\n",
    "\n",
    "    with open(configuration_JSON_path, 'w') as f:\n",
    "        json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "    \n",
    "    # initialize the active learning with the same pool of generated compounds resulting from a standard Reinvent run\n",
    "    initial_dir = f\"{dirname}_rounds_{num_rounds}_None_seed_{seed}\"\n",
    "    \n",
    "    if os.path.exists(initial_dir): # if you already have a standard Reinvent run\n",
    "        # copy the file containing the initial unlabelled pool in your current directory\n",
    "        os.makedirs(os.path.join(output_dir, \"iteration_0\"))\n",
    "        try:\n",
    "            initial_unlabelled_pool = os.path.join(initial_dir, \"results/scaffold_memory.csv\")\n",
    "            shutil.copy(initial_unlabelled_pool, os.path.join(output_dir, \"iteration_0\"))\n",
    "        # if this file does not exist, skip this step\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "    else: # if you do not have a standard Reinvent run, skip this step\n",
    "        pass\n",
    "    \n",
    "    # multi-parameter optimization (MPO) loop\n",
    "    print(f\"Running MPO experiment with rounds {num_rounds}, iters {num_iters}, queries {num_queries}, seed {seed}. \\n Results will be saved at {output_dir}\")\n",
    "\n",
    "    # Initialize human feedback model\n",
    "\n",
    "    print(f\"Loading {feedback_type} feedback model.\")\n",
    "\n",
    "    if feedback_type == \"scoring\":\n",
    "        raise NotImplementedError(\"Score feedback not implemented yet.\")\n",
    "    elif feedback_type == \"comparing\":\n",
    "        from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "        # pickle that torch model of bradley_terry_model.pth\n",
    "        feedback_model = BradleyTerryModel(feature_dim=2048)\n",
    "        feedback_model.load_state_dict(torch.load(\"training_Bradley_Terry_model/bradley_terry_model.pth\"))\n",
    "        print(\"Loading Bradley Terry model successfully\")\n",
    "    elif feedback_type == \"ranking\":\n",
    "        raise NotImplementedError(\"Rank feedback not implemented yet.\")\n",
    "    \n",
    "    # store expert scores\n",
    "    expert_score = []\n",
    "\n",
    "    READ_ONLY = False # if folder exists, do not overwrite results there\n",
    "\n",
    "    for REINVENT_round in np.arange(1, num_rounds + 1):\n",
    "        print(\"=====================================\")\n",
    "        print(f\"REINVENT round = {REINVENT_round}\")\n",
    "\n",
    "        if REINVENT_round == 1:\n",
    "            if os.path.exists(f\"{output_dir}/iteration_0/scaffold_memory.csv\"):\n",
    "                # start from your pre-existing pool of unlabelled compounds\n",
    "                with open(f\"{output_dir}/iteration_0/scaffold_memory.csv\", 'r') as file:\n",
    "                    data = pd.read_csv(file)\n",
    "                data = data[data[\"Step\"] < 100]\n",
    "                data.reset_index(inplace=True)\n",
    "            else:\n",
    "                # generate a pool of unlabelled compounds with REINVENT\n",
    "                # print(\"Run REINVENT\")\n",
    "                # exit_code = os.system(f\"{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path} &> {output_dir} /run.err\")\n",
    "                # print(\"The exit code: \", exit_code)\n",
    "                \n",
    "                command = f\"{reinvent_env}/bin/python\"\n",
    "                script = f\"{reinvent_dir}/input.py\"\n",
    "                config_path = configuration_JSON_path\n",
    "                stderr_file = f\"{output_dir}/run.err\"\n",
    "                stdout_file = f\"{output_dir}/run.out\"\n",
    "\n",
    "                # Construct the full command to run\n",
    "                cmd = [command, script, config_path]\n",
    "\n",
    "                # Open the file to which you want to redirect stderr and stdout\n",
    "                \n",
    "                with open(stderr_file, 'w') as ferr, open(stdout_file, 'w') as fout:\n",
    "                    # Execute the command\n",
    "                    result = subprocess.run(cmd, text=True, stdout=fout, stderr=ferr)\n",
    "\n",
    "                # Check the result\n",
    "                print(\"Exit code:\", result.returncode)\n",
    "\n",
    "                with open(f\"{output_dir}/results/scaffold_memory.csv\", 'r') as file:\n",
    "                    data = pd.read_csv(file)\n",
    "\n",
    "        N = len(data)\n",
    "        colnames = list(data) \n",
    "        smiles = data['SMILES']\n",
    "        bioactivity_score = data['bioactivity'] # the same as raw_bioactivity since no transformation applied\n",
    "        raw_bioactivity_score = data['raw_bioactivity']\n",
    "        high_scoring_threshold = threshold\n",
    "        # save the indexes of high scoring molecules for bioactivity\n",
    "        high_scoring_idx = bioactivity_score > high_scoring_threshold\n",
    "\n",
    "        # Scoring component values\n",
    "        scoring_component_names = [s.split(\"raw_\")[1] for s in colnames if \"raw_\" in s]\n",
    "        print(f\"scoring components: {scoring_component_names}\")\n",
    "        x = np.array(data[scoring_component_names])\n",
    "        print(f'Scoring component matrix dimensions: {x.shape}')\n",
    "        x = x[high_scoring_idx,:]\n",
    "\n",
    "        # Only analyse highest scoring molecules\n",
    "        smiles = smiles[high_scoring_idx]\n",
    "        bioactivity_score = bioactivity_score[high_scoring_idx]\n",
    "        raw_bioactivity_score = raw_bioactivity_score[high_scoring_idx]\n",
    "        print(f'{len(smiles)} high-scoring (> {high_scoring_threshold}) molecules')\n",
    "\n",
    "        if len(smiles) == 0:\n",
    "            smiles = data['SMILES']\n",
    "            print(f'{len(smiles)} molecules')\n",
    "\n",
    "               \n",
    "        # store molecule indexes selected for feedback\n",
    "        selected_feedback = np.empty(0).astype(int)\n",
    "        human_sample_weight = np.empty(0).astype(float)\n",
    "        # store number of accepted queries (y = 1) at each iteration\n",
    "        n_accept = []\n",
    "\n",
    "        ########################### HITL rounds ######################################\n",
    "        \n",
    "        for iteration in np.arange(num_iters): # T number of HITL iterations\n",
    "            print(\"=====================================\")\n",
    "            print(f\"Round = {REINVENT_round}, Iteration = {iteration}\")\n",
    "            \n",
    "            # classify \n",
    "            model = RandomForestClf(fitted_model)\n",
    "            \n",
    "            if len(smiles) > num_queries:\n",
    "                new_query = select_query(data, num_queries, list(smiles), model, selected_feedback, acquisition, rng) # select n smiles with Active Learning\n",
    "            else:\n",
    "                new_query = select_query(data, len(smiles), list(smiles), model, selected_feedback, acquisition, rng)\n",
    "            \n",
    "            # Initialize the expert values vector\n",
    "            s_bioactivity = [] # for scores (between 0 and 1)\n",
    "            v_bioactivity = [] # for continuous feedback (regression)\n",
    "            \n",
    "            # Get expert feedback on selected queries\n",
    "            print(new_query)\n",
    "            for i in new_query:\n",
    "                cur_mol = data.iloc[i][\"SMILES\"]\n",
    "                print(cur_mol)\n",
    "                value = feedback_model.human_score(cur_mol, sigma_noise)\n",
    "                s_bioactivity.append(value)\n",
    "            \n",
    "            # Get raw scores and transformed score (if any) from the high scoring molecules in U\n",
    "            raw_scoring_component_names = [\"raw_\"+name for name in scoring_component_names] \n",
    "            x_raw = data[raw_scoring_component_names].to_numpy()\n",
    "            x =  data[scoring_component_names].to_numpy()\n",
    "\n",
    "            # get (binary) simulated chemist's responses\n",
    "            \n",
    "            new_y = np.array([1 if s > 0.5 else 0 for s in s_bioactivity])\n",
    "            accepted = new_y.tolist()\n",
    "            \n",
    "            expert_score += [accepted]\n",
    "            n_accept += [sum(accepted)]\n",
    "\n",
    "            print(f\"Feedback idx at iteration {REINVENT_round}, {iteration}: {new_query}\")\n",
    "            print(f\"Number of accepted molecules at iteration {REINVENT_round}, {iteration}: {n_accept[iteration]}\")   \n",
    "            \n",
    "            # append feedback\n",
    "            if len(new_y) > 0:\n",
    "                selected_feedback = np.hstack((selected_feedback, new_query))\n",
    "\n",
    "            mask = np.ones(N, dtype=bool)\n",
    "            mask[selected_feedback] = False\n",
    "\n",
    "            # use the augmented training data to retrain the model\n",
    "            new_smiles = data.iloc[new_query].SMILES.tolist()\n",
    "            new_mols = [Chem.MolFromSmiles(s) for s in new_smiles]\n",
    "            new_x = fingerprints_from_mol(new_mols, type = \"counts\")\n",
    "            new_human_sample_weight = np.array([s if s > 0.5 else 1-s for s in s_bioactivity])\n",
    "            sample_weight = np.concatenate([sample_weight, new_human_sample_weight])\n",
    "            print(len(new_x), len(new_y))\n",
    "            x_train = np.concatenate([x_train, new_x])\n",
    "            y_train = np.concatenate([y_train, new_y])\n",
    "            smiles_train = np.concatenate([smiles_train, new_smiles])\n",
    "            print(f\"Augmented train set size at iteration {REINVENT_round}: {x_train.shape[0]} {y_train.shape[0]}\")\n",
    "            # save augmented training data\n",
    "            D_r = pd.DataFrame(np.concatenate([smiles_train.reshape(-1,1), x_train, y_train.reshape(-1,1)], 1))\n",
    "            D_r.columns = [\"SMILES\"] + [f\"bit{i}\" for i in range(x_train.shape[1])] + [\"target\"]\n",
    "            D_r.to_csv(os.path.join(output_dir, f\"augmented_train_set_iter{REINVENT_round}.csv\"))\n",
    "\n",
    "            # re-fit and save the model using the augmented train set and save to new directory\n",
    "            model_new_savefile = output_dir + '/{}_iteration_{}.pkl'.format(predictive_model_name, REINVENT_round)\n",
    "            model._retrain(x_train, y_train, sample_weight = sample_weight, save_to_path = model_new_savefile)\n",
    "            fitted_model = pickle.load(open(model_new_savefile, 'rb'))\n",
    "\n",
    "            # get current configuration\n",
    "            configuration = json.load(open(os.path.join(output_dir, conf_filename)))\n",
    "            conf_filename = \"iteration{}_config.json\".format(REINVENT_round)    \n",
    "\n",
    "            # modify model path in configuration\n",
    "            configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "            for i in range(len(configuration_scoring_function)):\n",
    "                if configuration_scoring_function[i][\"component_type\"] == \"predictive_property\":\n",
    "                    configuration_scoring_function[i][\"specific_parameters\"][\"model_path\"] = model_new_savefile\n",
    "\n",
    "            # Keep agent checkpoint\n",
    "            if REINVENT_round == 1:\n",
    "                configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(initial_dir, \"results/Agent.ckpt\")\n",
    "            else:\n",
    "                configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(output_dir, \"results/Agent.ckpt\")\n",
    "\n",
    "        root_output_dir = os.path.expanduser(\"{}_seed{}\".format(jobid, seed))\n",
    "\n",
    "        # Define new directory for the next round\n",
    "        output_dir = os.path.join(root_output_dir, \"iteration{}_{}\".format(REINVENT_round, acquisition))\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        print(output_dir)\n",
    "\n",
    "        # modify log and result paths in configuration\n",
    "        configuration[\"logging\"][\"logging_path\"] = os.path.join(output_dir, \"progress.log\")\n",
    "        configuration[\"logging\"][\"result_folder\"] = os.path.join(output_dir, \"results\")\n",
    "\n",
    "        # write the updated configuration file to the disc\n",
    "        configuration_JSON_path = os.path.join(output_dir, conf_filename)\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "\n",
    "    r = np.arange(len(expert_score))\n",
    "    m_score = [np.mean(expert_score[i]) for i in r]\n",
    "    print(\"Mean expert score : \", m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/springnuance/reinvent-hitl/Base-Code-Binh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output directory: outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42.\n",
      "Creating config file: outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42/config.json.\n",
      "The configuration file path:  /home/springnuance/reinvent-hitl/Base-Code-Binh/outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42/config.json\n",
      "Running MPO experiment with rounds 2, iters 10, queries 10, seed 42. \n",
      " Results will be saved at outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42\n",
      "Loading comparing feedback model.\n",
      "Loading Bradley Terry model successfully\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Exit code: 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42/results/scaffold_memory.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-5b95e7df4e64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0macquisition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msigma_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# noise level for simulated chemist's responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mthreshold\u001b[0m \u001b[0;31m# threshold for high scoring molecules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-25-ac02eba9f49b>\u001b[0m in \u001b[0;36mrun_HITL_classify\u001b[0;34m(seed, dirname, reinvent_dir, reinvent_env, feedback_type, init_model_path, init_train_set_path, num_rounds, num_iters, num_queries, num_train_samples, REINVENT_n_steps, train_similarity, acquisition, sigma_noise, threshold)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exit code:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{output_dir}/results/scaffold_memory.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'outputs_rounds_2_iters_10_queries_10_thompson_noise_0.0_seed_42/results/scaffold_memory.csv'"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "dirname = \"outputs\"\n",
    "\n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "#reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/cc_env_hitl\") # We must use absolute path\n",
    "#reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/reinvent.v3.2\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "\n",
    "\n",
    "# the performance should not be good, around random accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"comparing\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as scoring:\n",
    "# Given a molecule, what is the probability that the molecule is active regarding DRD2?  \n",
    "# init_model_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Random_Forest_model/random_forest_model.pkl\"\n",
    "\n",
    "# feedback type as comparing:\n",
    "# Given two molecules, what is the probability that the first molecule is more active than the second molecule regarding DRD2?\n",
    "init_model_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/bradley_terry_model.pth\"\n",
    "init_train_set_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_rank_data.csv\" \n",
    "\n",
    "\n",
    "# feedback type as ranking:\n",
    "# Given N molecules, what are the orders of preference of these molecules regarding DRD2?\n",
    "# init_model_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_List_Net_model/list_net_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds\n",
    "REINVENT_n_steps = 100 # number of REINVENT optimization steps\n",
    "train_similarity = False # if True, use the similarity of the training set to select queries\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "num_iters = 10 # number of molecules shown at each iteration to the human for feedback\n",
    "num_queries = 10 # number of molecules shown to the simulated chemist at each iteration (10 pairs)\n",
    "num_train_samples = 30 # number of training samples to select from the training set, ignore if train_similarity is False\n",
    "threshold = 0.5 # threshold for high scoring molecules\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env,\n",
    "        feedback_type, # score, compare, rank\n",
    "        init_model_path, \n",
    "        init_train_set_path, \n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        num_train_samples, # number of training samples to select from the training set\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        train_similarity, # if True, use the similarity of the training set to select queries\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc_env_hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
