{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run this code with the kernel reinvent.v3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle\n",
    "import subprocess\n",
    "\n",
    "from utils import fingerprints_from_mol\n",
    "\n",
    "from scripts.acquisition import select_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install the custom reinvent scoring package to support the Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# print python version\n",
    "import sys\n",
    "\n",
    "# Print Python version\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: reinvent-scoring\n",
      "Version: 0.0.73\n",
      "Summary: Scoring functions for Reinvent\n",
      "Home-page: https://github.com/MolecularAI/reinvent-scoring.git\n",
      "Author: MolecularAI\n",
      "Author-email: patronov@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install scikit-learn=0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If there already exists reinvent_scoring, we should uninstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: reinvent-scoring 0.0.73\n",
      "Uninstalling reinvent-scoring-0.0.73:\n",
      "  Successfully uninstalled reinvent-scoring-0.0.73\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y reinvent_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we install the custom reinvent scoring package\n",
    "##### The flag -e means that the package is installed in editable mode, so that changes to the code will be immediately available without reinstalling the package. All package info is stored in the setup.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-chemistry\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-chemistry\n",
      "  Attempting uninstall: reinvent-chemistry\n",
      "    Found existing installation: reinvent-chemistry 0.0.51\n",
      "    Uninstalling reinvent-chemistry-0.0.51:\n",
      "      Successfully uninstalled reinvent-chemistry-0.0.51\n",
      "  Running setup.py develop for reinvent-chemistry\n",
      "Successfully installed reinvent-chemistry-0.0.51\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-models\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-models\n",
      "  Attempting uninstall: reinvent-models\n",
      "    Found existing installation: reinvent-models 0.0.15rc1\n",
      "    Uninstalling reinvent-models-0.0.15rc1:\n",
      "      Successfully uninstalled reinvent-models-0.0.15rc1\n",
      "  Running setup.py develop for reinvent-models\n",
      "Successfully installed reinvent-models-0.0.15rc1\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-chemistry\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y scikit-learn=0.21.3\n",
    "! pip list | grep reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "from training_Rank_ListNet_model.rank_listnet import RankListNetModel\n",
    "from training_Score_Regression_model.score_regression import ScoreRegressionModel\n",
    "from helper import load_drd2_dataset, write_REINVENT_config, change_config_json, \\\n",
    "                    read_scaffold_result, load_feedback_model, smiles_human_score, \\\n",
    "                    compute_fingerprints, retrain_feedback_model,\\\n",
    "                    create_drd2_dataset, combine_drd2_dataset, save_drd2_dataset\n",
    "                        \n",
    "from scripts.acquisition import select_query_feedback\n",
    "\n",
    "def check_create(path):\n",
    "    \"\"\"\n",
    "    Check if the directory exists, if not, create it.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir, \n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps. This is not related to the HITL but on the REINVENT side\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    "        ):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    ################################################\n",
    "    # DEFINING REINVENT JOBNAME, JOBID, OUTPUT_DIR #\n",
    "    ################################################\n",
    "\n",
    "    jobname = \"fine-tune predictive component HITL\"\n",
    "    jobid = f\"rounds_{num_rounds}_iters_{num_iters}_queries_{num_queries}_{acquisition}_noise_{sigma_noise}\"\n",
    "    conf_filename = \"config.json\"\n",
    "\n",
    "    # create root output dir\n",
    "    check_create(output_dir)\n",
    "\n",
    "    # create HITL round folders to store results\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "        check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}\")\n",
    "        for HITL_iteration in range(1, num_iters + 1):\n",
    "            check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration}\")\n",
    "    \n",
    "    # Copy the pretrained model to the first REINVENT round/ HITL_iteration_1\n",
    "    shutil.copy2(f\"{model_pretrained_path}\", f\"{output_dir}/REINVENT_round_1/HITL_iteration_1\")\n",
    "\n",
    "    # multi-parameter optimization (MPO) loop\n",
    "    print(f\"Running DRD2 (one objective) with rounds {num_rounds}, iters {num_iters}, queries {num_queries}, seed {seed}\")\n",
    "    print(f\"Results will be saved at {output_dir}\")\n",
    "    \n",
    "    base_training_dataset_outputs = load_drd2_dataset(feedback_type=feedback_type, \n",
    "                                                 data_path=base_training_dataset_path)\n",
    "    base_testing_dataset_outputs = load_drd2_dataset(feedback_type=feedback_type,\n",
    "                                                data_path=base_testing_dataset_path)\n",
    "    \n",
    "    print(\"Loading initial training and testing datasets successfully\")\n",
    "\n",
    "    # ########################### REINVENT rounds ######################################\n",
    "\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"REINVENT round = {REINVENT_round}\")\n",
    "\n",
    "        REINVENT_round_output_dir = f\"{output_dir}/REINVENT_round_{REINVENT_round}\"\n",
    "        \n",
    "        configuration_JSON_path = write_REINVENT_config(feedback_type, reinvent_dir, jobid, jobname, \n",
    "                                                        REINVENT_round_output_dir, conf_filename)\n",
    "\n",
    "        print(f\"Creating config file: {configuration_JSON_path}.\")\n",
    "\n",
    "        configuration = json.load(open(f\"{configuration_JSON_path}\"))\n",
    "\n",
    "        current_model_path = f\"{REINVENT_round_output_dir}/HITL_iteration_1/{model_pretrained_name}\"\n",
    "\n",
    "        configuration = change_config_json(configuration, REINVENT_n_steps, batch_size, current_model_path)\n",
    "\n",
    "        # write the updated configuration file \n",
    "\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "    \n",
    "        print(\"Run REINVENT\")                \n",
    "        command = f\"{reinvent_env}/bin/python\"\n",
    "        script = f\"{reinvent_dir}/input.py\"\n",
    "        stderr_file = f\"{REINVENT_round_output_dir}/run.err\"\n",
    "        stdout_file = f\"{REINVENT_round_output_dir}/run.out\"\n",
    "\n",
    "        # Construct the full command to run\n",
    "        cmd = [command, script, configuration_JSON_path]\n",
    "        # Open the file to which you want to redirect stderr and stdout\n",
    "        with open(stderr_file, 'w') as ferr, open(stdout_file, 'w') as fout:\n",
    "            # Execute the command\n",
    "            result = subprocess.run(cmd, text=True, stdout=fout, stderr=ferr)\n",
    "        # Check the result\n",
    "        print(\"Exit code:\", result.returncode)\n",
    "        \n",
    "        #############################################################################\n",
    "        # REINVENT HAS OUTPUT THE RESULT in path f\"{REINVENT_round_output_dir}/results\" #\n",
    "        #############################################################################\n",
    "        \n",
    "        # Get the high scoring molecules\n",
    "        output_high_score = read_scaffold_result(f\"{REINVENT_round_output_dir}/results/scaffold_memory.csv\", \n",
    "                                                 choose_top_smiles=choose_top_smiles)\n",
    "        \n",
    "        scaffold_df = output_high_score[\"scaffold_df\"]\n",
    "        smiles = output_high_score[\"smiles\"]\n",
    "        \n",
    "        # store molecule indexes selected for feedback\n",
    "        selected_feedback = np.empty(0).astype(int)\n",
    "\n",
    "        ########################### HITL_iteration in each REINVENT round #####################\n",
    "        \n",
    "        for HITL_iteration in range(1, num_iters + 1): # T number of HITL_iterations\n",
    "\n",
    "            print(\"=====================================\")\n",
    "            print(f\"HITL iteration = {HITL_iteration}\")\n",
    "            \n",
    "            # Initialize human feedback model\n",
    "            print(f\"Loading {feedback_type} feedback model.\")\n",
    "\n",
    "            # Loading feedback model\n",
    "            feedback_model_path = f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/{model_pretrained_name}\"\n",
    "            feedback_model = load_feedback_model(feedback_type, feedback_model_path)\n",
    "            \n",
    "            ######################################################## \n",
    "            # Select queries number of smiles with Active Learning #\n",
    "            ########################################################\n",
    "\n",
    "            if len(smiles) > num_queries:\n",
    "                new_queried_smiles_indices = select_query_feedback(feedback_type, feedback_model, \n",
    "                                                  scaffold_df, num_queries, list(smiles), \n",
    "                                                  selected_feedback, acquisition, rng) \n",
    "            else:\n",
    "                new_queried_smiles_indices = select_query_feedback(feedback_type, feedback_model, \n",
    "                                                  scaffold_df, len(smiles), list(smiles), \n",
    "                                                  selected_feedback, acquisition, rng)\n",
    "            \n",
    "            print(f\"Feedback idx at HITL iteration {HITL_iteration}: {new_queried_smiles_indices}\")\n",
    "            \n",
    "            new_queried_smiles = [smiles[i] for i in new_queried_smiles_indices]\n",
    "  \n",
    "            selected_feedback = np.hstack((selected_feedback, new_queried_smiles_indices))\n",
    "\n",
    "            new_queried_smiles_human_score = smiles_human_score(new_queried_smiles, sigma_noise)\n",
    "            \n",
    "            print(f\"Human score at HITL iteration {HITL_iteration}: {new_queried_smiles_human_score}\")\n",
    "            \n",
    "            # use the augmented training data to retrain the model\n",
    "            new_queried_fps = [compute_fingerprints(smiles) for smiles in new_queried_smiles]\n",
    "\n",
    "            iteration_training_dataset_outputs = create_drd2_dataset(feedback_type, \n",
    "                                                                      new_queried_smiles, \n",
    "                                                                      new_queried_smiles_human_score,\n",
    "                                                                      new_queried_fps)\n",
    "            \n",
    "            print(f\"New queried dataset size: {len(iteration_training_dataset_outputs['smiles'])}\")\n",
    "\n",
    "            # combining the base training dataset with the new queried dataset\n",
    "            base_training_dataset_outputs = combine_drd2_dataset(feedback_type, base_training_dataset_outputs, \n",
    "                                                                   iteration_training_dataset_outputs)\n",
    "            \n",
    "            print(f\"Combined dataset size: {len(base_training_dataset_outputs['smiles'])}\")\n",
    "\n",
    "            # save augmented training data\n",
    "            save_drd2_dataset(feedback_type, iteration_training_dataset_outputs, f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_queried_data.csv\")\n",
    "            save_drd2_dataset(feedback_type, base_training_dataset_outputs, f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_combined_data.csv\")\n",
    "            \n",
    "            print(f\"Saved augmented training data at {REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_combined_data.csv\")\n",
    "            # Retraining the feedback model using the augmented train set\n",
    "            retrained_feedback_model = retrain_feedback_model(feedback_type, feedback_model, base_training_dataset_outputs)\n",
    "            \n",
    "            # At the last round and last iteration, we no longer need to copy the model to the next round\n",
    "            if REINVENT_round != num_rounds and HITL_iteration != num_iters:\n",
    "                if HITL_iteration < num_iters:\n",
    "                    # Moving on to the next iteration at the current round\n",
    "                    feedback_model_saving_path = f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration + 1}/{model_pretrained_name}\"\n",
    "                else:\n",
    "                    # Moving to the first iteration at the next round\n",
    "                    feedback_model_saving_path = f\"{output_dir}/REINVENT_round_{REINVENT_round + 1}/HITL_iteration_1/{model_pretrained_name}\"\n",
    "                \n",
    "                # save the torch model\n",
    "                torch.save(retrained_feedback_model.state_dict(), feedback_model_saving_path)\n",
    "\n",
    "    #         # get current configuration\n",
    "    #         configuration = json.load(open(os.path.join(output_dir, conf_filename)))\n",
    "    #         conf_filename = \"HITL_iteration{}_config.json\".format(REINVENT_round)    \n",
    "\n",
    "    #         # modify model path in configuration\n",
    "    #         configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "    #         for i in range(len(configuration_scoring_function)):\n",
    "    #             if configuration_scoring_function[i][\"component_type\"] == \"predictive_property\":\n",
    "    #                 configuration_scoring_function[i][\"specific_parameters\"][\"model_path\"] = model_new_savefile\n",
    "\n",
    "    #         # Keep agent checkpoint\n",
    "    #         if REINVENT_round == 1:\n",
    "    #             configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(initial_dir, \"results/Agent.ckpt\")\n",
    "    #         else:\n",
    "    #             configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(output_dir, \"results/Agent.ckpt\")\n",
    "\n",
    "    #     root_output_dir = os.path.expanduser(\"{}_seed{}\".format(jobid, seed))\n",
    "\n",
    "    #     # Define new directory for the next round\n",
    "    #     output_dir = os.path.join(root_output_dir, \"HITL_iteration{}_{}\".format(REINVENT_round, acquisition))\n",
    "    #     if not os.path.exists(output_dir):\n",
    "    #         os.makedirs(output_dir)\n",
    "    #     print(output_dir)\n",
    "\n",
    "    #     # modify log and result paths in configuration\n",
    "    #     configuration[\"logging\"][\"logging_path\"] = os.path.join(output_dir, \"progress.log\")\n",
    "    #     configuration[\"logging\"][\"result_folder\"] = os.path.join(output_dir, \"results\")\n",
    "\n",
    "    #     # write the updated configuration file to the disc\n",
    "    #     configuration_JSON_path = os.path.join(output_dir, conf_filename)\n",
    "    #     with open(configuration_JSON_path, 'w') as f:\n",
    "    #         json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "\n",
    "    # r = np.arange(len(expert_score))\n",
    "    # m_score = [np.mean(expert_score[i]) for i in r]\n",
    "    # print(\"Mean expert score : \", m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/springnuance/reinvent-hitl/Base-Code-Binh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running score regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Running DRD2 (one objective) with rounds 2, iters 3, queries 10, seed 42\n",
      "Results will be saved at score_regression_R2_T3_Q10_random_0.1\n",
      "Loading initial training and testing datasets successfully\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: score_regression_R2_T3_Q10_random_0.1/REINVENT_round_1/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  79\n",
      "=====================================\n",
      "HITL iteration = 1\n",
      "Loading scoring feedback model.\n",
      "Loading Score Regression model successfully\n",
      "Feedback idx at HITL iteration 1: [ 4 32  3 28 19 44 33 49  9 39]\n",
      "Human score at HITL iteration 1: [0.36197765639556934, 0.018668260291653804, 0.15745703517860277, 0.17864798033269413, 0.23860682283868223, 0.0, 0.18676499739872188, 0.07684694028250622, 0.05398697840056103, 0.05698414426946282]\n",
      "New queried dataset size: 10\n",
      "Combined dataset size: 34\n",
      "Saved augmented training data at score_regression_R2_T3_Q10_random_0.1/REINVENT_round_1/HITL_iteration_1/iteration_combined_data.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-78d9905a7402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0macquisition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0msigma_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# noise level for simulated chemist's responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mchoose_top_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of top scoring molecules to choose for feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-75-a296936eea26>\u001b[0m in \u001b[0;36mrun_HITL_classify\u001b[0;34m(seed, reinvent_dir, reinvent_env, output_dir, feedback_type, base_training_dataset_path, base_testing_dataset_path, model_pretrained_path, model_pretrained_name, num_rounds, num_iters, num_queries, REINVENT_n_steps, batch_size, acquisition, sigma_noise, choose_top_smiles)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved augmented training data at {REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_combined_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;31m# Retraining the feedback model using the augmented train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mretrained_feedback_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrain_feedback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeedback_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_training_dataset_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;31m# At the last round and last iteration, we no longer need to copy the model to the next round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reinvent-hitl/Base-Code-Binh/helper.py\u001b[0m in \u001b[0;36mretrain_feedback_model\u001b[0;34m(feedback_type, feedback_model, training_outputs, epochs)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_proba\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/score_regression.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Compute strength scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Features is Morgan Fingerprints of smiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# theta is the predicted strength of smiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = \"/home/springnuance/reinvent-hitl/Reinvent\" # We must use absolute path\n",
    "reinvent_env = \"/home/springnuance/miniconda3/envs/ReinventCommunity\" # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"scoring\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as scoring:\n",
    "# Given a molecule, what is the probability that the molecule is active regarding DRD2?  \n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/score_regression_model.pth\"\n",
    "model_pretrained_name = \"score_regression_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "batch_size = 80 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"random\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.1 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "\n",
    "choose_top_smiles = 50 # number of top molecules to choose from scaffold. \n",
    "\n",
    "output_dir = f\"score_regression_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_{sigma_noise}\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Bradley Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Running DRD2 (one objective) with rounds 2, iters 3, queries 10, seed 42. \n",
      " Results will be saved at output_feedback_comparing\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: output_feedback_comparing/REINVENT_round_1/config.json.\n",
      "Run REINVENT\n",
      "Exit code: 0\n",
      "Loading comparing feedback model.\n",
      "Loading Bradley Terry model successfully\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = \"/home/springnuance/reinvent-hitl/Reinvent\" # We must use absolute path\n",
    "reinvent_env = \"/home/springnuance/miniconda3/envs/ReinventCommunity\" # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"comparing\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as comparing:\n",
    "# Given two molecules, what is the probability that the first molecule is more active than the second molecule regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/bradley_terry_model.pth\"\n",
    "model_pretrained_name = \"bradley_terry_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "batch_size = 32 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.1 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "choose_top_smiles = 50 # number of top molecules to choose from scaffold. \n",
    "\n",
    "output_dir = f\"bradley_terry_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_{sigma_noise}\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir, \n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rank ListNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Running DRD2 (one objective) with rounds 2, iters 3, queries 10, seed 42. \n",
      " Results will be saved at output_feedback_ranking\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: output_feedback_ranking/REINVENT_round_1/config.json.\n",
      "Run REINVENT\n",
      "Exit code: 0\n",
      "Loading ranking feedback model.\n",
      "Loading Rank ListNet model successfully\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"ranking\" # scoring, comparing, ranking\n",
    "output_dir = f\"output_feedback_{feedback_type}\"\n",
    "\n",
    "# feedback type as ranking:\n",
    "# Given N molecules, what are the orders of preference of these molecules regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/rank_listnet_model.pth\"\n",
    "model_pretrained_name = \"rank_listnet_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 4 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "\n",
    "# WARNING: CHOOSING LARGER BATCH SIZE WOULD EXPONENTIALLY INCREASE THE NUMBER OF COMBINATIONS\n",
    "# BETTER KEEP IT AT 32 OR 64\n",
    "batch_size = 80 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 5 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "choose_top_smiles = 50 # number of top molecules to choose from scaffold. \n",
    "        \n",
    "assert num_queries * num_iters < choose_top_smiles, \"num_queries * num_iters must be less than choose_top_smiles\"\n",
    "assert choose_top_smiles < batch_size, \"choose_top_smiles must be less than batch_size\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir, \n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top molecules to choose from scaffold\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc_env_hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
