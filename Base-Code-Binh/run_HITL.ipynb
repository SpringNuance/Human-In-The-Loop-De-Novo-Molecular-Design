{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run this code with the kernel reinvent.v3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle\n",
    "import subprocess\n",
    "\n",
    "from utils import fingerprints_from_mol\n",
    "from scripts.write_config_bradley_terry import write_REINVENT_config_bradley_terry\n",
    "from models.RandomForest import RandomForestReg, RandomForestClf\n",
    "from scripts.acquisition import select_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install the custom reinvent scoring package to support the Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# print python version\n",
    "import sys\n",
    "\n",
    "# Print Python version\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: reinvent-scoring\n",
      "Version: 0.0.73\n",
      "Summary: Scoring functions for Reinvent\n",
      "Home-page: https://github.com/MolecularAI/reinvent-scoring.git\n",
      "Author: MolecularAI\n",
      "Author-email: patronov@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install scikit-learn=0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If there already exists reinvent_scoring, we should uninstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: reinvent-scoring 0.0.73\n",
      "Uninstalling reinvent-scoring-0.0.73:\n",
      "  Successfully uninstalled reinvent-scoring-0.0.73\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y reinvent_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we install the custom reinvent scoring package\n",
    "##### The flag -e means that the package is installed in editable mode, so that changes to the code will be immediately available without reinstalling the package. All package info is stored in the setup.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-chemistry\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-chemistry\n",
      "  Attempting uninstall: reinvent-chemistry\n",
      "    Found existing installation: reinvent-chemistry 0.0.51\n",
      "    Uninstalling reinvent-chemistry-0.0.51:\n",
      "      Successfully uninstalled reinvent-chemistry-0.0.51\n",
      "  Running setup.py develop for reinvent-chemistry\n",
      "Successfully installed reinvent-chemistry-0.0.51\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-models\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-models\n",
      "  Attempting uninstall: reinvent-models\n",
      "    Found existing installation: reinvent-models 0.0.15rc1\n",
      "    Uninstalling reinvent-models-0.0.15rc1:\n",
      "      Successfully uninstalled reinvent-models-0.0.15rc1\n",
      "  Running setup.py develop for reinvent-models\n",
      "Successfully installed reinvent-models-0.0.15rc1\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-chemistry\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y scikit-learn=0.21.3\n",
    "! pip list | grep reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ECFP_dataset(init_train_set_path, num_train_samples):\n",
    "    \"\"\"\n",
    "        Load background training data used to pre-train the predictive model    \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading D0\")\n",
    "    train_set = pd.read_csv(init_train_set_path)\n",
    "    feature_cols = [f\"bit{i}\" for i in range(2048)]\n",
    "    target_col = [\"activity\"]\n",
    "    smiles_train = train_set[\"smiles\"].values.reshape(-1)\n",
    "    x_train = train_set[feature_cols].values\n",
    "    y_train = train_set[target_col].values.reshape(-1)\n",
    "    sample_weight = np.array([1. for i in range(len(x_train))])\n",
    "    print(\"The feature matrix shape: \", x_train.shape)\n",
    "    print(\"The labels shape: \", y_train.shape)\n",
    "\n",
    "    train_sample = train_set[train_set[\"activity\"] == 1].sample(num_train_samples).smiles.tolist()\n",
    "    return x_train, y_train, sample_weight, smiles_train, train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scaffold_result(scaffold_memory_path, threshold=0.5):\n",
    "    scaffold_df = pd.read_csv(scaffold_memory_path)\n",
    "\n",
    "    data_len = len(scaffold_df)\n",
    "    print(\"Number of SMILES in scaffold_memory.csv: \", data_len)\n",
    "    colnames = scaffold_df.columns \n",
    "    scaffold = scaffold_df[\"Scaffold\"].to_numpy()\n",
    "    smiles = scaffold_df[\"SMILES\"].to_numpy()\n",
    "    human_component = scaffold_df[\"Human-Component\"].to_numpy()\n",
    "    raw_human_component = scaffold_df[\"raw_Human-Component\"].to_numpy()\n",
    "    total_score = scaffold_df[\"total_score\"].to_numpy()\n",
    "\n",
    "    # save the indexes of high scoring molecules for bioactivity\n",
    "    high_scoring_idx = np.where(total_score > threshold)[0]\n",
    "\n",
    "    print(f'{len(high_scoring_idx)}/{data_len} high-scoring (> {threshold}) molecules')\n",
    "\n",
    "    # Only analyse highest scoring molecules\n",
    "    smiles_high_score = smiles[high_scoring_idx]\n",
    "    scaffold_high_score = scaffold[high_scoring_idx]\n",
    "    human_component_high_score = human_component[high_scoring_idx]\n",
    "    raw_human_component_high_score = raw_human_component[high_scoring_idx]\n",
    "    total_score_high_score = total_score[high_scoring_idx]\n",
    "    \n",
    "    # print shape\n",
    "    print(\"Scaffold shape: \", scaffold_high_score.shape)\n",
    "    print(\"SMILES shape: \", smiles_high_score.shape)\n",
    "    print(\"Human component shape: \", human_component_high_score.shape)\n",
    "    print(\"Raw human component shape: \", raw_human_component_high_score.shape)\n",
    "    print(\"Total score shape: \", total_score_high_score.shape)\n",
    "    \n",
    "    output_high_score = {\n",
    "        \"scaffold\": scaffold_high_score,\n",
    "        \"smiles\": smiles_high_score,\n",
    "        \"human_component\": human_component_high_score,\n",
    "        \"raw_human_component\": raw_human_component_high_score,\n",
    "        \"total_score\": total_score_high_score\n",
    "    }\n",
    "    return output_high_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SMILES in scaffold_memory.csv:  101\n",
      "63/101 high-scoring (> 0.5) molecules\n",
      "Scaffold shape:  (63,)\n",
      "SMILES shape:  (63,)\n",
      "Human component shape:  (63,)\n",
      "Raw human component shape:  (63,)\n",
      "Total score shape:  (63,)\n"
     ]
    }
   ],
   "source": [
    "output_high_score = read_scaffold_result(\"output_feedback_comparing/HITL_round_1/results/scaffold_memory.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "\n",
    "def check_create(path):\n",
    "    \"\"\"\n",
    "    Check if the directory exists, if not, create it.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # score, compare, rank\n",
    "        model_pretrained_path, # Path to the pretrained model before HITL_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before HITL_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps. This is not related to the HITL but on the REINVENT side\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    "        ):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    ################################################\n",
    "    # DEFINING REINVENT JOBNAME, JOBID, OUTPUT_DIR #\n",
    "    ################################################\n",
    "\n",
    "    jobname = \"fine-tune predictive component HITL\"\n",
    "    jobid = f\"{dirname}_rounds_{num_rounds}_iters_{num_iters}_queries_{num_queries}_{acquisition}_noise_{sigma_noise}\"\n",
    "    conf_filename = \"config.json\"\n",
    "\n",
    "    # create root output dir\n",
    "    check_create(output_dir)\n",
    "\n",
    "    # create HITL round folders to store results\n",
    "    for HITL_round in np.arange(1, num_rounds + 1):\n",
    "        check_create(f\"{output_dir}/HITL_round_{HITL_round}\")\n",
    "    \n",
    "    # Copy the pretrained model to the first HITL_iteration\n",
    "    shutil.copy2(f\"{model_pretrained_path}\", f\"{output_dir}/HITL_round_1\")\n",
    "    \n",
    "    # store expert scores\n",
    "    expert_score = []\n",
    "\n",
    "    # multi-parameter optimization (MPO) loop\n",
    "    print(f\"Running DRD2 (one objective) with rounds {num_rounds}, iters {num_iters}, queries {num_queries}, seed {seed}. \\n Results will be saved at {output_dir}\")\n",
    "    \n",
    "    ########################### HITL rounds ######################################\n",
    "\n",
    "    for HITL_round in range(1, num_rounds + 1):\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"HITL round = {HITL_round}\")\n",
    "\n",
    "        HITL_round_output_dir = f\"{output_dir}/HITL_round_{HITL_round}\"\n",
    "        \n",
    "        if feedback_type == \"scoring\":\n",
    "            raise NotImplementedError(\"Score feedback not implemented yet.\")\n",
    "        elif feedback_type == \"comparing\":\n",
    "            configuration_JSON_path =\\\n",
    "                write_REINVENT_config_bradley_terry(reinvent_dir, jobid, jobname,\n",
    "                                                    HITL_round_output_dir, conf_filename\n",
    "                                                    )\n",
    "        elif feedback_type == \"ranking\":\n",
    "            raise NotImplementedError(\"Rank feedback not implemented yet.\")\n",
    "        \n",
    "        print(f\"Creating config file: {configuration_JSON_path}.\")\n",
    "\n",
    "        configuration = json.load(open(os.path.join(HITL_round_output_dir, conf_filename)))\n",
    "\n",
    "        # write specified number of RL optimization steps in configuration\n",
    "        # (example: if num_rounds = 5 (rounds) and Reinvent REINVENT_n_steps = 100, we will do 5*100 RL optimization steps)\n",
    "        configuration[\"parameters\"][\"reinforcement_learning\"][\"n_steps\"] = REINVENT_n_steps\n",
    "\n",
    "        # write the model path at current HITL round\n",
    "        configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "        \n",
    "        configuration_scoring_function[0][\"specific_parameters\"][\"model_pretrained_path\"] =\\\n",
    "            f\"{HITL_round_output_dir}/{model_pretrained_name}\"\n",
    "        \n",
    "        configuration[\"parameters\"][\"scoring_function\"][\"parameters\"] = configuration_scoring_function\n",
    "        \n",
    "        # write the updated configuration file to the disc\n",
    "        configuration_JSON_path = f\"{os.getcwd()}/{HITL_round_output_dir}/{conf_filename}\"\n",
    "        print(\"The configuration file path: \", configuration_JSON_path)\n",
    "\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "        \n",
    "        # Initialize human feedback model\n",
    "\n",
    "        print(f\"Loading {feedback_type} feedback model.\")\n",
    "\n",
    "        if feedback_type == \"scoring\":\n",
    "            raise NotImplementedError(\"Score feedback not implemented yet.\")\n",
    "        elif feedback_type == \"comparing\":\n",
    "            feedback_model = BradleyTerryModel()\n",
    "            # Load the state dict\n",
    "            feedback_model.load_state_dict(torch.load(f\"{HITL_round_output_dir}/{model_pretrained_name}\"))\n",
    "            print(\"Loading Bradley Terry model successfully\")\n",
    "        elif feedback_type == \"ranking\":\n",
    "            raise NotImplementedError(\"Rank feedback not implemented yet.\")\n",
    "\n",
    "        # generate a pool of unlabelled compounds with REINVENT\n",
    "        print(\"Run REINVENT\")                \n",
    "        command = f\"{reinvent_env}/bin/python\"\n",
    "        script = f\"{reinvent_dir}/input.py\"\n",
    "        config_path = configuration_JSON_path\n",
    "        stderr_file = f\"{HITL_round_output_dir}/run.err\"\n",
    "        stdout_file = f\"{HITL_round_output_dir}/run.out\"\n",
    "\n",
    "        # Construct the full command to run\n",
    "        cmd = [command, script, config_path]\n",
    "        # Open the file to which you want to redirect stderr and stdout\n",
    "        with open(stderr_file, 'w') as ferr, open(stdout_file, 'w') as fout:\n",
    "            # Execute the command\n",
    "            result = subprocess.run(cmd, text=True, stdout=fout, stderr=ferr)\n",
    "        # Check the result\n",
    "        print(\"Exit code:\", result.returncode)\n",
    "        \n",
    "        #############################################################################\n",
    "        # REINVENT HAS OUTPUT THE RESULT in path f\"{HITL_round_output_dir}/results\" #\n",
    "        #############################################################################\n",
    "        \n",
    "        output_high_score = read_scaffold_result(f\"{HITL_round_output_dir}/results/scaffold_memory.csv\", threshold)\n",
    "        \n",
    "        # store molecule indexes selected for feedback\n",
    "        selected_feedback = np.empty(0).astype(int)\n",
    "        human_sample_weight = np.empty(0).astype(float)\n",
    "        # store number of accepted queries (y = 1) at each HITL_iteration\n",
    "        n_accept = []\n",
    "\n",
    "        ########################### HITL_iteration in each round #####################\n",
    "        \n",
    "        for HITL_iteration in range(1, num_iters + 1): # T number of HITL_iterations\n",
    "            print(\"=====================================\")\n",
    "            print(f\"HITL_iteration = {HITL_iteration}\")\n",
    "            \n",
    "            # classify \n",
    "            model = RandomForestClf(fitted_model)\n",
    "            \n",
    "            if len(smiles) > num_queries:\n",
    "                new_query = select_query(data, num_queries, list(smiles), model, selected_feedback, acquisition, rng) # select n smiles with Active Learning\n",
    "            else:\n",
    "                new_query = select_query(data, len(smiles), list(smiles), model, selected_feedback, acquisition, rng)\n",
    "            \n",
    "            # Initialize the expert values vector\n",
    "            s_bioactivity = [] # for scores (between 0 and 1)\n",
    "            v_bioactivity = [] # for continuous feedback (regression)\n",
    "            \n",
    "            # Get expert feedback on selected queries\n",
    "            print(new_query)\n",
    "            for i in new_query:\n",
    "                cur_mol = data.iloc[i][\"SMILES\"]\n",
    "                print(cur_mol)\n",
    "                value = feedback_model.human_score(cur_mol, sigma_noise)\n",
    "                s_bioactivity.append(value)\n",
    "            \n",
    "            # Get raw scores and transformed score (if any) from the high scoring molecules in U\n",
    "            raw_scoring_component_names = [\"raw_\"+name for name in scoring_component_names] \n",
    "            x_raw = data[raw_scoring_component_names].to_numpy()\n",
    "            x =  data[scoring_component_names].to_numpy()\n",
    "\n",
    "            # get (binary) simulated chemist's responses\n",
    "            \n",
    "            new_y = np.array([1 if s > 0.5 else 0 for s in s_bioactivity])\n",
    "            accepted = new_y.tolist()\n",
    "            \n",
    "            expert_score += [accepted]\n",
    "            n_accept += [sum(accepted)]\n",
    "\n",
    "            print(f\"Feedback idx at HITL_iteration {HITL_round}, {HITL_iteration}: {new_query}\")\n",
    "            print(f\"Number of accepted molecules at HITL_iteration {HITL_round}, {HITL_iteration}: {n_accept[HITL_iteration]}\")   \n",
    "            \n",
    "            # append feedback\n",
    "            if len(new_y) > 0:\n",
    "                selected_feedback = np.hstack((selected_feedback, new_query))\n",
    "\n",
    "            mask = np.ones(N, dtype=bool)\n",
    "            mask[selected_feedback] = False\n",
    "\n",
    "            # use the augmented training data to retrain the model\n",
    "            new_smiles = data.iloc[new_query].SMILES.tolist()\n",
    "            new_mols = [Chem.MolFromSmiles(s) for s in new_smiles]\n",
    "            new_x = fingerprints_from_mol(new_mols, type = \"counts\")\n",
    "            new_human_sample_weight = np.array([s if s > 0.5 else 1-s for s in s_bioactivity])\n",
    "            sample_weight = np.concatenate([sample_weight, new_human_sample_weight])\n",
    "            print(len(new_x), len(new_y))\n",
    "            x_train = np.concatenate([x_train, new_x])\n",
    "            y_train = np.concatenate([y_train, new_y])\n",
    "            smiles_train = np.concatenate([smiles_train, new_smiles])\n",
    "            print(f\"Augmented train set size at HITL_iteration {HITL_round}: {x_train.shape[0]} {y_train.shape[0]}\")\n",
    "            \n",
    "            # save augmented training data\n",
    "            D_r = pd.DataFrame(np.concatenate([smiles_train.reshape(-1,1), x_train, y_train.reshape(-1,1)], 1))\n",
    "            D_r.columns = [\"SMILES\"] + [f\"bit{i}\" for i in range(x_train.shape[1])] + [\"target\"]\n",
    "            D_r.to_csv(os.path.join(output_dir, f\"augmented_train_set_iter{HITL_round}.csv\"))\n",
    "\n",
    "            # re-fit and save the model using the augmented train set and save to new directory\n",
    "            model_new_savefile = output_dir + '/{}_HITL_iteration_{}.pkl'.format(predictive_model_name, HITL_round)\n",
    "            model._retrain(x_train, y_train, sample_weight = sample_weight, save_to_path = model_new_savefile)\n",
    "            fitted_model = pickle.load(open(model_new_savefile, 'rb'))\n",
    "\n",
    "            # get current configuration\n",
    "            configuration = json.load(open(os.path.join(output_dir, conf_filename)))\n",
    "            conf_filename = \"HITL_iteration{}_config.json\".format(HITL_round)    \n",
    "\n",
    "            # modify model path in configuration\n",
    "            configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "            for i in range(len(configuration_scoring_function)):\n",
    "                if configuration_scoring_function[i][\"component_type\"] == \"predictive_property\":\n",
    "                    configuration_scoring_function[i][\"specific_parameters\"][\"model_path\"] = model_new_savefile\n",
    "\n",
    "            # Keep agent checkpoint\n",
    "            if HITL_round == 1:\n",
    "                configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(initial_dir, \"results/Agent.ckpt\")\n",
    "            else:\n",
    "                configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(output_dir, \"results/Agent.ckpt\")\n",
    "\n",
    "        root_output_dir = os.path.expanduser(\"{}_seed{}\".format(jobid, seed))\n",
    "\n",
    "        # Define new directory for the next round\n",
    "        output_dir = os.path.join(root_output_dir, \"HITL_iteration{}_{}\".format(HITL_round, acquisition))\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        print(output_dir)\n",
    "\n",
    "        # modify log and result paths in configuration\n",
    "        configuration[\"logging\"][\"logging_path\"] = os.path.join(output_dir, \"progress.log\")\n",
    "        configuration[\"logging\"][\"result_folder\"] = os.path.join(output_dir, \"results\")\n",
    "\n",
    "        # write the updated configuration file to the disc\n",
    "        configuration_JSON_path = os.path.join(output_dir, conf_filename)\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "\n",
    "    r = np.arange(len(expert_score))\n",
    "    m_score = [np.mean(expert_score[i]) for i in r]\n",
    "    print(\"Mean expert score : \", m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/springnuance/reinvent-hitl/Base-Code-Binh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Running DRD2 (one objective) with rounds 2, iters 10, queries 10, seed 42. \n",
      " Results will be saved at output_feedback_comparing\n",
      "=====================================\n",
      "HITL round = 1\n",
      "Creating config file: output_feedback_comparing/HITL_round_1/config.json.\n",
      "The configuration file path:  /home/springnuance/reinvent-hitl/Base-Code-Binh/output_feedback_comparing/HITL_round_1/config.json\n",
      "Loading comparing feedback model.\n",
      "Loading Bradley Terry model successfully\n",
      "Run REINVENT\n",
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  101\n",
      "63/101 high-scoring (> 0.5) molecules\n",
      "Scaffold shape:  (63,)\n",
      "SMILES shape:  (63,)\n",
      "Human component shape:  (63,)\n",
      "Raw human component shape:  (63,)\n",
      "Total score shape:  (63,)\n",
      "=====================================\n",
      "HITL_iteration = 1\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fitted_model' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-8f77159b18b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0macquisition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0msigma_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# noise level for simulated chemist's responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mthreshold\u001b[0m \u001b[0;31m# threshold for high scoring molecules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-56-80e433ba66f7>\u001b[0m in \u001b[0;36mrun_HITL_classify\u001b[0;34m(seed, dirname, reinvent_dir, reinvent_env, output_dir, restart, feedback_type, model_pretrained_path, model_pretrained_name, num_rounds, num_iters, num_queries, REINVENT_n_steps, acquisition, sigma_noise, threshold)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# classify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnum_queries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'fitted_model' referenced before assignment"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "dirname = \"outputs\"\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"comparing\" # scoring, comparing, ranking\n",
    "output_dir = f\"output_feedback_{feedback_type}\"\n",
    "\n",
    "# feedback type as scoring:\n",
    "# Given a molecule, what is the probability that the molecule is active regarding DRD2?  \n",
    "\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/score_regression_model.pth\"\n",
    "model_pretrained_name = \"score_regression_model.pth\"\n",
    "\n",
    "# feedback type as comparing:\n",
    "# Given two molecules, what is the probability that the first molecule is more active than the second molecule regarding DRD2?\n",
    "\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/bradley_terry_model.pth\"\n",
    "model_pretrained_name = \"bradley_terry_model.pth\"\n",
    "\n",
    "# feedback type as ranking:\n",
    "# Given N molecules, what are the orders of preference of these molecules regarding DRD2?\n",
    "\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/rank_listnet_model.pth\"\n",
    "model_pretrained_name = \"rank_listnet_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "num_iters = 10 # number of molecules shown at each HITL_iteration to the human for feedback\n",
    "num_queries = 10 # number of molecules shown to the simulated chemist at each HITL_iteration (10 pairs)\n",
    "threshold = 0.5 # threshold for high scoring molecules\n",
    "    \n",
    "run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        model_pretrained_path, # Path to the pretrained model before HITL_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before HITL_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc_env_hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
