{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run this code with the kernel reinvent.v3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle\n",
    "import subprocess\n",
    "\n",
    "from utils import fingerprints_from_mol\n",
    "\n",
    "from scripts.acquisition import select_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install the custom reinvent scoring package to support the Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# print python version\n",
    "import sys\n",
    "\n",
    "# Print Python version\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: reinvent-scoring\n",
      "Version: 0.0.73\n",
      "Summary: Scoring functions for Reinvent\n",
      "Home-page: https://github.com/MolecularAI/reinvent-scoring.git\n",
      "Author: MolecularAI\n",
      "Author-email: patronov@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install scikit-learn=0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If there already exists reinvent_scoring, we should uninstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: reinvent-scoring 0.0.73\n",
      "Uninstalling reinvent-scoring-0.0.73:\n",
      "  Successfully uninstalled reinvent-scoring-0.0.73\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y reinvent_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we install the custom reinvent scoring package\n",
    "##### The flag -e means that the package is installed in editable mode, so that changes to the code will be immediately available without reinstalling the package. All package info is stored in the setup.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-chemistry\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-chemistry\n",
      "  Attempting uninstall: reinvent-chemistry\n",
      "    Found existing installation: reinvent-chemistry 0.0.51\n",
      "    Uninstalling reinvent-chemistry-0.0.51:\n",
      "      Successfully uninstalled reinvent-chemistry-0.0.51\n",
      "  Running setup.py develop for reinvent-chemistry\n",
      "Successfully installed reinvent-chemistry-0.0.51\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-models\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-models\n",
      "  Attempting uninstall: reinvent-models\n",
      "    Found existing installation: reinvent-models 0.0.15rc1\n",
      "    Uninstalling reinvent-models-0.0.15rc1:\n",
      "      Successfully uninstalled reinvent-models-0.0.15rc1\n",
      "  Running setup.py develop for reinvent-models\n",
      "Successfully installed reinvent-models-0.0.15rc1\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-chemistry\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y scikit-learn=0.21.3\n",
    "! pip list | grep reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the function\n",
    "# feedback_type = \"scoring\"\n",
    "# base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_training_data.csv\"\n",
    "# base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_testing_data.csv\"\n",
    "\n",
    "# # bradley_terry\n",
    "# feedback_type = \"comparing\"\n",
    "# base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_training_data.csv\"\n",
    "# base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_testing_data.csv\"\n",
    "\n",
    "# rank_listnet\n",
    "feedback_type = \"ranking\"\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_testing_data.csv\"\n",
    "\n",
    "outputs = load_drd2_dataset(feedback_type=feedback_type, data_path=base_training_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "from training_Rank_ListNet_model.rank_listnet import RankListNetModel\n",
    "from training_Score_Regression_model.score_regression import ScoreRegressionModel\n",
    "from scripts.acquisition import select_query\n",
    "from scripts.simulated_expert import ActivityEvaluationModel\n",
    "from helper import write_REINVENT_config, change_config_json, load_feedback_model, read_scaffold_result\n",
    "\n",
    "def check_create(path):\n",
    "    \"\"\"\n",
    "    Check if the directory exists, if not, create it.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps. This is not related to the HITL but on the REINVENT side\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    "        ):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    ################################################\n",
    "    # DEFINING REINVENT JOBNAME, JOBID, OUTPUT_DIR #\n",
    "    ################################################\n",
    "\n",
    "    jobname = \"fine-tune predictive component HITL\"\n",
    "    jobid = f\"{dirname}_rounds_{num_rounds}_iters_{num_iters}_queries_{num_queries}_{acquisition}_noise_{sigma_noise}\"\n",
    "    conf_filename = \"config.json\"\n",
    "\n",
    "    # create root output dir\n",
    "    check_create(output_dir)\n",
    "\n",
    "    # create HITL round folders to store results\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "        check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}\")\n",
    "        for HITL_iteration in range(1, num_iters + 1):\n",
    "            check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration}\")\n",
    "    \n",
    "    # Copy the pretrained model to the first HITL_iteration\n",
    "    shutil.copy2(f\"{model_pretrained_path}\", f\"{output_dir}/REINVENT_round_1/HITL_iteration_1\")\n",
    "    \n",
    "    # store expert scores\n",
    "    expert_score = []\n",
    "\n",
    "    # multi-parameter optimization (MPO) loop\n",
    "    print(f\"Running DRD2 (one objective) with rounds {num_rounds}, iters {num_iters}, queries {num_queries}, seed {seed}. \\n Results will be saved at {output_dir}\")\n",
    "    \n",
    "    # ########################### REINVENT rounds ######################################\n",
    "\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"REINVENT round = {REINVENT_round}\")\n",
    "\n",
    "        REINVENT_round_output_dir = f\"{output_dir}/REINVENT_round_{REINVENT_round}\"\n",
    "        \n",
    "        configuration_JSON_path = write_REINVENT_config(feedback_type, reinvent_dir, jobid, jobname, \n",
    "                                                        REINVENT_round_output_dir, conf_filename)\n",
    "\n",
    "\n",
    "        print(f\"Creating config file: {configuration_JSON_path}.\")\n",
    "\n",
    "        configuration = json.load(open(f\"{configuration_JSON_path}\"))\n",
    "\n",
    "        current_model_path = f\"{REINVENT_round_output_dir}/HITL_iteration_1/{model_pretrained_name}\"\n",
    "\n",
    "        configuration = change_config_json(configuration, REINVENT_n_steps, current_model_path)\n",
    "\n",
    "        # write the updated configuration file \n",
    "\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "\n",
    "        break\n",
    "    \n",
    "    #     # generate a pool of unlabelled compounds with REINVENT\n",
    "    #     print(\"Run REINVENT\")                \n",
    "    #     command = f\"{reinvent_env}/bin/python\"\n",
    "    #     script = f\"{reinvent_dir}/input.py\"\n",
    "    #     config_path = configuration_JSON_path\n",
    "    #     stderr_file = f\"{REINVENT_round_output_dir}/run.err\"\n",
    "    #     stdout_file = f\"{REINVENT_round_output_dir}/run.out\"\n",
    "\n",
    "    #     # Construct the full command to run\n",
    "    #     cmd = [command, script, config_path]\n",
    "    #     # Open the file to which you want to redirect stderr and stdout\n",
    "    #     with open(stderr_file, 'w') as ferr, open(stdout_file, 'w') as fout:\n",
    "    #         # Execute the command\n",
    "    #         result = subprocess.run(cmd, text=True, stdout=fout, stderr=ferr)\n",
    "    #     # Check the result\n",
    "    #     print(\"Exit code:\", result.returncode)\n",
    "        \n",
    "    #     # Initialize human feedback model\n",
    "    #     print(f\"Loading {feedback_type} feedback model.\")\n",
    "\n",
    "    #     # Loading feedback model\n",
    "    #     feedback_model_path = f\"{REINVENT_round_output_dir}/{model_pretrained_name}\"\n",
    "    #     feedback_model = load_feedback_model(feedback_type, feedback_model_path)\n",
    "        \n",
    "    #     #############################################################################\n",
    "    #     # REINVENT HAS OUTPUT THE RESULT in path f\"{REINVENT_round_output_dir}/results\" #\n",
    "    #     #############################################################################\n",
    "        \n",
    "    #     output_high_score = read_scaffold_result(f\"{REINVENT_round_output_dir}/results/scaffold_memory.csv\", threshold)\n",
    "        \n",
    "    #     scaffold_output = output_high_score[\"scaffold\"]\n",
    "    #     smiles_output = output_high_score[\"smiles\"]\n",
    "    #     human_component_output = output_high_score[\"human_component\"]\n",
    "    #     raw_human_component_output = output_high_score[\"raw_human_component\"]\n",
    "    #     total_score_output = output_high_score[\"total_score\"]\n",
    "        \n",
    "    #     drd2_oracle_model = ActivityEvaluationModel()\n",
    "    #     smiles_score_human = [drd2_oracle_model.human_score(smile, sigma_noise) for smile in smiles_output] \n",
    "        \n",
    "    #     # store molecule indexes selected for feedback\n",
    "    #     selected_feedback = np.empty(0).astype(int)\n",
    "    #     human_sample_weight = np.empty(0).astype(float)\n",
    "    #     # store number of accepted queries (y = 1) at each HITL_iteration\n",
    "    #     n_accept = []\n",
    "\n",
    "    #     ########################### HITL_iteration in each round #####################\n",
    "        \n",
    "    #     for HITL_iteration in range(1, num_iters + 1): # T number of HITL_iterations\n",
    "    #         print(\"=====================================\")\n",
    "    #         print(f\"HITL_iteration = {HITL_iteration}\")\n",
    "            \n",
    "    #         # classify \n",
    "    #         model = RandomForestClf(fitted_model)\n",
    "            \n",
    "    #         if len(smiles) > num_queries:\n",
    "    #             new_query = select_query(data, num_queries, list(smiles), model, selected_feedback, acquisition, rng) # select n smiles with Active Learning\n",
    "    #         else:\n",
    "    #             new_query = select_query(data, len(smiles), list(smiles), model, selected_feedback, acquisition, rng)\n",
    "            \n",
    "    #         # Initialize the expert values vector\n",
    "    #         s_bioactivity = [] # for scores (between 0 and 1)\n",
    "    #         v_bioactivity = [] # for continuous feedback (regression)\n",
    "            \n",
    "    #         # Get expert feedback on selected queries\n",
    "    #         print(new_query)\n",
    "    #         for i in new_query:\n",
    "    #             cur_mol = data.iloc[i][\"SMILES\"]\n",
    "    #             print(cur_mol)\n",
    "    #             value = feedback_model.human_score(cur_mol, sigma_noise)\n",
    "    #             s_bioactivity.append(value)\n",
    "            \n",
    "    #         # Get raw scores and transformed score (if any) from the high scoring molecules in U\n",
    "    #         raw_scoring_component_names = [\"raw_\"+name for name in scoring_component_names] \n",
    "    #         x_raw = data[raw_scoring_component_names].to_numpy()\n",
    "    #         x =  data[scoring_component_names].to_numpy()\n",
    "\n",
    "    #         # get (binary) simulated chemist's responses\n",
    "            \n",
    "    #         new_y = np.array([1 if s > 0.5 else 0 for s in s_bioactivity])\n",
    "    #         accepted = new_y.tolist()\n",
    "            \n",
    "    #         expert_score += [accepted]\n",
    "    #         n_accept += [sum(accepted)]\n",
    "\n",
    "    #         print(f\"Feedback idx at HITL_iteration {REINVENT_round}, {HITL_iteration}: {new_query}\")\n",
    "    #         print(f\"Number of accepted molecules at HITL_iteration {REINVENT_round}, {HITL_iteration}: {n_accept[HITL_iteration]}\")   \n",
    "            \n",
    "    #         # append feedback\n",
    "    #         if len(new_y) > 0:\n",
    "    #             selected_feedback = np.hstack((selected_feedback, new_query))\n",
    "\n",
    "    #         mask = np.ones(N, dtype=bool)\n",
    "    #         mask[selected_feedback] = False\n",
    "\n",
    "    #         # use the augmented training data to retrain the model\n",
    "    #         new_smiles = data.iloc[new_query].SMILES.tolist()\n",
    "    #         new_mols = [Chem.MolFromSmiles(s) for s in new_smiles]\n",
    "    #         new_x = fingerprints_from_mol(new_mols, type = \"counts\")\n",
    "    #         new_human_sample_weight = np.array([s if s > 0.5 else 1-s for s in s_bioactivity])\n",
    "    #         sample_weight = np.concatenate([sample_weight, new_human_sample_weight])\n",
    "    #         print(len(new_x), len(new_y))\n",
    "    #         x_train = np.concatenate([x_train, new_x])\n",
    "    #         y_train = np.concatenate([y_train, new_y])\n",
    "    #         smiles_train = np.concatenate([smiles_train, new_smiles])\n",
    "    #         print(f\"Augmented train set size at HITL_iteration {REINVENT_round}: {x_train.shape[0]} {y_train.shape[0]}\")\n",
    "            \n",
    "    #         # save augmented training data\n",
    "    #         D_r = pd.DataFrame(np.concatenate([smiles_train.reshape(-1,1), x_train, y_train.reshape(-1,1)], 1))\n",
    "    #         D_r.columns = [\"SMILES\"] + [f\"bit{i}\" for i in range(x_train.shape[1])] + [\"target\"]\n",
    "    #         D_r.to_csv(os.path.join(output_dir, f\"augmented_train_set_iter{REINVENT_round}.csv\"))\n",
    "\n",
    "    #         # re-fit and save the model using the augmented train set and save to new directory\n",
    "    #         model_new_savefile = output_dir + '/{}_HITL_iteration_{}.pkl'.format(predictive_model_name, REINVENT_round)\n",
    "    #         model._retrain(x_train, y_train, sample_weight = sample_weight, save_to_path = model_new_savefile)\n",
    "    #         fitted_model = pickle.load(open(model_new_savefile, 'rb'))\n",
    "\n",
    "    #         # get current configuration\n",
    "    #         configuration = json.load(open(os.path.join(output_dir, conf_filename)))\n",
    "    #         conf_filename = \"HITL_iteration{}_config.json\".format(REINVENT_round)    \n",
    "\n",
    "    #         # modify model path in configuration\n",
    "    #         configuration_scoring_function = configuration[\"parameters\"][\"scoring_function\"][\"parameters\"]\n",
    "    #         for i in range(len(configuration_scoring_function)):\n",
    "    #             if configuration_scoring_function[i][\"component_type\"] == \"predictive_property\":\n",
    "    #                 configuration_scoring_function[i][\"specific_parameters\"][\"model_path\"] = model_new_savefile\n",
    "\n",
    "    #         # Keep agent checkpoint\n",
    "    #         if REINVENT_round == 1:\n",
    "    #             configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(initial_dir, \"results/Agent.ckpt\")\n",
    "    #         else:\n",
    "    #             configuration[\"parameters\"][\"reinforcement_learning\"][\"agent\"] = os.path.join(output_dir, \"results/Agent.ckpt\")\n",
    "\n",
    "    #     root_output_dir = os.path.expanduser(\"{}_seed{}\".format(jobid, seed))\n",
    "\n",
    "    #     # Define new directory for the next round\n",
    "    #     output_dir = os.path.join(root_output_dir, \"HITL_iteration{}_{}\".format(REINVENT_round, acquisition))\n",
    "    #     if not os.path.exists(output_dir):\n",
    "    #         os.makedirs(output_dir)\n",
    "    #     print(output_dir)\n",
    "\n",
    "    #     # modify log and result paths in configuration\n",
    "    #     configuration[\"logging\"][\"logging_path\"] = os.path.join(output_dir, \"progress.log\")\n",
    "    #     configuration[\"logging\"][\"result_folder\"] = os.path.join(output_dir, \"results\")\n",
    "\n",
    "    #     # write the updated configuration file to the disc\n",
    "    #     configuration_JSON_path = os.path.join(output_dir, conf_filename)\n",
    "    #     with open(configuration_JSON_path, 'w') as f:\n",
    "    #         json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "\n",
    "    # r = np.arange(len(expert_score))\n",
    "    # m_score = [np.mean(expert_score[i]) for i in r]\n",
    "    # print(\"Mean expert score : \", m_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/springnuance/reinvent-hitl/Base-Code-Binh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running score regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "dirname = \"outputs\"\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"scoring\" # scoring, comparing, ranking\n",
    "output_dir = f\"output_feedback_{feedback_type}\"\n",
    "\n",
    "# feedback type as scoring:\n",
    "# Given a molecule, what is the probability that the molecule is active regarding DRD2?  \n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/score_regression_model.pth\"\n",
    "model_pretrained_name = \"score_regression_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "threshold = 0.5 # threshold for high scoring molecules\n",
    "    \n",
    "run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Bradley Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Running DRD2 (one objective) with rounds 2, iters 3, queries 10, seed 42. \n",
      " Results will be saved at output_feedback_comparing\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: output_feedback_comparing/REINVENT_round_1/config.json.\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "dirname = \"outputs\"\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"comparing\" # scoring, comparing, ranking\n",
    "output_dir = f\"output_feedback_{feedback_type}\"\n",
    "\n",
    "# feedback type as comparing:\n",
    "# Given two molecules, what is the probability that the first molecule is more active than the second molecule regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/bradley_terry_model.pth\"\n",
    "model_pretrained_name = \"bradley_terry_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.1 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "threshold = 0.5 # threshold for high scoring molecules\n",
    "    \n",
    "run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rank ListNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "dirname = \"outputs\"\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"ranking\" # scoring, comparing, ranking\n",
    "output_dir = f\"output_feedback_{feedback_type}\"\n",
    "\n",
    "# feedback type as ranking:\n",
    "# Given N molecules, what are the orders of preference of these molecules regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/rank_listnet_model.pth\"\n",
    "model_pretrained_name = \"rank_listnet_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 1 # number of REINVENT optimization steps\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"thompson\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "threshold = 0.5 # threshold for high scoring molecules\n",
    "    \n",
    "run_HITL_classify(\n",
    "        seed, dirname, reinvent_dir, reinvent_env, output_dir, restart,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        threshold # threshold for high scoring molecules\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc_env_hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
