{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0005901676463998309, 0.001288978921112421, 0.00023099921452992108, 0.0014480634352253118, 0.00023229149413919086, 0.007226910417238079, 0.03177009486102104, 0.00018465196104625156, 0.0006181948403864203, 0.017767959705749174, 0.0001353658415040822, 7.584214925439865e-05, 0.00011932658307753439, 0.00019596215439119096, 5.0310012366721855e-05, 0.00153997550154151, 0.004863899555067754, 0.0013627517075909072, 0.00022636359589811632, 0.9999907104594737, 0.002364173240172854, 0.9999987724917501, 0.0004128064910287372, 4.515114620151249e-05, 0.9999899941967955, 3.439700377056164e-05, 0.005426522090583173, 0.00015732934690030053, 0.0003269993975438858, 0.0003363411034820678, 0.0055611952891646, 0.9890921212669289, 0.9999988552735308, 0.9905578204031097, 0.00045109684719108454, 0.0012732716327158269, 0.0005288131087850552, 0.0021161386976471714, 0.014029352175312171, 0.013244877011903917, 0.9999973055784004, 0.9999998974481366, 0.0032787785378776348, 0.0002981816185162872, 0.00042036779434050873, 0.001814834216310095, 0.0011774454500123486, 0.0010582825849395822, 0.00018476092638482834, 0.0007292199909660255, 0.0003754157463252528, 0.0041114146581634455, 0.9999979172189909, 0.006261474972710569, 0.9999979450327827, 0.0001879892487192794, 0.003896816782062064, 8.958536744060414e-05, 0.0004092054668379563, 0.004782212562425562, 0.002209865026652471, 0.9999945012677769, 0.0004092054668379563, 0.0002865270730883282, 0.0013202989172575188, 0.001810292038855387, 0.0006702484938684605, 0.00019586360854653503, 0.000383641159481653, 0.9999975683231251, 0.9968642932401842, 0.9935260639669249, 0.0006438897722014135, 0.002404273805165934, 0.9999994910723929, 0.001938311493176282, 0.002065353515301654, 6.979447770930128e-05, 0.999999540363816, 0.0005154213061424374, 0.9999973055784004, 0.99999481531433, 0.0012062095273522617, 0.0003016502942466645, 0.9999973055784004, 0.9999993478737205, 0.014115803656290614, 0.00033702279693329044, 0.00042505771109273055, 0.0014580654985439539, 0.000847669237280818, 0.0002342716665780194, 0.9999875912605337, 0.9422954647225189, 0.0020147324375968233, 0.9999979549672328, 0.0006876249604984917, 0.04545445072064346, 0.9999979508542166, 0.0004685846458284135, 0.003358949275224765, 0.9918497484692325, 0.000740826918224148, 0.0005622464610039502, 0.0010582825849395822, 0.984760736217924, 0.0003237994420893527, 0.0003587470337912561, 0.9999998969657062, 0.000177739522203383, 0.00034957783687254853, 0.9999999639608361, 0.00015421563601894172, 0.00025857824397611283, 0.0022870322544063623, 0.0005530418948680203, 0.000345994363763932, 0.0005663269162095706, 0.9999981263100579, 0.0005810591261236133, 0.001476121604255974, 0.9999889064723066, 0.00018579878833621075, 0.001191370188987206, 0.0010978339976112244, 0.9999967152818698, 0.0012575329606122417, 0.9999989916680257, 0.00048384335155571734, 9.738623776762325e-05, 8.876027118262232e-05, 0.9999979460964545, 0.00021676418371091347, 0.0013592987179396636, 0.9999998969657062, 0.0027752367783352608, 0.9688444477416027, 0.004040068207550039, 0.9999979528706872, 0.0003673147106466183, 0.0007585474459448414, 0.0046734567718272, 0.0013648549463819283, 0.989853043086398, 0.006187637068708067, 0.9999936356426508, 0.0008113241314145356, 0.00042064769864728327, 0.0007064421619055175, 0.9999990380336338, 0.0005559191528330199, 0.00015477336953094857, 0.0017319101087791414, 0.9970724635338566, 0.0017120153193430651, 0.0003133717004575522, 0.9972006958914625, 0.001347681150180494, 0.9999988707993551, 0.9474463159595384, 0.001936425678589996, 9.681679633224503e-05, 0.9999981263100579, 0.0019028051472603925, 0.9999991870643247, 0.0009439804100662562, 1.7974291153285605e-05, 0.99999481531433, 0.9999993817505263, 0.9999979549672328, 0.002514533367109411, 0.005300985628557938, 0.997080057938897, 0.000421870379538592, 0.0008055625738994726, 9.682858953475047e-05, 0.0026566603742818867, 0.9999888061243491, 0.9999979420192974, 0.00045934865975602666, 0.0001257025618620002, 0.9999917069555132, 0.002807497162824487, 0.0005092048368857076, 6.857075109763618e-05, 4.66497221930094e-05, 0.0013342240503595828, 0.0002897644899935572, 0.00021951242930383935, 0.003614265706607552, 0.003236775616799799, 0.0002585625975243525, 1.8074112189849902e-05, 0.0004359816677336856, 7.584214925439865e-05, 0.9999989798534827, 0.0005658792264689748, 0.996677788804331, 4.8878943261661794e-05, 0.0003719319401692122, 0.003078488554464032, 0.9561598241613558, 0.9999990324768554, 0.9829503430432021, 0.00036461921911503585, 2.2147402930533356e-05, 0.0034735169030902157, 0.00024971500053392616, 0.00037815784102775536, 0.9999979485955824, 0.9999997372338433, 0.0004819792511980272, 0.99999751014689, 0.0008108943006821922, 0.005483673009565892, 9.704775701398966e-05, 0.0017957755032875175, 0.9999984926091092, 0.0023386270272292534, 0.9968642932401842, 0.0008258382853335917, 0.00095549861271999, 0.004174886952397837, 0.0005315070657719729, 0.9999993478737205, 0.0005432504687833247, 0.00013488827625616882, 0.00384358999185699, 0.9999998916661036, 0.0006082499504658582, 0.00035381608185397804, 0.0036591717264559715, 0.0008569518530564626, 0.0023707204088490416, 0.00018925489290841238, 0.9999997261291642, 0.9999979549672328, 0.9999981263100579, 0.9999999202103159, 0.001788454414272621]\n"
     ]
    }
   ],
   "source": [
    "# Load data and Oracle\n",
    "oracle = Oracle(name='DRD2')\n",
    "data = pd.read_csv(\"small_drd2_data.csv\")\n",
    "smiles_list = data['smiles'].tolist()\n",
    "proba_molecules = [oracle(smiles) for smiles in smiles_list]\n",
    "print(proba_molecules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing morgan fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 2048])\n"
     ]
    }
   ],
   "source": [
    "def compute_fingerprints(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None:\n",
    "        return AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048)\n",
    "    else:\n",
    "        return np.zeros((2048,), dtype=int)\n",
    "\n",
    "features = torch.tensor([compute_fingerprints(smiles) for smiles in smiles_list])\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate pairs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairs_labels(features, proba_molecules, smiles_list, num_sets = 100):\n",
    "    n = len(features)\n",
    "    features_1 = []\n",
    "    features_2 = []\n",
    "    features_3 = []\n",
    "    labels_1_proba = []\n",
    "    labels_1_rank = []\n",
    "    labels_2_proba = []\n",
    "    labels_2_rank = []\n",
    "    labels_3_proba = []\n",
    "    labels_3_rank = []\n",
    "    smiles_1 = []\n",
    "    smiles_2 = []\n",
    "    smiles_3 = []\n",
    "\n",
    "    # set seed\n",
    "    np.random.seed(42) \n",
    "    \n",
    "    count = 0\n",
    "    # sample unrepeated num_sets number of pairs\n",
    "    while count < num_sets:\n",
    "        i = np.random.randint(0, n)\n",
    "        j = np.random.randint(0, n)\n",
    "        k = np.random.randint(0, n)\n",
    "        if i != j and i != k and j != k:\n",
    "            features_1.append(features[i])\n",
    "            features_2.append(features[j])\n",
    "            features_3.append(features[k])\n",
    "\n",
    "            smiles_1.append(smiles_list[i])\n",
    "            smiles_2.append(smiles_list[j])\n",
    "            smiles_3.append(smiles_list[k])\n",
    "\n",
    "            # convert to float\n",
    "            proba_list = [proba_molecules[i], proba_molecules[j], proba_molecules[k]]\n",
    "            proba_softmax = nn.Softmax(dim=0)(torch.tensor(proba_list))\n",
    "\n",
    "            # Now we need to rank them\n",
    "            # Rank 1 has lowest value, Rank 3 has highest value\n",
    "            ranks = np.argsort(np.argsort(proba_softmax)) + 1\n",
    "\n",
    "            labels_1_proba.append(proba_softmax[0])\n",
    "            labels_1_rank.append(ranks[0])\n",
    "            labels_2_proba.append(proba_softmax[1])\n",
    "            labels_2_rank.append(ranks[1])\n",
    "            labels_3_proba.append(proba_softmax[2])\n",
    "            labels_3_rank.append(ranks[2])\n",
    "\n",
    "            count += 1\n",
    "        \n",
    "    # Convert to numpy\n",
    "    features_1 = torch.stack(features_1).float()\n",
    "    features_2 = torch.stack(features_2).float()\n",
    "    features_3 = torch.stack(features_3).float()\n",
    "    labels_1_proba = torch.stack(labels_1_proba).float()\n",
    "    labels_1_rank = torch.tensor(labels_1_rank)\n",
    "    labels_2_proba = torch.stack(labels_2_proba).float()\n",
    "    labels_2_rank = torch.tensor(labels_2_rank)\n",
    "    labels_3_proba = torch.stack(labels_3_proba).float()\n",
    "    labels_3_rank = torch.tensor(labels_3_rank)\n",
    "\n",
    "    return features_1, features_2, features_3,\\\n",
    "        labels_1_proba, labels_1_rank, labels_2_proba, labels_2_rank, labels_3_proba, labels_3_rank,\\\n",
    "            smiles_1, smiles_2, smiles_3\n",
    "\n",
    "features_1, features_2, features_3,\\\n",
    "        labels_1_proba, labels_1_rank, labels_2_proba, labels_2_rank, labels_3_proba, labels_3_rank,\\\n",
    "            smiles_1, smiles_2, smiles_3 =\\\n",
    "    generate_pairs_labels(features, proba_molecules, smiles_list, num_sets=len(smiles_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2573000.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculation for choosing 3 elements from 240\n",
    "import math\n",
    "def comb(n, k):\n",
    "    return math.factorial(n) / (math.factorial(k) * math.factorial(n-k))\n",
    "num_ways_125 = comb(250, 3)\n",
    "num_ways_125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 2048])\n",
      "torch.Size([240, 2048])\n",
      "torch.Size([240, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(features_1.shape)\n",
    "print(features_2.shape)\n",
    "print(features_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Why is test_size very high here?\n",
    "# This is because we are using active learning later\n",
    "# Where the Human in the loop process would generate more better training data for the model\n",
    "# So the amount of training data to train the initial model is not important, as the model should not be better than random guess\n",
    "\n",
    "features_1_train, features_1_test,\\\n",
    "    features_2_train, features_2_test,\\\n",
    "    features_3_train, features_3_test,\\\n",
    "    labels_1_proba_train, labels_1_proba_test,\\\n",
    "    labels_1_rank_train, labels_1_rank_test,\\\n",
    "    labels_2_proba_train, labels_2_proba_test,\\\n",
    "    labels_2_rank_train, labels_2_rank_test,\\\n",
    "    labels_3_proba_train, labels_3_proba_test,\\\n",
    "    labels_3_rank_train, labels_3_rank_test,\\\n",
    "    smiles_1_train, smiles_1_test,\\\n",
    "    smiles_2_train, smiles_2_test,\\\n",
    "    smiles_3_train, smiles_3_test\\\n",
    "            = train_test_split(features_1, features_2, features_3, \n",
    "                                 labels_1_proba, labels_1_rank, labels_2_proba, labels_2_rank, labels_3_proba, labels_3_rank,\n",
    "                                    smiles_1, smiles_2, smiles_3, test_size=0.9, random_state=42)\n",
    "\n",
    "# Now we need to save them \n",
    "\n",
    "small_drd2_training_data = pd.DataFrame()\n",
    "small_drd2_training_data['smiles_1'] = smiles_1_train\n",
    "small_drd2_training_data['smiles_2'] = smiles_2_train\n",
    "small_drd2_training_data['smiles_3'] = smiles_3_train\n",
    "small_drd2_training_data['label_1_proba'] = labels_1_proba_train\n",
    "small_drd2_training_data['label_2_proba'] = labels_2_proba_train\n",
    "small_drd2_training_data['label_3_proba'] = labels_3_proba_train\n",
    "small_drd2_training_data['label_1_rank'] = labels_1_rank_train\n",
    "small_drd2_training_data['label_2_rank'] = labels_2_rank_train\n",
    "small_drd2_training_data['label_3_rank'] = labels_3_rank_train\n",
    "\n",
    "small_drd2_training_data.to_csv(\"small_drd2_training_data.csv\", index=False)\n",
    "\n",
    "small_drd2_testing_data = pd.DataFrame()\n",
    "small_drd2_testing_data['smiles_1'] = smiles_1_test\n",
    "small_drd2_testing_data['smiles_2'] = smiles_2_test\n",
    "small_drd2_testing_data['smiles_3'] = smiles_3_test\n",
    "small_drd2_testing_data['label_1_proba'] = labels_1_proba_test\n",
    "small_drd2_testing_data['label_2_proba'] = labels_2_proba_test\n",
    "small_drd2_testing_data['label_3_proba'] = labels_3_proba_test\n",
    "small_drd2_testing_data['label_1_rank'] = labels_1_rank_test\n",
    "small_drd2_testing_data['label_2_rank'] = labels_2_rank_test\n",
    "small_drd2_testing_data['label_3_rank'] = labels_3_rank_test\n",
    "\n",
    "small_drd2_testing_data.to_csv(\"small_drd2_testing_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.4451767957458895e-05\n",
      "Model trained and saved\n"
     ]
    }
   ],
   "source": [
    "from rank_listnet import RankListNetModel\n",
    "    \n",
    "# Training the model\n",
    "model = RankListNetModel(feature_dim=2048)\n",
    "\n",
    "# When using Binary Cross-Entropy Loss (BCELoss) in neural networks, the input expected by the \n",
    "# loss function is a list of probabilities, not binary values (0 or 1)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# Correct Usage of KLDivLoss\n",
    "# Model Outputs: Should be log-probabilities.\n",
    "# True Labels: Should be probabilities.\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create torch data loader\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming X_train and y_train are numpy arrays, convert them to PyTorch tensors\n",
    "features_1_train_tensor = torch.tensor(features_1_train).float()  \n",
    "features_2_train_tensor = torch.tensor(features_2_train).float()\n",
    "features_3_train_tensor = torch.tensor(features_3_train).float()\n",
    "labels_1_proba_train_tensor = torch.tensor(labels_1_proba_train).float()\n",
    "labels_2_proba_train_tensor = torch.tensor(labels_2_proba_train).float()\n",
    "labels_3_proba_train_tensor = torch.tensor(labels_3_proba_train).float()\n",
    "\n",
    "features_1_test_tensor = torch.tensor(features_1_test).float()\n",
    "features_2_test_tensor = torch.tensor(features_2_test).float()\n",
    "features_3_test_tensor = torch.tensor(features_3_test).float()\n",
    "labels_1_proba_test_tensor = torch.tensor(labels_1_proba_test).float()\n",
    "labels_2_proba_test_tensor = torch.tensor(labels_2_proba_test).float()\n",
    "labels_3_proba_test_tensor = torch.tensor(labels_3_proba_test).float()\n",
    "\n",
    "# Create a TensorDataset\n",
    "train_dataset = TensorDataset(features_1_train_tensor, features_2_train_tensor, \n",
    "                              features_3_train_tensor, labels_1_proba_train_tensor,\n",
    "                                labels_2_proba_train_tensor, labels_3_proba_train_tensor)\n",
    "              \n",
    "test_dataset = TensorDataset(features_1_test_tensor, features_2_test_tensor,\n",
    "                                features_3_test_tensor, labels_1_proba_test_tensor,\n",
    "                                    labels_2_proba_test_tensor, labels_3_proba_test_tensor)\n",
    "\n",
    "# Create a DataLoader\n",
    "batch_size = 64  # You can adjust the batch size as needed\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def train(model, train_loader, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features_1, features_2, features_3, labels_proba_1, labels_proba_2, labels_proba_3 in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            ranking_scores = model(features_1, features_2, features_3) # softmax scores\n",
    "            true_label = torch.stack([labels_proba_1, labels_proba_2, labels_proba_3], dim=1)\n",
    "            softmax_label = torch.softmax(true_label, dim=1) # true labels should also be softmax\n",
    "\n",
    "            # Add a small epsilon to avoid log(0)\n",
    "            epsilon = 1e-9\n",
    "            ranking_scores = ranking_scores + epsilon\n",
    "\n",
    "            # Taking the logs of the ranking scores\n",
    "            log_ranking_scores = torch.log(ranking_scores)  \n",
    "            \n",
    "            # As we see softmax_label is not log\n",
    "            loss = criterion(log_ranking_scores, softmax_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(features)}')\n",
    "\n",
    "train(model, train_loader)\n",
    "\n",
    "# save state dict\n",
    "torch.save(model.state_dict(), \"rank_listnet_model.pth\")\n",
    "\n",
    "print(\"Model trained and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform prediction on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef\n",
    "\n",
    "def compute_metrics(labels, predictions):\n",
    "    num_classes = labels.shape[1]\n",
    "    class_metrics = {}\n",
    "\n",
    "    for i in range(0, num_classes):\n",
    "        # Selecting each class: True for the current class, False for the others\n",
    "        true_class = labels[:, i]\n",
    "        pred_class = predictions[:, i]\n",
    "\n",
    "        # Confusion matrix for the current class\n",
    "        cm = confusion_matrix(true_class, pred_class)\n",
    "        \n",
    "        # Calculate each metric\n",
    "        accuracy = accuracy_score(true_class, pred_class)\n",
    "        precision = precision_score(true_class, pred_class, average=\"weighted\")\n",
    "        recall = recall_score(true_class, pred_class, average=\"weighted\")\n",
    "        f1 = f1_score(true_class, pred_class, average=\"weighted\")\n",
    "        mcc = matthews_corrcoef(true_class, pred_class)\n",
    "\n",
    "        # Store metrics for the current class\n",
    "        class_metrics[f'Rank {i+1}'] = {\n",
    "            'Confusion Matrix': cm,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'MCC': mcc\n",
    "        }\n",
    "\n",
    "    return class_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Rank 1\n",
      "{'Confusion Matrix': array([[38, 17, 16],\n",
      "       [23, 23, 20],\n",
      "       [ 9, 30, 40]]), 'Accuracy': 0.4675925925925926, 'Precision': 0.4713311055416318, 'Recall': 0.4675925925925926, 'F1 Score': 0.469292715306718, 'MCC': 0.20039302718898558}\n",
      "Metrics for Rank 2\n",
      "{'Confusion Matrix': array([[21, 26, 24],\n",
      "       [21, 25, 21],\n",
      "       [32, 14, 32]]), 'Accuracy': 0.3611111111111111, 'Precision': 0.3626549251549252, 'Recall': 0.3611111111111111, 'F1 Score': 0.3618090589494, 'MCC': 0.03973061935191471}\n",
      "Metrics for Rank 3\n",
      "{'Confusion Matrix': array([[28, 38,  8],\n",
      "       [35, 32, 16],\n",
      "       [ 9, 11, 39]]), 'Accuracy': 0.4583333333333333, 'Precision': 0.4541282905480436, 'Recall': 0.4583333333333333, 'F1 Score': 0.4559959121374281, 'MCC': 0.18188926125547827}\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = RankListNetModel(feature_dim=2048)\n",
    "\n",
    "# Load the state dict\n",
    "model.load_state_dict(torch.load(\"rank_listnet_model.pth\"))\n",
    "\n",
    "# Finally we perform prediction\n",
    "model.eval()\n",
    "\n",
    "prediction_rank_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features_1, features_2, features_3, labels_proba_1, labels_proba_2, labels_proba_3 in test_loader:\n",
    "        ranking_scores = model(features_1, features_2, features_3) # shape (batch_size, 3)\n",
    "        \n",
    "        # print(outputs.shape)\n",
    "        true_rankings = torch.argsort(ranking_scores, dim=1) + 1\n",
    "        \n",
    "        #print(output_rank)\n",
    "        prediction_rank_test.extend(true_rankings)\n",
    "\n",
    "prediction_rank_test = torch.stack(prediction_rank_test).numpy()\n",
    "labels_rank_test = np.stack([labels_1_rank_test, labels_2_rank_test, labels_3_rank_test]).T\n",
    "# print(prediction_rank_test.shape)\n",
    "# print(labels_rank_test.shape)\n",
    "metrics = compute_metrics(labels_rank_test, prediction_rank_test)\n",
    "\n",
    "for rank in metrics:\n",
    "    print(f\"Metrics for {rank}\")\n",
    "    print(metrics[rank])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model performs weakly, which means that we can now use this model as a human component for HITL. Ideally, the initial model should be no better than random guess"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
