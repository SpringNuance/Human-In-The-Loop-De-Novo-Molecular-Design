{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Please run this code with the kernel reinvent.v3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dependencies\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rdkit.Chem as Chem\n",
    "from numpy.random import default_rng\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from torch import nn, optim\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from tdc import Oracle\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we need to install the custom reinvent scoring package to support the Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:57:50) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "# print python version\n",
    "import sys\n",
    "\n",
    "# Print Python version\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: reinvent-scoring\n",
      "Version: 0.0.73\n",
      "Summary: Scoring functions for Reinvent\n",
      "Home-page: https://github.com/MolecularAI/reinvent-scoring.git\n",
      "Author: MolecularAI\n",
      "Author-email: patronov@gmail.com\n",
      "License: UNKNOWN\n",
      "Location: /home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "! pip show reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install scikit-learn=0.21.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If there already exists reinvent_scoring, we should uninstall it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: reinvent-scoring 0.0.73\n",
      "Uninstalling reinvent-scoring-0.0.73:\n",
      "  Successfully uninstalled reinvent-scoring-0.0.73\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y reinvent_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we install the custom reinvent scoring package\n",
    "##### The flag -e means that the package is installed in editable mode, so that changes to the code will be immediately available without reinstalling the package. All package info is stored in the setup.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-chemistry\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-chemistry\n",
      "  Attempting uninstall: reinvent-chemistry\n",
      "    Found existing installation: reinvent-chemistry 0.0.51\n",
      "    Uninstalling reinvent-chemistry-0.0.51:\n",
      "      Successfully uninstalled reinvent-chemistry-0.0.51\n",
      "  Running setup.py develop for reinvent-chemistry\n",
      "Successfully installed reinvent-chemistry-0.0.51\n",
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-models\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-models\n",
      "  Attempting uninstall: reinvent-models\n",
      "    Found existing installation: reinvent-models 0.0.15rc1\n",
      "    Uninstalling reinvent-models-0.0.15rc1:\n",
      "      Successfully uninstalled reinvent-models-0.0.15rc1\n",
      "  Running setup.py develop for reinvent-models\n",
      "Successfully installed reinvent-models-0.0.15rc1\n"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-chemistry\"\n",
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install -y scikit-learn=0.21.3\n",
    "! pip list | grep reinvent_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_Bradley_Terry_model.bradley_terry import BradleyTerryModel\n",
    "from training_Rank_ListNet_model.rank_listnet import RankListNetModel\n",
    "from training_Score_Regression_model.score_regression import ScoreRegressionModel\n",
    "from helper import load_drd2_dataset, write_REINVENT_config, change_config_json, \\\n",
    "                    read_scaffold_result, load_feedback_model, smiles_human_score, \\\n",
    "                    compute_fingerprints, retrain_feedback_model,\\\n",
    "                    create_drd2_dataset, combine_drd2_dataset, save_drd2_dataset\n",
    "                        \n",
    "from scripts.acquisition import select_query_feedback\n",
    "\n",
    "def check_create(path):\n",
    "    \"\"\"\n",
    "    Check if the directory exists, if not, create it.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir, \n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps. This is not related to the HITL but on the REINVENT side\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    "        training_epochs # number of epochs for training the model in each HITL iteration\n",
    "        ):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    rng = default_rng(seed)\n",
    "    \n",
    "    ################################################\n",
    "    # DEFINING REINVENT JOBNAME, JOBID, OUTPUT_DIR #\n",
    "    ################################################\n",
    "\n",
    "    jobname = \"fine-tune predictive component HITL\"\n",
    "    jobid = output_dir\n",
    "    conf_filename = \"config.json\"\n",
    "\n",
    "    # create root output dir\n",
    "    check_create(output_dir)\n",
    "\n",
    "    # create HITL round folders to store results\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "        check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}\")\n",
    "        for HITL_iteration in range(1, num_iters + 1):\n",
    "            check_create(f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration}\")\n",
    "    \n",
    "    # Copy the pretrained model to the first REINVENT round/ HITL_iteration_1\n",
    "    shutil.copy2(f\"{model_pretrained_path}\", f\"{output_dir}/REINVENT_round_1/HITL_iteration_1\")\n",
    "\n",
    "    # multi-parameter optimization (MPO) loop\n",
    "    print(f\"\\nRunning DRD2 (one objective) with rounds {num_rounds}, iters {num_iters}, queries {num_queries}, seed {seed}\")\n",
    "    print(f\"Results will be saved at {output_dir}\")\n",
    "    \n",
    "    base_training_dataset_outputs = load_drd2_dataset(feedback_type=feedback_type, \n",
    "                                                 data_path=base_training_dataset_path)\n",
    "\n",
    "    \n",
    "    print(\"Loading initial training and testing datasets successfully\")\n",
    "\n",
    "    # ########################### REINVENT rounds ######################################\n",
    "\n",
    "    for REINVENT_round in range(1, num_rounds + 1):\n",
    "\n",
    "        print(\"=====================================\")\n",
    "        print(f\"REINVENT round = {REINVENT_round}\")\n",
    "\n",
    "        REINVENT_round_output_dir = f\"{output_dir}/REINVENT_round_{REINVENT_round}\"\n",
    "        \n",
    "        configuration_JSON_path = write_REINVENT_config(feedback_type, reinvent_dir, jobid, jobname, \n",
    "                                                        REINVENT_round_output_dir, conf_filename)\n",
    "\n",
    "        print(f\"Creating config file: {configuration_JSON_path}.\")\n",
    "\n",
    "        configuration = json.load(open(f\"{configuration_JSON_path}\"))\n",
    "\n",
    "        current_model_path = f\"{REINVENT_round_output_dir}/HITL_iteration_1/{model_pretrained_name}\"\n",
    "\n",
    "        configuration = change_config_json(configuration, REINVENT_n_steps, batch_size, current_model_path)\n",
    "\n",
    "        # write the updated configuration file \n",
    "\n",
    "        with open(configuration_JSON_path, 'w') as f:\n",
    "            json.dump(configuration, f, indent=4, sort_keys=True)\n",
    "    \n",
    "        print(\"Run REINVENT\")                \n",
    "        command = f\"{reinvent_env}/bin/python\"\n",
    "        script = f\"{reinvent_dir}/input.py\"\n",
    "        stderr_file = f\"{REINVENT_round_output_dir}/run.err\"\n",
    "        stdout_file = f\"{REINVENT_round_output_dir}/run.out\"\n",
    "\n",
    "        # Construct the full command to run\n",
    "        cmd = [command, script, configuration_JSON_path]\n",
    "        # Open the file to which you want to redirect stderr and stdout\n",
    "        with open(stderr_file, 'w') as ferr, open(stdout_file, 'w') as fout:\n",
    "            # Execute the command\n",
    "            result = subprocess.run(cmd, text=True, stdout=fout, stderr=ferr)\n",
    "        # Check the result\n",
    "        print(\"Exit code:\", result.returncode)\n",
    "        \n",
    "        #############################################################################\n",
    "        # REINVENT HAS OUTPUT THE RESULT in path f\"{REINVENT_round_output_dir}/results\" #\n",
    "        #############################################################################\n",
    "        \n",
    "        # Get the high scoring molecules\n",
    "        output_high_score = read_scaffold_result(f\"{REINVENT_round_output_dir}/results/scaffold_memory.csv\", \n",
    "                                                 choose_top_smiles=choose_top_smiles)\n",
    "        \n",
    "        scaffold_df = output_high_score[\"scaffold_df\"]\n",
    "        smiles = output_high_score[\"smiles\"]\n",
    "        \n",
    "        # store molecule indexes selected for feedback\n",
    "        selected_feedback = np.empty(0).astype(int)\n",
    "\n",
    "        ########################### HITL_iteration in each REINVENT round #####################\n",
    "        \n",
    "        for HITL_iteration in range(1, num_iters + 1): # T number of HITL_iterations\n",
    "\n",
    "            print(\"----------------------------------\")\n",
    "            print(f\"HITL iteration = {HITL_iteration}\")\n",
    "            \n",
    "            # Loading feedback model\n",
    "            feedback_model_path = f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/{model_pretrained_name}\"\n",
    "            feedback_model = load_feedback_model(feedback_type, feedback_model_path)\n",
    "            \n",
    "            ######################################################## \n",
    "            # Select queries number of smiles with Active Learning #\n",
    "            ########################################################\n",
    "\n",
    "            if len(smiles) > num_queries:\n",
    "                new_queried_smiles_indices = select_query_feedback(feedback_type, feedback_model, \n",
    "                                                  scaffold_df, num_queries, list(smiles), \n",
    "                                                  selected_feedback, acquisition, rng) \n",
    "            else:\n",
    "                new_queried_smiles_indices = select_query_feedback(feedback_type, feedback_model, \n",
    "                                                  scaffold_df, len(smiles), list(smiles), \n",
    "                                                  selected_feedback, acquisition, rng)\n",
    "            \n",
    "            print(f\"Feedback idx at HITL iteration {HITL_iteration}: {new_queried_smiles_indices}\")\n",
    "            \n",
    "            new_queried_smiles = [smiles[i] for i in new_queried_smiles_indices]\n",
    "  \n",
    "            selected_feedback = np.hstack((selected_feedback, new_queried_smiles_indices))\n",
    "\n",
    "            new_queried_smiles_human_score = smiles_human_score(new_queried_smiles, sigma_noise)\n",
    "            \n",
    "            print(f\"Human score at HITL iteration {HITL_iteration}: {new_queried_smiles_human_score}\")\n",
    "            \n",
    "            # use the augmented training data to retrain the model\n",
    "            new_queried_fps = np.array([compute_fingerprints(smiles) for smiles in new_queried_smiles])\n",
    "\n",
    "            iteration_training_dataset_outputs = create_drd2_dataset(feedback_type, \n",
    "                                                                      new_queried_smiles, \n",
    "                                                                      new_queried_smiles_human_score,\n",
    "                                                                      new_queried_fps)\n",
    "            \n",
    "            if feedback_type == \"scoring\":\n",
    "                print(f\"New queried dataset size: {len(iteration_training_dataset_outputs['smiles'])}\")\n",
    "            else:\n",
    "                print(f\"New queried dataset size: {len(iteration_training_dataset_outputs['smiles_1'])}\")\n",
    "            \n",
    "            # combining the base training dataset with the new queried dataset\n",
    "            base_training_dataset_outputs = combine_drd2_dataset(feedback_type, base_training_dataset_outputs, \n",
    "                                                                   iteration_training_dataset_outputs)\n",
    "            \n",
    "            if feedback_type == \"scoring\":\n",
    "                print(f\"Combined dataset size: {len(base_training_dataset_outputs['smiles'])}\")\n",
    "            else:\n",
    "                print(f\"Combined dataset size: {len(base_training_dataset_outputs['smiles_1'])}\")\n",
    "            \n",
    "            # save augmented training data\n",
    "            save_drd2_dataset(feedback_type, iteration_training_dataset_outputs, f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_queried_data.csv\")\n",
    "            save_drd2_dataset(feedback_type, base_training_dataset_outputs, f\"{REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_combined_data.csv\")\n",
    "            \n",
    "            print(f\"Saved augmented training data at {REINVENT_round_output_dir}/HITL_iteration_{HITL_iteration}/iteration_combined_data.csv\")\n",
    "            \n",
    "            # Retraining the feedback model using the augmented train set\n",
    "            retrained_feedback_model = retrain_feedback_model(feedback_type, feedback_model, \n",
    "                                                              base_training_dataset_outputs,\n",
    "                                                              training_epochs)\n",
    "            \n",
    "            if REINVENT_round != num_rounds:\n",
    "                if HITL_iteration < num_iters:\n",
    "                    # Moving on to the next iteration at the current round\n",
    "                    feedback_model_saving_path = f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration + 1}/{model_pretrained_name}\"\n",
    "                    torch.save(retrained_feedback_model.state_dict(), feedback_model_saving_path)\n",
    "                else:\n",
    "                    # Moving to the first iteration at the next round\n",
    "                    feedback_model_saving_path = f\"{output_dir}/REINVENT_round_{REINVENT_round + 1}/HITL_iteration_1/{model_pretrained_name}\"\n",
    "                    torch.save(retrained_feedback_model.state_dict(), feedback_model_saving_path)\n",
    "            else:\n",
    "                if HITL_iteration < num_iters:\n",
    "                    # Moving on to the next iteration at the current round\n",
    "                    feedback_model_saving_path = f\"{output_dir}/REINVENT_round_{REINVENT_round}/HITL_iteration_{HITL_iteration + 1}/{model_pretrained_name}\"\n",
    "                    torch.save(retrained_feedback_model.state_dict(), feedback_model_saving_path)\n",
    "                else:\n",
    "                    # Last iteration at the last round, we save to the final model\n",
    "                    feedback_model_saving_path = f\"{output_dir}/final_{model_pretrained_name}\"\n",
    "                    torch.save(retrained_feedback_model.state_dict(), feedback_model_saving_path)\n",
    "\n",
    "            print(f\"Saved retrained feedback model at {feedback_model_saving_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/springnuance/reinvent-hitl/Base-Code-Binh\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running score regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'run_HITL_classify' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-50c27f938652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"output_score_regression_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_s{sigma_noise}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m run_HITL_classify(\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinvent_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreinvent_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mfeedback_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# scoring, comparing, ranking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run_HITL_classify' is not defined"
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = \"/home/springnuance/reinvent-hitl/Reinvent\" # We must use absolute path\n",
    "reinvent_env = \"/home/springnuance/miniconda3/envs/ReinventCommunity\" # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"scoring\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as scoring:\n",
    "# Given a molecule, what is the probability that the molecule is active regarding DRD2?  \n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Score_Regression_model/score_regression_model.pth\"\n",
    "model_pretrained_name = \"score_regression_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 50 # number of REINVENT optimization steps\n",
    "batch_size = 256 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"greedy\" # acquisition: 'random', 'uncertainty', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.1 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "\n",
    "choose_top_smiles = 50 # number of top molecules to choose from scaffold. \n",
    "\n",
    "training_epochs = 5 # number of epochs for training the model in each HITL iteration\n",
    "\n",
    "output_dir = f\"output_score_regression_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_s{sigma_noise}\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    "        training_epochs, # number of epochs for training the model in each HITL iteration\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Bradley Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "\n",
      "Running DRD2 (one objective) with rounds 2, iters 3, queries 10, seed 42\n",
      "Results will be saved at output_bradley_terry_R2_T3_Q10_random_s0.1\n",
      "Loading initial training and testing datasets successfully\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: output_bradley_terry_R2_T3_Q10_random_s0.1/REINVENT_round_1/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  124\n",
      "----------------------------------\n",
      "HITL iteration = 1\n",
      "Loading Bradley Terry model successfully from output_bradley_terry_R2_T3_Q10_random_s0.1/REINVENT_round_1/HITL_iteration_1/bradley_terry_model.pth\n",
      "Feedback idx at HITL iteration 1: [96 71  8 60 41 94 68  9 19 82]\n",
      "Human score at HITL iteration 1: [0.07038732416895124, 0.0, 0.06710522471843096, 0.15469819153594322, 0.0, 0.0, 0.15811997926963975, 0.07932702198016026, 0.6791328819885362, 0.055336551097420125]\n",
      "New queried dataset size: 45\n",
      "Combined dataset size: 69\n",
      "Saved augmented training data at output_bradley_terry_R2_T3_Q10_random_s0.1/REINVENT_round_1/HITL_iteration_1/iteration_combined_data.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c6b964484b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0msigma_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# noise level for simulated chemist's responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mchoose_top_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of top scoring molecules to choose for feedback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of epochs for training the model in each HITL iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-11-7bbb64ed65ca>\u001b[0m in \u001b[0;36mrun_HITL_classify\u001b[0;34m(seed, reinvent_dir, reinvent_env, output_dir, feedback_type, base_training_dataset_path, base_testing_dataset_path, model_pretrained_path, model_pretrained_name, num_rounds, num_iters, num_queries, REINVENT_n_steps, batch_size, acquisition, sigma_noise, choose_top_smiles, training_epochs)\u001b[0m\n\u001b[1;32m    187\u001b[0m             retrained_feedback_model = retrain_feedback_model(feedback_type, feedback_model, \n\u001b[1;32m    188\u001b[0m                                                               \u001b[0mbase_training_dataset_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                                                               training_epochs)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mREINVENT_round\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnum_rounds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/reinvent-hitl/Base-Code-Binh/helper.py\u001b[0m in \u001b[0;36mretrain_feedback_model\u001b[0;34m(feedback_type, feedback_model, training_outputs, epochs)\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeedback_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                    \n",
    "# change these path variables as required\n",
    "reinvent_dir = \"/home/springnuance/reinvent-hitl/Reinvent\" # We must use absolute path\n",
    "reinvent_env = \"/home/springnuance/miniconda3/envs/ReinventCommunity\" # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"comparing\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as comparing:\n",
    "# Given two molecules, what is the probability that the first molecule is more active than the second molecule regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Bradley_Terry_model/bradley_terry_model.pth\"\n",
    "model_pretrained_name = \"bradley_terry_model.pth\"\n",
    "\n",
    "num_rounds = 2 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 3 # number of iterations of showing molecules to the human for feedback at each round\n",
    "\n",
    "REINVENT_n_steps = 5 # number of REINVENT optimization steps\n",
    "batch_size = 32 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"random\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.1 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 10 # number of molecules, pairs or a set of molecules, dependig on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "choose_top_smiles = 100 # number of top molecules to choose from scaffold. \n",
    "\n",
    "training_epochs = 5 # number of epochs for training the model in each HITL iteration\n",
    "\n",
    "output_dir = f\"output_bradley_terry_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_s{sigma_noise}\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir,\n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of molecules shown at each HITL_iteration to the human for feedback, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top scoring molecules to choose for feedback\n",
    "        training_epochs, # number of epochs for training the model in each HITL iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Rank ListNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///home/springnuance/reinvent-hitl/reinvent-scoring\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: reinvent-scoring\n",
      "  Attempting uninstall: reinvent-scoring\n",
      "    Found existing installation: reinvent-scoring 0.0.73\n",
      "    Uninstalling reinvent-scoring-0.0.73:\n",
      "      Successfully uninstalled reinvent-scoring-0.0.73\n",
      "  Running setup.py develop for reinvent-scoring\n",
      "Successfully installed reinvent-scoring-0.0.73\n",
      "\n",
      "Running DRD2 (one objective) with rounds 10, iters 5, queries 20, seed 42\n",
      "Results will be saved at output_rank_listnet_R10_T5_Q20_random_s0.0\n",
      "Loading initial training and testing datasets successfully\n",
      "=====================================\n",
      "REINVENT round = 1\n",
      "Creating config file: output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  785\n",
      "----------------------------------\n",
      "HITL iteration = 1\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_1/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 1: [140 139  38 187 167 147  25  16 119 101 184 186  90 159  17 142 154  80\n",
      " 131 100]\n",
      "Human score at HITL iteration 1: [0.9542954948344743, 0.0007585751838657166, 0.005540676267494359, 0.09403863127628723, 0.0005101371629612877, 0.013774972117641537, 0.029814977165815697, 0.016238625203295918, 0.33938953299934427, 0.000276966127419286, 0.01033759570646093, 0.01858239063911722, 0.028733176897448576, 0.006037345870299654, 0.01802089221013777, 0.0016668209762802162, 0.012454092941693409, 0.001028840726939133, 0.005633241529576334, 0.0023144929840674695]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 1164\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_1/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 4.3293861381243914e-05\n",
      "Epoch 1, Loss: 5.805805994896218e-05\n",
      "Epoch 1, Loss: 6.381390267051756e-05\n",
      "Epoch 1, Loss: 6.628759729210287e-05\n",
      "Epoch 1, Loss: 7.081001967890188e-05\n",
      "Epoch 1, Loss: 7.456739695044234e-05\n",
      "Epoch 1, Loss: 7.733816892141476e-05\n",
      "Epoch 1, Loss: 8.246968354796991e-05\n",
      "Epoch 1, Loss: 8.377425547223538e-05\n",
      "Epoch 1, Loss: 8.60540458234027e-05\n",
      "Epoch 1, Loss: 8.764580707065761e-05\n",
      "Epoch 1, Loss: 8.904726564651355e-05\n",
      "Epoch 1, Loss: 9.066216443898156e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 9.281193342758343e-05\n",
      "Epoch 1, Loss: 9.437937114853412e-05\n",
      "Epoch 1, Loss: 9.523719927528873e-05\n",
      "Epoch 1, Loss: 9.571758710080758e-05\n",
      "Epoch 1, Loss: 9.665907418821007e-05\n",
      "Epoch 1, Loss: 0.0005180555034106268\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_2/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 2\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_2/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 2: [124 133  11 166  86 146 123  29  78  36 109  30 143  62   7  93 179 199\n",
      " 105  67]\n",
      "Human score at HITL iteration 2: [0.011835926908550665, 0.00038767474392169466, 0.030635647302016754, 0.0006883672019101086, 0.6083159306205319, 0.11450057743134232, 0.026277949463692673, 0.059476468414362625, 0.2900909327011289, 9.522609014828154e-05, 0.009053170570335325, 0.008518026765702336, 0.00887749090305092, 0.023517414962955962, 0.0016357207488963761, 0.0008416627766331858, 0.00942836456280312, 0.006947846507052678, 0.006912854208097962, 0.010390482848604658]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 2304\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_2/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.0773568646982312e-05\n",
      "Epoch 1, Loss: 1.4886114513501525e-05\n",
      "Epoch 1, Loss: 1.704580063233152e-05\n",
      "Epoch 1, Loss: 1.8823375285137445e-05\n",
      "Epoch 1, Loss: 2.0163650333415717e-05\n",
      "Epoch 1, Loss: 2.170002699131146e-05\n",
      "Epoch 1, Loss: 2.250414399895817e-05\n",
      "Epoch 1, Loss: 2.314002631464973e-05\n",
      "Epoch 1, Loss: 2.376642805757001e-05\n",
      "Epoch 1, Loss: 2.4127482902258635e-05\n",
      "Epoch 1, Loss: 2.453819615766406e-05\n",
      "Epoch 1, Loss: 2.5224398996215314e-05\n",
      "Epoch 1, Loss: 2.683947968762368e-05\n",
      "Epoch 1, Loss: 2.7216869057156146e-05\n",
      "Epoch 1, Loss: 2.7397160010877997e-05\n",
      "Epoch 1, Loss: 2.7699577913153917e-05\n",
      "Epoch 1, Loss: 2.7921363653149456e-05\n",
      "Epoch 1, Loss: 2.814449544530362e-05\n",
      "Epoch 1, Loss: 2.824321563821286e-05\n",
      "Epoch 1, Loss: 2.8547641704790294e-05\n",
      "Epoch 1, Loss: 2.8693393687717617e-05\n",
      "Epoch 1, Loss: 2.8863818442914635e-05\n",
      "Epoch 1, Loss: 2.8988644771743566e-05\n",
      "Epoch 1, Loss: 2.9083348636049777e-05\n",
      "Epoch 1, Loss: 2.9202376026660204e-05\n",
      "Epoch 1, Loss: 2.9330505640245974e-05\n",
      "Epoch 1, Loss: 2.9419992642942816e-05\n",
      "Epoch 1, Loss: 2.9816445021424443e-05\n",
      "Epoch 1, Loss: 2.9883303795941174e-05\n",
      "Epoch 1, Loss: 2.998307900270447e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.0040762794669718e-05\n",
      "Epoch 1, Loss: 3.033857501577586e-05\n",
      "Epoch 1, Loss: 3.0539551516994834e-05\n",
      "Epoch 1, Loss: 3.0586736102122813e-05\n",
      "Epoch 1, Loss: 3.0651994165964425e-05\n",
      "Epoch 1, Loss: 3.069406375288963e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_3/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 3\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_3/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 3: [ 18  54 115 155  71 175 152  47 112  28 126  55 144 158  95 134  73 163\n",
      " 169  77]\n",
      "Human score at HITL iteration 3: [0.038920079618572676, 0.015695640207131503, 0.0012488808788619508, 0.0005387039705822871, 0.024418029067050925, 0.00064007590052303, 0.007598157147197996, 0.019454175387893412, 0.0003409379768917956, 0.0024589959667501255, 0.005707544952711055, 0.04432963002249314, 0.0001737636935651253, 0.023932733936565257, 6.0967955205673796e-05, 0.0007252894724127204, 0.00019109682999088359, 0.4320631437351854, 0.023113757618655365, 0.0018650566207918265]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 3444\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_3/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.569307642057538e-06\n",
      "Epoch 1, Loss: 3.5696648410521448e-06\n",
      "Epoch 1, Loss: 4.039051418658346e-06\n",
      "Epoch 1, Loss: 4.890272975899279e-06\n",
      "Epoch 1, Loss: 5.307338142301887e-06\n",
      "Epoch 1, Loss: 5.82714710617438e-06\n",
      "Epoch 1, Loss: 6.2604667618870735e-06\n",
      "Epoch 1, Loss: 6.691312592010945e-06\n",
      "Epoch 1, Loss: 6.996582669671625e-06\n",
      "Epoch 1, Loss: 7.328912033699453e-06\n",
      "Epoch 1, Loss: 7.49689934309572e-06\n",
      "Epoch 1, Loss: 7.746260962449014e-06\n",
      "Epoch 1, Loss: 7.968104910105467e-06\n",
      "Epoch 1, Loss: 8.121380233205855e-06\n",
      "Epoch 1, Loss: 8.250790415331721e-06\n",
      "Epoch 1, Loss: 8.337017789017409e-06\n",
      "Epoch 1, Loss: 8.417810022365302e-06\n",
      "Epoch 1, Loss: 8.513103239238262e-06\n",
      "Epoch 1, Loss: 8.598690328653902e-06\n",
      "Epoch 1, Loss: 9.45976353250444e-06\n",
      "Epoch 1, Loss: 9.551426046527922e-06\n",
      "Epoch 1, Loss: 9.689043508842587e-06\n",
      "Epoch 1, Loss: 9.882227459456772e-06\n",
      "Epoch 1, Loss: 1.0011324775405228e-05\n",
      "Epoch 1, Loss: 1.0126008419319987e-05\n",
      "Epoch 1, Loss: 1.032183354254812e-05\n",
      "Epoch 1, Loss: 1.0698146070353687e-05\n",
      "Epoch 1, Loss: 1.0810792446136475e-05\n",
      "Epoch 1, Loss: 1.0971787560265511e-05\n",
      "Epoch 1, Loss: 1.1054165952373296e-05\n",
      "Epoch 1, Loss: 1.1106356396339834e-05\n",
      "Epoch 1, Loss: 1.1180432920809835e-05\n",
      "Epoch 1, Loss: 1.122232060879469e-05\n",
      "Epoch 1, Loss: 1.1315947631374002e-05\n",
      "Epoch 1, Loss: 1.1787669791374356e-05\n",
      "Epoch 1, Loss: 1.1816315236501396e-05\n",
      "Epoch 1, Loss: 1.1866140994243324e-05\n",
      "Epoch 1, Loss: 1.1906966392416507e-05\n",
      "Epoch 1, Loss: 1.195006916532293e-05\n",
      "Epoch 1, Loss: 1.2013493687845767e-05\n",
      "Epoch 1, Loss: 1.2071308447048068e-05\n",
      "Epoch 1, Loss: 1.2132259143982083e-05\n",
      "Epoch 1, Loss: 1.2182477803435177e-05\n",
      "Epoch 1, Loss: 1.2251337466295809e-05\n",
      "Epoch 1, Loss: 1.2274824257474393e-05\n",
      "Epoch 1, Loss: 1.2316275388002396e-05\n",
      "Epoch 1, Loss: 1.2329393939580768e-05\n",
      "Epoch 1, Loss: 1.2426055036485195e-05\n",
      "Epoch 1, Loss: 1.2439893907867372e-05\n",
      "Epoch 1, Loss: 1.2477779819164425e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2517819413915277e-05\n",
      "Epoch 1, Loss: 1.2538061127997935e-05\n",
      "Epoch 1, Loss: 1.2637079635169357e-05\n",
      "Epoch 1, Loss: 1.558479536137943e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_4/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 4\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_4/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 4: [ 97  12  14  56  99  40 192 102 196  19 198 138 114 111 113  70 103 157\n",
      "  79  21]\n",
      "Human score at HITL iteration 4: [0.17309724522279868, 0.00043325890630916954, 0.5378792533974456, 0.0101685600140103, 0.37199252299450686, 0.038691518493632567, 0.0054119920174428284, 0.003763831035210668, 0.0033591208029725827, 0.018090441804134712, 0.00031015422318228926, 0.004892617566822852, 0.3761756441050509, 0.02149562392181323, 0.7266077037500958, 0.010599348814571087, 7.438445718548502e-05, 0.0007535933041032912, 0.0018498740054620824, 0.00260542005066638]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 4584\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_4/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 4.452835128176957e-06\n",
      "Epoch 1, Loss: 6.2095350585877895e-06\n",
      "Epoch 1, Loss: 6.921203748788685e-06\n",
      "Epoch 1, Loss: 7.533672032877803e-06\n",
      "Epoch 1, Loss: 8.134578820317984e-06\n",
      "Epoch 1, Loss: 8.741801138967276e-06\n",
      "Epoch 1, Loss: 9.725896234158427e-06\n",
      "Epoch 1, Loss: 1.006574893835932e-05\n",
      "Epoch 1, Loss: 1.0445532097946852e-05\n",
      "Epoch 1, Loss: 1.0848678357433528e-05\n",
      "Epoch 1, Loss: 1.1091571650467813e-05\n",
      "Epoch 1, Loss: 1.1605712643358856e-05\n",
      "Epoch 1, Loss: 1.19643664220348e-05\n",
      "Epoch 1, Loss: 1.2652526493184268e-05\n",
      "Epoch 1, Loss: 1.3054872397333384e-05\n",
      "Epoch 1, Loss: 1.3270859199110419e-05\n",
      "Epoch 1, Loss: 1.3376265997067094e-05\n",
      "Epoch 1, Loss: 1.3641467376146466e-05\n",
      "Epoch 1, Loss: 1.3801931345369667e-05\n",
      "Epoch 1, Loss: 1.4064637070987374e-05\n",
      "Epoch 1, Loss: 1.4341960195451975e-05\n",
      "Epoch 1, Loss: 1.4690078387502581e-05\n",
      "Epoch 1, Loss: 1.4907040167599916e-05\n",
      "Epoch 1, Loss: 1.5018013073131442e-05\n",
      "Epoch 1, Loss: 1.5214325685519725e-05\n",
      "Epoch 1, Loss: 1.5350458852481097e-05\n",
      "Epoch 1, Loss: 1.539871300337836e-05\n",
      "Epoch 1, Loss: 1.5555058780591935e-05\n",
      "Epoch 1, Loss: 1.6020545444916934e-05\n",
      "Epoch 1, Loss: 1.6276724636554718e-05\n",
      "Epoch 1, Loss: 1.641795097384602e-05\n",
      "Epoch 1, Loss: 1.6521415091119707e-05\n",
      "Epoch 1, Loss: 1.6553036402910948e-05\n",
      "Epoch 1, Loss: 1.67138350661844e-05\n",
      "Epoch 1, Loss: 1.6909907571971416e-05\n",
      "Epoch 1, Loss: 1.7069134628400207e-05\n",
      "Epoch 1, Loss: 1.719642023090273e-05\n",
      "Epoch 1, Loss: 1.7325335647910833e-05\n",
      "Epoch 1, Loss: 1.7429323634132743e-05\n",
      "Epoch 1, Loss: 1.761641033226624e-05\n",
      "Epoch 1, Loss: 1.769373193383217e-05\n",
      "Epoch 1, Loss: 1.7763450159691274e-05\n",
      "Epoch 1, Loss: 1.783201878424734e-05\n",
      "Epoch 1, Loss: 1.7908540030475706e-05\n",
      "Epoch 1, Loss: 1.8064776668325067e-05\n",
      "Epoch 1, Loss: 1.81395371328108e-05\n",
      "Epoch 1, Loss: 1.8165010260418057e-05\n",
      "Epoch 1, Loss: 1.822621561586857e-05\n",
      "Epoch 1, Loss: 1.830791006796062e-05\n",
      "Epoch 1, Loss: 1.837078161770478e-05\n",
      "Epoch 1, Loss: 1.8503342289477587e-05\n",
      "Epoch 1, Loss: 1.8546139472164214e-05\n",
      "Epoch 1, Loss: 1.86294928425923e-05\n",
      "Epoch 1, Loss: 1.8670827557798475e-05\n",
      "Epoch 1, Loss: 1.877494651125744e-05\n",
      "Epoch 1, Loss: 1.8923543393611908e-05\n",
      "Epoch 1, Loss: 1.9024409994017333e-05\n",
      "Epoch 1, Loss: 1.932673330884427e-05\n",
      "Epoch 1, Loss: 1.94636668311432e-05\n",
      "Epoch 1, Loss: 1.9518440240062773e-05\n",
      "Epoch 1, Loss: 1.95694956346415e-05\n",
      "Epoch 1, Loss: 1.9629696907941252e-05\n",
      "Epoch 1, Loss: 1.9722676370292902e-05\n",
      "Epoch 1, Loss: 1.9789396901614964e-05\n",
      "Epoch 1, Loss: 1.98122434085235e-05\n",
      "Epoch 1, Loss: 1.985709968721494e-05\n",
      "Epoch 1, Loss: 1.992205943679437e-05\n",
      "Epoch 1, Loss: 2.001134998863563e-05\n",
      "Epoch 1, Loss: 2.0134168153163046e-05\n",
      "Epoch 1, Loss: 2.0229737856425345e-05\n",
      "Epoch 1, Loss: 2.026279253186658e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.263377816438151e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_5/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 5\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_5/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 5: [ 20  31 180   2 141  52  84  57 135  85 176 116 150  64  81  13  66 151\n",
      " 132 190]\n",
      "Human score at HITL iteration 5: [0.017053239791503652, 0.014559150434579064, 0.023105683837224614, 0.012811871001834927, 0.001076212635586073, 0.06650456390058648, 0.024076602195205417, 0.000330445465903566, 0.22872489551043132, 0.014275512750084452, 0.01209183126164367, 0.0380640496778885, 9.156529602969416e-05, 0.006864462645423188, 0.05350245785202419, 0.26752134692112883, 0.005040761919874857, 0.0013775080228978717, 0.0007275481423545311, 0.0031725928805782936]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 5724\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_1/HITL_iteration_5/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.340151356998831e-06\n",
      "Epoch 1, Loss: 2.4443434085696936e-06\n",
      "Epoch 1, Loss: 2.758242771960795e-06\n",
      "Epoch 1, Loss: 3.3856340451166034e-06\n",
      "Epoch 1, Loss: 3.913315595127642e-06\n",
      "Epoch 1, Loss: 4.123154212720692e-06\n",
      "Epoch 1, Loss: 4.2779065552167594e-06\n",
      "Epoch 1, Loss: 4.592817276716232e-06\n",
      "Epoch 1, Loss: 4.987647116649896e-06\n",
      "Epoch 1, Loss: 5.597059498541057e-06\n",
      "Epoch 1, Loss: 5.951871571596712e-06\n",
      "Epoch 1, Loss: 6.112495611887425e-06\n",
      "Epoch 1, Loss: 6.444701284635812e-06\n",
      "Epoch 1, Loss: 6.733585905749351e-06\n",
      "Epoch 1, Loss: 7.048365660011768e-06\n",
      "Epoch 1, Loss: 7.259681297000498e-06\n",
      "Epoch 1, Loss: 7.537892088294029e-06\n",
      "Epoch 1, Loss: 7.788788934703916e-06\n",
      "Epoch 1, Loss: 7.875692972447723e-06\n",
      "Epoch 1, Loss: 8.085036824923009e-06\n",
      "Epoch 1, Loss: 8.237664587795734e-06\n",
      "Epoch 1, Loss: 8.487229933962226e-06\n",
      "Epoch 1, Loss: 8.640505257062614e-06\n",
      "Epoch 1, Loss: 8.882918336894363e-06\n",
      "Epoch 1, Loss: 9.015202522277832e-06\n",
      "Epoch 1, Loss: 9.054900147020817e-06\n",
      "Epoch 1, Loss: 9.12428367882967e-06\n",
      "Epoch 1, Loss: 9.255119948647916e-06\n",
      "Epoch 1, Loss: 9.33113187784329e-06\n",
      "Epoch 1, Loss: 9.41369216889143e-06\n",
      "Epoch 1, Loss: 9.507653885520995e-06\n",
      "Epoch 1, Loss: 9.600749763194472e-06\n",
      "Epoch 1, Loss: 9.659117495175451e-06\n",
      "Epoch 1, Loss: 9.72444104263559e-06\n",
      "Epoch 1, Loss: 9.882453014142811e-06\n",
      "Epoch 1, Loss: 9.919254807755351e-06\n",
      "Epoch 1, Loss: 9.94897709460929e-06\n",
      "Epoch 1, Loss: 9.972492989618331e-06\n",
      "Epoch 1, Loss: 1.0031813872046769e-05\n",
      "Epoch 1, Loss: 1.0059702617581934e-05\n",
      "Epoch 1, Loss: 1.0103896784130484e-05\n",
      "Epoch 1, Loss: 1.0158742952626199e-05\n",
      "Epoch 1, Loss: 1.0237177775707096e-05\n",
      "Epoch 1, Loss: 1.0272357030771673e-05\n",
      "Epoch 1, Loss: 1.0341878805775195e-05\n",
      "Epoch 1, Loss: 1.036282628774643e-05\n",
      "Epoch 1, Loss: 1.0404190106783062e-05\n",
      "Epoch 1, Loss: 1.0445393854752183e-05\n",
      "Epoch 1, Loss: 1.0503004887141287e-05\n",
      "Epoch 1, Loss: 1.0539966751821339e-05\n",
      "Epoch 1, Loss: 1.0561139788478613e-05\n",
      "Epoch 1, Loss: 1.0633222700562328e-05\n",
      "Epoch 1, Loss: 1.0656454833224416e-05\n",
      "Epoch 1, Loss: 1.0669202310964465e-05\n",
      "Epoch 1, Loss: 1.070792495738715e-05\n",
      "Epoch 1, Loss: 1.0730051144491881e-05\n",
      "Epoch 1, Loss: 1.0795345588121563e-05\n",
      "Epoch 1, Loss: 1.0833886335603893e-05\n",
      "Epoch 1, Loss: 1.0866802767850459e-05\n",
      "Epoch 1, Loss: 1.0883319191634655e-05\n",
      "Epoch 1, Loss: 1.0942116205114871e-05\n",
      "Epoch 1, Loss: 1.098124630516395e-05\n",
      "Epoch 1, Loss: 1.104397961171344e-05\n",
      "Epoch 1, Loss: 1.1075717338826507e-05\n",
      "Epoch 1, Loss: 1.1096381058450788e-05\n",
      "Epoch 1, Loss: 1.1163858289364725e-05\n",
      "Epoch 1, Loss: 1.1234107660129666e-05\n",
      "Epoch 1, Loss: 1.1300719052087516e-05\n",
      "Epoch 1, Loss: 1.1314659786876291e-05\n",
      "Epoch 1, Loss: 1.1337113392073661e-05\n",
      "Epoch 1, Loss: 1.1437608918640763e-05\n",
      "Epoch 1, Loss: 1.1507378076203167e-05\n",
      "Epoch 1, Loss: 1.1827061825897545e-05\n",
      "Epoch 1, Loss: 1.1922420526389033e-05\n",
      "Epoch 1, Loss: 1.215597876580432e-05\n",
      "Epoch 1, Loss: 1.2234231689944863e-05\n",
      "Epoch 1, Loss: 1.2283409887459129e-05\n",
      "Epoch 1, Loss: 1.2371863704174757e-05\n",
      "Epoch 1, Loss: 1.2454511306714267e-05\n",
      "Epoch 1, Loss: 1.2506876373663545e-05\n",
      "Epoch 1, Loss: 1.2538708688225597e-05\n",
      "Epoch 1, Loss: 1.2561482435557991e-05\n",
      "Epoch 1, Loss: 1.2600816262420267e-05\n",
      "Epoch 1, Loss: 1.2617194443009794e-05\n",
      "Epoch 1, Loss: 1.2710173905361444e-05\n",
      "Epoch 1, Loss: 1.312132371822372e-05\n",
      "Epoch 1, Loss: 1.320678711635992e-05\n",
      "Epoch 1, Loss: 1.3291042705532163e-05\n",
      "Epoch 1, Loss: 1.3374461559578776e-05\n",
      "Epoch 1, Loss: 3.059840361986842e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_1/rank_listnet_model.pth\n",
      "=====================================\n",
      "REINVENT round = 2\n",
      "Creating config file: output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  783\n",
      "----------------------------------\n",
      "HITL iteration = 1\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_1/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 1: [132 147  15  51 146 195 187 177  50 183 141  21  86 169 156 151  93  89\n",
      "  62  68]\n",
      "Human score at HITL iteration 1: [0.013420163637304455, 0.006106257070046325, 0.9310344185076902, 0.007749198537811534, 0.01626872962027841, 0.003018904982753186, 0.005487979418633843, 0.0089328532548344, 0.0024692251674823837, 0.1403191971893395, 0.008128088211439668, 0.9323606507340716, 0.7878713850778384, 0.0016620902237753229, 0.0008143191556980437, 0.06703016014350026, 0.001747437996615119, 0.02605595764477854, 0.18468142241698865, 0.01768891633104311]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 6864\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_1/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.2954005796927959e-05\n",
      "Epoch 1, Loss: 2.2657070076093078e-05\n",
      "Epoch 1, Loss: 2.8340342396404594e-05\n",
      "Epoch 1, Loss: 3.148850373690948e-05\n",
      "Epoch 1, Loss: 3.407280019018799e-05\n",
      "Epoch 1, Loss: 3.776993980864063e-05\n",
      "Epoch 1, Loss: 3.892950189765543e-05\n",
      "Epoch 1, Loss: 3.948232188122347e-05\n",
      "Epoch 1, Loss: 4.0366976463701576e-05\n",
      "Epoch 1, Loss: 4.059670027345419e-05\n",
      "Epoch 1, Loss: 4.128734872210771e-05\n",
      "Epoch 1, Loss: 4.2127008782699704e-05\n",
      "Epoch 1, Loss: 4.2786319681908935e-05\n",
      "Epoch 1, Loss: 4.3426320189610124e-05\n",
      "Epoch 1, Loss: 4.388160596136004e-05\n",
      "Epoch 1, Loss: 4.4243017327971756e-05\n",
      "Epoch 1, Loss: 4.480595816858113e-05\n",
      "Epoch 1, Loss: 4.5245127694215626e-05\n",
      "Epoch 1, Loss: 4.575299681164324e-05\n",
      "Epoch 1, Loss: 4.618813545675948e-05\n",
      "Epoch 1, Loss: 4.6678673243150115e-05\n",
      "Epoch 1, Loss: 4.694754898082465e-05\n",
      "Epoch 1, Loss: 4.707778862211853e-05\n",
      "Epoch 1, Loss: 4.7285524487961084e-05\n",
      "Epoch 1, Loss: 4.7724664909765124e-05\n",
      "Epoch 1, Loss: 4.793618427356705e-05\n",
      "Epoch 1, Loss: 4.8255169531330466e-05\n",
      "Epoch 1, Loss: 4.831939440919086e-05\n",
      "Epoch 1, Loss: 4.8390516894869506e-05\n",
      "Epoch 1, Loss: 4.8563466407358646e-05\n",
      "Epoch 1, Loss: 4.8647627409081906e-05\n",
      "Epoch 1, Loss: 4.8838366637937725e-05\n",
      "Epoch 1, Loss: 4.895123856840655e-05\n",
      "Epoch 1, Loss: 4.913334851153195e-05\n",
      "Epoch 1, Loss: 4.937509220326319e-05\n",
      "Epoch 1, Loss: 4.944413376506418e-05\n",
      "Epoch 1, Loss: 4.962761158822104e-05\n",
      "Epoch 1, Loss: 4.967488348484039e-05\n",
      "Epoch 1, Loss: 4.978827928425744e-05\n",
      "Epoch 1, Loss: 5.004087870474905e-05\n",
      "Epoch 1, Loss: 5.009980668546632e-05\n",
      "Epoch 1, Loss: 5.01629474456422e-05\n",
      "Epoch 1, Loss: 5.032958142692223e-05\n",
      "Epoch 1, Loss: 5.054423672845587e-05\n",
      "Epoch 1, Loss: 5.059381510363892e-05\n",
      "Epoch 1, Loss: 5.075436638435349e-05\n",
      "Epoch 1, Loss: 5.0856098823715e-05\n",
      "Epoch 1, Loss: 5.101611168356612e-05\n",
      "Epoch 1, Loss: 5.105828313389793e-05\n",
      "Epoch 1, Loss: 5.146957118995488e-05\n",
      "Epoch 1, Loss: 5.1557435654103756e-05\n",
      "Epoch 1, Loss: 5.158928252058104e-05\n",
      "Epoch 1, Loss: 5.1779134082607925e-05\n",
      "Epoch 1, Loss: 5.2283023251220584e-05\n",
      "Epoch 1, Loss: 5.2373412472661585e-05\n",
      "Epoch 1, Loss: 5.28925666003488e-05\n",
      "Epoch 1, Loss: 5.3127616411074996e-05\n",
      "Epoch 1, Loss: 5.403043905971572e-05\n",
      "Epoch 1, Loss: 5.423895345302299e-05\n",
      "Epoch 1, Loss: 5.434924969449639e-05\n",
      "Epoch 1, Loss: 5.444201087811962e-05\n",
      "Epoch 1, Loss: 5.452986079035327e-05\n",
      "Epoch 1, Loss: 5.4582102166023105e-05\n",
      "Epoch 1, Loss: 5.466189031722024e-05\n",
      "Epoch 1, Loss: 5.47940144315362e-05\n",
      "Epoch 1, Loss: 5.498030805028975e-05\n",
      "Epoch 1, Loss: 5.5089607485570014e-05\n",
      "Epoch 1, Loss: 5.571702786255628e-05\n",
      "Epoch 1, Loss: 5.5783253628760576e-05\n",
      "Epoch 1, Loss: 5.589586362475529e-05\n",
      "Epoch 1, Loss: 5.5974618589971215e-05\n",
      "Epoch 1, Loss: 5.625718040391803e-05\n",
      "Epoch 1, Loss: 5.6465883972123265e-05\n",
      "Epoch 1, Loss: 5.6500321079511195e-05\n",
      "Epoch 1, Loss: 5.672985571436584e-05\n",
      "Epoch 1, Loss: 5.677476292476058e-05\n",
      "Epoch 1, Loss: 5.699531902791932e-05\n",
      "Epoch 1, Loss: 5.708272510673851e-05\n",
      "Epoch 1, Loss: 5.7234974519815296e-05\n",
      "Epoch 1, Loss: 5.7412391470279545e-05\n",
      "Epoch 1, Loss: 5.760069325333461e-05\n",
      "Epoch 1, Loss: 5.763574881711975e-05\n",
      "Epoch 1, Loss: 5.7681259931996465e-05\n",
      "Epoch 1, Loss: 5.770252028014511e-05\n",
      "Epoch 1, Loss: 5.774613964604214e-05\n",
      "Epoch 1, Loss: 5.781539948657155e-05\n",
      "Epoch 1, Loss: 5.7872784964274615e-05\n",
      "Epoch 1, Loss: 5.802750092698261e-05\n",
      "Epoch 1, Loss: 5.806599074276164e-05\n",
      "Epoch 1, Loss: 5.813595635117963e-05\n",
      "Epoch 1, Loss: 5.824724939884618e-05\n",
      "Epoch 1, Loss: 5.829473229823634e-05\n",
      "Epoch 1, Loss: 5.8346900914330035e-05\n",
      "Epoch 1, Loss: 5.8388905017636716e-05\n",
      "Epoch 1, Loss: 5.8468227507546544e-05\n",
      "Epoch 1, Loss: 5.860619421582669e-05\n",
      "Epoch 1, Loss: 5.867409345228225e-05\n",
      "Epoch 1, Loss: 5.8869190979748964e-05\n",
      "Epoch 1, Loss: 5.89835035498254e-05\n",
      "Epoch 1, Loss: 5.90710187680088e-05\n",
      "Epoch 1, Loss: 5.926322046434507e-05\n",
      "Epoch 1, Loss: 5.930900078965351e-05\n",
      "Epoch 1, Loss: 5.932821659371257e-05\n",
      "Epoch 1, Loss: 5.95506135141477e-05\n",
      "Epoch 1, Loss: 5.971206701360643e-05\n",
      "Epoch 1, Loss: 5.986044561723247e-05\n",
      "Epoch 1, Loss: 5.9961101214867085e-05\n",
      "Epoch 1, Loss: 0.00024011658388189971\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_2/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_2/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 2: [150  54  85  33  25 107  96  64 113 119 116  76   7  14  17  35 125 142\n",
      " 117  78]\n",
      "Human score at HITL iteration 2: [0.0007699963549256928, 0.030614792488563157, 0.0020992303362393364, 0.016756547902519833, 0.016072311088749312, 0.0077887353173807855, 0.12533911815159868, 0.1709580558960121, 0.0018870904752294527, 0.0009751117148078926, 0.006939657232626914, 0.0003767667932179672, 0.0586341281836162, 0.5, 0.008989734079547642, 0.4634129548575005, 0.0015517251374365193, 0.0007540575351041633, 0.014604307862653682, 0.00019762562208785176]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 8004\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_2/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 2.377877535764128e-06\n",
      "Epoch 1, Loss: 4.176989023108035e-06\n",
      "Epoch 1, Loss: 4.909350536763668e-06\n",
      "Epoch 1, Loss: 5.817986675538123e-06\n",
      "Epoch 1, Loss: 6.084555934648961e-06\n",
      "Epoch 1, Loss: 6.399983249139041e-06\n",
      "Epoch 1, Loss: 6.97434734320268e-06\n",
      "Epoch 1, Loss: 7.3175106081180274e-06\n",
      "Epoch 1, Loss: 7.646667654626071e-06\n",
      "Epoch 1, Loss: 7.946204277686775e-06\n",
      "Epoch 1, Loss: 8.189439540728927e-06\n",
      "Epoch 1, Loss: 8.531562343705446e-06\n",
      "Epoch 1, Loss: 8.89301736606285e-06\n",
      "Epoch 1, Loss: 9.15412965696305e-06\n",
      "Epoch 1, Loss: 9.417381079401821e-06\n",
      "Epoch 1, Loss: 9.49214881984517e-06\n",
      "Epoch 1, Loss: 9.650415449868888e-06\n",
      "Epoch 1, Loss: 9.74378053797409e-06\n",
      "Epoch 1, Loss: 9.87314706435427e-06\n",
      "Epoch 1, Loss: 9.979426977224648e-06\n",
      "Epoch 1, Loss: 1.0108924470841885e-05\n",
      "Epoch 1, Loss: 1.059115311363712e-05\n",
      "Epoch 1, Loss: 1.0751136869657785e-05\n",
      "Epoch 1, Loss: 1.0880619811359793e-05\n",
      "Epoch 1, Loss: 1.147421426139772e-05\n",
      "Epoch 1, Loss: 1.163053821073845e-05\n",
      "Epoch 1, Loss: 1.170302857644856e-05\n",
      "Epoch 1, Loss: 1.1941003322135657e-05\n",
      "Epoch 1, Loss: 1.2064359907526523e-05\n",
      "Epoch 1, Loss: 1.2344346032477915e-05\n",
      "Epoch 1, Loss: 1.2447460903786123e-05\n",
      "Epoch 1, Loss: 1.2564800272230059e-05\n",
      "Epoch 1, Loss: 1.2657044862862676e-05\n",
      "Epoch 1, Loss: 1.277806586585939e-05\n",
      "Epoch 1, Loss: 1.2947610230185091e-05\n",
      "Epoch 1, Loss: 1.3062679499853402e-05\n",
      "Epoch 1, Loss: 1.31644555949606e-05\n",
      "Epoch 1, Loss: 1.3292039511725307e-05\n",
      "Epoch 1, Loss: 1.3359451259020716e-05\n",
      "Epoch 1, Loss: 1.3471297279465944e-05\n",
      "Epoch 1, Loss: 1.3735349057242274e-05\n",
      "Epoch 1, Loss: 1.3915487215854228e-05\n",
      "Epoch 1, Loss: 1.4180841390043497e-05\n",
      "Epoch 1, Loss: 1.4324134099297225e-05\n",
      "Epoch 1, Loss: 1.4365628885570914e-05\n",
      "Epoch 1, Loss: 1.4439952792599797e-05\n",
      "Epoch 1, Loss: 1.4492019545286894e-05\n",
      "Epoch 1, Loss: 1.4601057046093047e-05\n",
      "Epoch 1, Loss: 1.470371353207156e-05\n",
      "Epoch 1, Loss: 1.477352634537965e-05\n",
      "Epoch 1, Loss: 1.5016063116490841e-05\n",
      "Epoch 1, Loss: 1.535858609713614e-05\n",
      "Epoch 1, Loss: 1.546577550470829e-05\n",
      "Epoch 1, Loss: 1.5651450667064637e-05\n",
      "Epoch 1, Loss: 1.6010897525120527e-05\n",
      "Epoch 1, Loss: 1.6266982129309326e-05\n",
      "Epoch 1, Loss: 1.6495607269462198e-05\n",
      "Epoch 1, Loss: 1.672530925134197e-05\n",
      "Epoch 1, Loss: 1.6821097233332694e-05\n",
      "Epoch 1, Loss: 1.6981088265310973e-05\n",
      "Epoch 1, Loss: 1.71386418514885e-05\n",
      "Epoch 1, Loss: 1.729466748656705e-05\n",
      "Epoch 1, Loss: 1.737463753670454e-05\n",
      "Epoch 1, Loss: 1.749467628542334e-05\n",
      "Epoch 1, Loss: 1.7558530089445412e-05\n",
      "Epoch 1, Loss: 1.772620453266427e-05\n",
      "Epoch 1, Loss: 1.7812286387197673e-05\n",
      "Epoch 1, Loss: 1.7856727936305106e-05\n",
      "Epoch 1, Loss: 1.7913516785483807e-05\n",
      "Epoch 1, Loss: 1.8188569811172783e-05\n",
      "Epoch 1, Loss: 1.8545535567682236e-05\n",
      "Epoch 1, Loss: 1.8572027329355478e-05\n",
      "Epoch 1, Loss: 1.8608407117426395e-05\n",
      "Epoch 1, Loss: 1.885385427158326e-05\n",
      "Epoch 1, Loss: 1.8949125660583377e-05\n",
      "Epoch 1, Loss: 1.9017279555555433e-05\n",
      "Epoch 1, Loss: 1.905494718812406e-05\n",
      "Epoch 1, Loss: 1.928194978972897e-05\n",
      "Epoch 1, Loss: 1.933301246026531e-05\n",
      "Epoch 1, Loss: 1.937562774401158e-05\n",
      "Epoch 1, Loss: 1.9393432012293488e-05\n",
      "Epoch 1, Loss: 1.9416824216023088e-05\n",
      "Epoch 1, Loss: 1.9433849956840277e-05\n",
      "Epoch 1, Loss: 1.948278077179566e-05\n",
      "Epoch 1, Loss: 1.9513281586114317e-05\n",
      "Epoch 1, Loss: 1.953161699930206e-05\n",
      "Epoch 1, Loss: 1.9589911971706897e-05\n",
      "Epoch 1, Loss: 1.972464087884873e-05\n",
      "Epoch 1, Loss: 1.9779159629251808e-05\n",
      "Epoch 1, Loss: 1.9837614672724158e-05\n",
      "Epoch 1, Loss: 1.987756695598364e-05\n",
      "Epoch 1, Loss: 1.990184682654217e-05\n",
      "Epoch 1, Loss: 1.99433634406887e-05\n",
      "Epoch 1, Loss: 2.0131818018853664e-05\n",
      "Epoch 1, Loss: 2.0174949895590544e-05\n",
      "Epoch 1, Loss: 2.0360159396659583e-05\n",
      "Epoch 1, Loss: 2.0407940610311925e-05\n",
      "Epoch 1, Loss: 2.0427796698641032e-05\n",
      "Epoch 1, Loss: 2.0575898815877736e-05\n",
      "Epoch 1, Loss: 2.0726736693177372e-05\n",
      "Epoch 1, Loss: 2.0755775040015578e-05\n",
      "Epoch 1, Loss: 2.09910940611735e-05\n",
      "Epoch 1, Loss: 2.119543933076784e-05\n",
      "Epoch 1, Loss: 2.130908251274377e-05\n",
      "Epoch 1, Loss: 2.1388572349678725e-05\n",
      "Epoch 1, Loss: 2.1478248527273536e-05\n",
      "Epoch 1, Loss: 2.1767293219454587e-05\n",
      "Epoch 1, Loss: 2.1969732188154012e-05\n",
      "Epoch 1, Loss: 2.2271648049354553e-05\n",
      "Epoch 1, Loss: 2.234225394204259e-05\n",
      "Epoch 1, Loss: 2.2416788851842284e-05\n",
      "Epoch 1, Loss: 2.263251371914521e-05\n",
      "Epoch 1, Loss: 2.2712534700985998e-05\n",
      "Epoch 1, Loss: 2.3020285880193114e-05\n",
      "Epoch 1, Loss: 2.318521001143381e-05\n",
      "Epoch 1, Loss: 2.3210872313939035e-05\n",
      "Epoch 1, Loss: 2.3277170839719474e-05\n",
      "Epoch 1, Loss: 2.3314147256314754e-05\n",
      "Epoch 1, Loss: 2.3358050384558737e-05\n",
      "Epoch 1, Loss: 2.33891187235713e-05\n",
      "Epoch 1, Loss: 2.3645283363293856e-05\n",
      "Epoch 1, Loss: 2.384458639426157e-05\n",
      "Epoch 1, Loss: 2.398692595306784e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.4070788640528917e-05\n",
      "Epoch 1, Loss: 2.427584695396945e-05\n",
      "Epoch 1, Loss: 0.00038863334339112043\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_3/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 3\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_3/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 3: [ 10 191 190  52 105  83  84  73 180  91  30 162 196 171 143  48 110 127\n",
      "  94  13]\n",
      "Human score at HITL iteration 3: [0.9951812669033241, 0.023677730528116184, 0.00042840248256400675, 0.056679358714425636, 0.00911201079632099, 0.0077544785414524545, 0.0033270395636325776, 0.005042865669023987, 0.00027656320469815997, 0.5382024353100184, 0.5737244521343007, 0.012153581393010784, 0.0010484620078877285, 0.03718672905869477, 0.018819103569982402, 0.0021397776218778485, 0.6865777173079818, 0.003824164621477794, 0.0013409350925767966, 0.6220629758491694]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 9144\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_3/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 4.027977411169559e-06\n",
      "Epoch 1, Loss: 7.2569819167256355e-06\n",
      "Epoch 1, Loss: 9.276009222958237e-06\n",
      "Epoch 1, Loss: 1.3115168258082122e-05\n",
      "Epoch 1, Loss: 1.4453660696744919e-05\n",
      "Epoch 1, Loss: 1.5419296687468886e-05\n",
      "Epoch 1, Loss: 1.59213159349747e-05\n",
      "Epoch 1, Loss: 1.680744026089087e-05\n",
      "Epoch 1, Loss: 1.733347016852349e-05\n",
      "Epoch 1, Loss: 1.7616526747588068e-05\n",
      "Epoch 1, Loss: 1.8057377019431442e-05\n",
      "Epoch 1, Loss: 1.8412254576105624e-05\n",
      "Epoch 1, Loss: 1.8591148545965552e-05\n",
      "Epoch 1, Loss: 1.88336634892039e-05\n",
      "Epoch 1, Loss: 1.926295954035595e-05\n",
      "Epoch 1, Loss: 1.945844996953383e-05\n",
      "Epoch 1, Loss: 1.974577025976032e-05\n",
      "Epoch 1, Loss: 1.9966297259088606e-05\n",
      "Epoch 1, Loss: 2.009758463827893e-05\n",
      "Epoch 1, Loss: 2.0298197341617197e-05\n",
      "Epoch 1, Loss: 2.0438928913790733e-05\n",
      "Epoch 1, Loss: 2.050360490102321e-05\n",
      "Epoch 1, Loss: 2.0767212845385075e-05\n",
      "Epoch 1, Loss: 2.111837238771841e-05\n",
      "Epoch 1, Loss: 2.1253246814012527e-05\n",
      "Epoch 1, Loss: 2.135508111678064e-05\n",
      "Epoch 1, Loss: 2.151799708371982e-05\n",
      "Epoch 1, Loss: 2.1760453819297254e-05\n",
      "Epoch 1, Loss: 2.210090315202251e-05\n",
      "Epoch 1, Loss: 2.2217573132365942e-05\n",
      "Epoch 1, Loss: 2.254379796795547e-05\n",
      "Epoch 1, Loss: 2.2672393242828548e-05\n",
      "Epoch 1, Loss: 2.281689376104623e-05\n",
      "Epoch 1, Loss: 2.3088483430910856e-05\n",
      "Epoch 1, Loss: 2.327209949726239e-05\n",
      "Epoch 1, Loss: 2.3346568923443556e-05\n",
      "Epoch 1, Loss: 2.3634740500710905e-05\n",
      "Epoch 1, Loss: 2.3685148335061967e-05\n",
      "Epoch 1, Loss: 2.3874847101978958e-05\n",
      "Epoch 1, Loss: 2.4073931854218245e-05\n",
      "Epoch 1, Loss: 2.424562262604013e-05\n",
      "Epoch 1, Loss: 2.4494584067724645e-05\n",
      "Epoch 1, Loss: 2.4631110136397183e-05\n",
      "Epoch 1, Loss: 2.495550870662555e-05\n",
      "Epoch 1, Loss: 2.5299625121988356e-05\n",
      "Epoch 1, Loss: 2.555156243033707e-05\n",
      "Epoch 1, Loss: 2.5617591745685786e-05\n",
      "Epoch 1, Loss: 2.5980843929573894e-05\n",
      "Epoch 1, Loss: 2.6089153834618628e-05\n",
      "Epoch 1, Loss: 2.6243571483064443e-05\n",
      "Epoch 1, Loss: 2.643806510604918e-05\n",
      "Epoch 1, Loss: 2.6587738830130547e-05\n",
      "Epoch 1, Loss: 2.6708614313974977e-05\n",
      "Epoch 1, Loss: 2.6767454983200878e-05\n",
      "Epoch 1, Loss: 2.69062293227762e-05\n",
      "Epoch 1, Loss: 2.7133246476296335e-05\n",
      "Epoch 1, Loss: 2.721454802667722e-05\n",
      "Epoch 1, Loss: 2.7398462407290936e-05\n",
      "Epoch 1, Loss: 2.7656264137476683e-05\n",
      "Epoch 1, Loss: 2.778574707917869e-05\n",
      "Epoch 1, Loss: 2.8081667551305145e-05\n",
      "Epoch 1, Loss: 2.8376838599797338e-05\n",
      "Epoch 1, Loss: 2.8487294912338257e-05\n",
      "Epoch 1, Loss: 2.8600545192603022e-05\n",
      "Epoch 1, Loss: 2.8665272111538798e-05\n",
      "Epoch 1, Loss: 2.878439408959821e-05\n",
      "Epoch 1, Loss: 2.885874710045755e-05\n",
      "Epoch 1, Loss: 2.9023292881902307e-05\n",
      "Epoch 1, Loss: 2.920275437645614e-05\n",
      "Epoch 1, Loss: 2.9265531338751316e-05\n",
      "Epoch 1, Loss: 2.9462513339240104e-05\n",
      "Epoch 1, Loss: 2.964952727779746e-05\n",
      "Epoch 1, Loss: 2.9810777050442994e-05\n",
      "Epoch 1, Loss: 2.9960756364744157e-05\n",
      "Epoch 1, Loss: 3.002707671839744e-05\n",
      "Epoch 1, Loss: 3.0261624488048255e-05\n",
      "Epoch 1, Loss: 3.0321381927933544e-05\n",
      "Epoch 1, Loss: 3.044677578145638e-05\n",
      "Epoch 1, Loss: 3.0496768886223435e-05\n",
      "Epoch 1, Loss: 3.076072607655078e-05\n",
      "Epoch 1, Loss: 3.084567288169637e-05\n",
      "Epoch 1, Loss: 3.0884984880685806e-05\n",
      "Epoch 1, Loss: 3.1048002711031586e-05\n",
      "Epoch 1, Loss: 3.133891004836187e-05\n",
      "Epoch 1, Loss: 3.1378505809698254e-05\n",
      "Epoch 1, Loss: 3.1590745493303984e-05\n",
      "Epoch 1, Loss: 3.1701500120107085e-05\n",
      "Epoch 1, Loss: 3.174294397467747e-05\n",
      "Epoch 1, Loss: 3.1911862606648356e-05\n",
      "Epoch 1, Loss: 3.207712870789692e-05\n",
      "Epoch 1, Loss: 3.2247691706288606e-05\n",
      "Epoch 1, Loss: 3.2475531043019146e-05\n",
      "Epoch 1, Loss: 3.279442171333358e-05\n",
      "Epoch 1, Loss: 3.2912859751377255e-05\n",
      "Epoch 1, Loss: 3.307155566290021e-05\n",
      "Epoch 1, Loss: 3.3105498005170375e-05\n",
      "Epoch 1, Loss: 3.342832496855408e-05\n",
      "Epoch 1, Loss: 3.3685690141282976e-05\n",
      "Epoch 1, Loss: 3.3780845114961267e-05\n",
      "Epoch 1, Loss: 3.404280141694471e-05\n",
      "Epoch 1, Loss: 3.4074459108524024e-05\n",
      "Epoch 1, Loss: 3.4321899875067174e-05\n",
      "Epoch 1, Loss: 3.4376425901427865e-05\n",
      "Epoch 1, Loss: 3.4449127269908786e-05\n",
      "Epoch 1, Loss: 3.4496275475248694e-05\n",
      "Epoch 1, Loss: 3.45884618582204e-05\n",
      "Epoch 1, Loss: 3.479553561192006e-05\n",
      "Epoch 1, Loss: 3.494613338261843e-05\n",
      "Epoch 1, Loss: 3.5174227377865463e-05\n",
      "Epoch 1, Loss: 3.527363878674805e-05\n",
      "Epoch 1, Loss: 3.546907828422263e-05\n",
      "Epoch 1, Loss: 3.563703648978844e-05\n",
      "Epoch 1, Loss: 3.5824930819217116e-05\n",
      "Epoch 1, Loss: 3.60851117875427e-05\n",
      "Epoch 1, Loss: 3.648670099209994e-05\n",
      "Epoch 1, Loss: 3.6609460948966444e-05\n",
      "Epoch 1, Loss: 3.687281423481181e-05\n",
      "Epoch 1, Loss: 3.714252670761198e-05\n",
      "Epoch 1, Loss: 3.7297766539268196e-05\n",
      "Epoch 1, Loss: 3.740689135156572e-05\n",
      "Epoch 1, Loss: 3.770426701521501e-05\n",
      "Epoch 1, Loss: 3.7875804991927e-05\n",
      "Epoch 1, Loss: 3.8102058169897646e-05\n",
      "Epoch 1, Loss: 3.829022170975804e-05\n",
      "Epoch 1, Loss: 3.855268732877448e-05\n",
      "Epoch 1, Loss: 3.8748599763493985e-05\n",
      "Epoch 1, Loss: 3.896728594554588e-05\n",
      "Epoch 1, Loss: 3.911687963409349e-05\n",
      "Epoch 1, Loss: 3.920487506547943e-05\n",
      "Epoch 1, Loss: 3.939153248211369e-05\n",
      "Epoch 1, Loss: 3.95248644053936e-05\n",
      "Epoch 1, Loss: 3.9640304748900235e-05\n",
      "Epoch 1, Loss: 3.977896267315373e-05\n",
      "Epoch 1, Loss: 4.0038867155089974e-05\n",
      "Epoch 1, Loss: 4.0252918552141637e-05\n",
      "Epoch 1, Loss: 4.03948943130672e-05\n",
      "Epoch 1, Loss: 4.041899228468537e-05\n",
      "Epoch 1, Loss: 4.049264680361375e-05\n",
      "Epoch 1, Loss: 4.055639874422923e-05\n",
      "Epoch 1, Loss: 4.071705916430801e-05\n",
      "Epoch 1, Loss: 4.0780549170449376e-05\n",
      "Epoch 1, Loss: 4.0908103983383626e-05\n",
      "Epoch 1, Loss: 4.6834132246788484e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_4/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 4\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_4/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 4: [ 27 184 115  20 109 178  45 172  42  70 118 139 188  40 131 198  41  57\n",
      "   5 170]\n",
      "Human score at HITL iteration 4: [0.00022879861781488465, 0.0015227659807934327, 0.28018663173655395, 0.006167969746132676, 0.06033200187601354, 0.07090317700870749, 0.0036262794360667327, 0.00024241019867442948, 0.05519375273838244, 0.2600560516188085, 0.20377485465703268, 0.007625346607357865, 0.4860258840897437, 0.1178674727602919, 0.03207191376121947, 0.0022322928919826486, 0.04866453357174371, 0.05930571447389981, 0.0015296741717380688, 0.009436505447703568]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 10284\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_4/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.4261604519560933e-06\n",
      "Epoch 1, Loss: 3.1898016459308565e-06\n",
      "Epoch 1, Loss: 6.00018393015489e-06\n",
      "Epoch 1, Loss: 6.627989932894707e-06\n",
      "Epoch 1, Loss: 7.107650162652135e-06\n",
      "Epoch 1, Loss: 7.844144420232624e-06\n",
      "Epoch 1, Loss: 8.407077984884381e-06\n",
      "Epoch 1, Loss: 9.592593414708972e-06\n",
      "Epoch 1, Loss: 1.0551266313996166e-05\n",
      "Epoch 1, Loss: 1.0877243767026812e-05\n",
      "Epoch 1, Loss: 1.1655785783659667e-05\n",
      "Epoch 1, Loss: 1.1935764632653445e-05\n",
      "Epoch 1, Loss: 1.2056414561811835e-05\n",
      "Epoch 1, Loss: 1.2423173757269979e-05\n",
      "Epoch 1, Loss: 1.279886782867834e-05\n",
      "Epoch 1, Loss: 1.296045957133174e-05\n",
      "Epoch 1, Loss: 1.315269764745608e-05\n",
      "Epoch 1, Loss: 1.3421231415122747e-05\n",
      "Epoch 1, Loss: 1.3693956134375185e-05\n",
      "Epoch 1, Loss: 1.4056276995688677e-05\n",
      "Epoch 1, Loss: 1.43797806231305e-05\n",
      "Epoch 1, Loss: 1.4585049939341843e-05\n",
      "Epoch 1, Loss: 1.4945268048904836e-05\n",
      "Epoch 1, Loss: 1.5132995031308383e-05\n",
      "Epoch 1, Loss: 1.5482903108932078e-05\n",
      "Epoch 1, Loss: 1.5657278709113598e-05\n",
      "Epoch 1, Loss: 1.598209928488359e-05\n",
      "Epoch 1, Loss: 1.620449620531872e-05\n",
      "Epoch 1, Loss: 1.6379293811041862e-05\n",
      "Epoch 1, Loss: 1.6557256458327174e-05\n",
      "Epoch 1, Loss: 1.67291218531318e-05\n",
      "Epoch 1, Loss: 1.6944868548307568e-05\n",
      "Epoch 1, Loss: 1.7047736037056893e-05\n",
      "Epoch 1, Loss: 1.7441088857594877e-05\n",
      "Epoch 1, Loss: 1.7697529983706772e-05\n",
      "Epoch 1, Loss: 1.791327667888254e-05\n",
      "Epoch 1, Loss: 1.8259379430674016e-05\n",
      "Epoch 1, Loss: 1.8393729988019913e-05\n",
      "Epoch 1, Loss: 1.855684968177229e-05\n",
      "Epoch 1, Loss: 1.8749575247056782e-05\n",
      "Epoch 1, Loss: 1.917359622893855e-05\n",
      "Epoch 1, Loss: 1.934319152496755e-05\n",
      "Epoch 1, Loss: 1.9451115804258734e-05\n",
      "Epoch 1, Loss: 1.9735991372726858e-05\n",
      "Epoch 1, Loss: 1.9891886040568352e-05\n",
      "Epoch 1, Loss: 2.0161663996987045e-05\n",
      "Epoch 1, Loss: 2.0223436877131462e-05\n",
      "Epoch 1, Loss: 2.0326842786744237e-05\n",
      "Epoch 1, Loss: 2.0541025151032954e-05\n",
      "Epoch 1, Loss: 2.0676910935435444e-05\n",
      "Epoch 1, Loss: 2.0751976990140975e-05\n",
      "Epoch 1, Loss: 2.0879619114566594e-05\n",
      "Epoch 1, Loss: 2.112423680955544e-05\n",
      "Epoch 1, Loss: 2.1473781089298427e-05\n",
      "Epoch 1, Loss: 2.1676263713743538e-05\n",
      "Epoch 1, Loss: 2.1777952497359365e-05\n",
      "Epoch 1, Loss: 2.2135551262181252e-05\n",
      "Epoch 1, Loss: 2.2316089598461986e-05\n",
      "Epoch 1, Loss: 2.2407271899282932e-05\n",
      "Epoch 1, Loss: 2.292303543072194e-05\n",
      "Epoch 1, Loss: 2.3064792912919074e-05\n",
      "Epoch 1, Loss: 2.3109045287128538e-05\n",
      "Epoch 1, Loss: 2.334791497560218e-05\n",
      "Epoch 1, Loss: 2.36056002904661e-05\n",
      "Epoch 1, Loss: 2.3703636543359607e-05\n",
      "Epoch 1, Loss: 2.3762244381941855e-05\n",
      "Epoch 1, Loss: 2.397070056758821e-05\n",
      "Epoch 1, Loss: 2.4137938453350216e-05\n",
      "Epoch 1, Loss: 2.4241664505098015e-05\n",
      "Epoch 1, Loss: 2.439582021906972e-05\n",
      "Epoch 1, Loss: 2.449713065288961e-05\n",
      "Epoch 1, Loss: 2.4794564524199814e-05\n",
      "Epoch 1, Loss: 2.4922745069488883e-05\n",
      "Epoch 1, Loss: 2.5127417757175863e-05\n",
      "Epoch 1, Loss: 2.518946712370962e-05\n",
      "Epoch 1, Loss: 2.5257249944843352e-05\n",
      "Epoch 1, Loss: 2.542317088227719e-05\n",
      "Epoch 1, Loss: 2.551949000917375e-05\n",
      "Epoch 1, Loss: 2.5753142836038023e-05\n",
      "Epoch 1, Loss: 2.587380731711164e-05\n",
      "Epoch 1, Loss: 2.5999717763625085e-05\n",
      "Epoch 1, Loss: 2.609675721032545e-05\n",
      "Epoch 1, Loss: 2.6376175810582936e-05\n",
      "Epoch 1, Loss: 2.6560606784187257e-05\n",
      "Epoch 1, Loss: 2.6718647859524935e-05\n",
      "Epoch 1, Loss: 2.6897461793851107e-05\n",
      "Epoch 1, Loss: 2.7017798856832087e-05\n",
      "Epoch 1, Loss: 2.723470242926851e-05\n",
      "Epoch 1, Loss: 2.726654929574579e-05\n",
      "Epoch 1, Loss: 2.7420428523328155e-05\n",
      "Epoch 1, Loss: 2.7685448003467172e-05\n",
      "Epoch 1, Loss: 2.785382093861699e-05\n",
      "Epoch 1, Loss: 2.7977468562312424e-05\n",
      "Epoch 1, Loss: 2.807115379255265e-05\n",
      "Epoch 1, Loss: 2.8108697733841836e-05\n",
      "Epoch 1, Loss: 2.8353737434372306e-05\n",
      "Epoch 1, Loss: 2.8477174055296928e-05\n",
      "Epoch 1, Loss: 2.858402149286121e-05\n",
      "Epoch 1, Loss: 2.8628834115806967e-05\n",
      "Epoch 1, Loss: 2.880550891859457e-05\n",
      "Epoch 1, Loss: 2.9049449949525297e-05\n",
      "Epoch 1, Loss: 2.9316746804397553e-05\n",
      "Epoch 1, Loss: 2.9536604415625334e-05\n",
      "Epoch 1, Loss: 2.9606228054035455e-05\n",
      "Epoch 1, Loss: 2.9691327654290944e-05\n",
      "Epoch 1, Loss: 2.9869879654143006e-05\n",
      "Epoch 1, Loss: 3.0098235583864152e-05\n",
      "Epoch 1, Loss: 3.0126517231110483e-05\n",
      "Epoch 1, Loss: 3.0469178454950452e-05\n",
      "Epoch 1, Loss: 3.068613295909017e-05\n",
      "Epoch 1, Loss: 3.083629417233169e-05\n",
      "Epoch 1, Loss: 3.121910413028672e-05\n",
      "Epoch 1, Loss: 3.138533793389797e-05\n",
      "Epoch 1, Loss: 3.144886431982741e-05\n",
      "Epoch 1, Loss: 3.147582174278796e-05\n",
      "Epoch 1, Loss: 3.164018562529236e-05\n",
      "Epoch 1, Loss: 3.171300340909511e-05\n",
      "Epoch 1, Loss: 3.178327460773289e-05\n",
      "Epoch 1, Loss: 3.188929258612916e-05\n",
      "Epoch 1, Loss: 3.203662345185876e-05\n",
      "Epoch 1, Loss: 3.219197242287919e-05\n",
      "Epoch 1, Loss: 3.2325136999133974e-05\n",
      "Epoch 1, Loss: 3.242275852244347e-05\n",
      "Epoch 1, Loss: 3.261765232309699e-05\n",
      "Epoch 1, Loss: 3.282176476204768e-05\n",
      "Epoch 1, Loss: 3.2954303605947644e-05\n",
      "Epoch 1, Loss: 3.310097235953435e-05\n",
      "Epoch 1, Loss: 3.31840492435731e-05\n",
      "Epoch 1, Loss: 3.324670979054645e-05\n",
      "Epoch 1, Loss: 3.338736860314384e-05\n",
      "Epoch 1, Loss: 3.35485819960013e-05\n",
      "Epoch 1, Loss: 3.3748823625501245e-05\n",
      "Epoch 1, Loss: 3.392037615412846e-05\n",
      "Epoch 1, Loss: 3.394477244000882e-05\n",
      "Epoch 1, Loss: 3.413772355997935e-05\n",
      "Epoch 1, Loss: 3.426075272727758e-05\n",
      "Epoch 1, Loss: 3.4308075555600226e-05\n",
      "Epoch 1, Loss: 3.4476048313081264e-05\n",
      "Epoch 1, Loss: 3.457412822172046e-05\n",
      "Epoch 1, Loss: 3.481896419543773e-05\n",
      "Epoch 1, Loss: 3.4912147384602576e-05\n",
      "Epoch 1, Loss: 3.503654443193227e-05\n",
      "Epoch 1, Loss: 3.527341323206201e-05\n",
      "Epoch 1, Loss: 3.5345372452866286e-05\n",
      "Epoch 1, Loss: 3.557551099220291e-05\n",
      "Epoch 1, Loss: 3.570046101231128e-05\n",
      "Epoch 1, Loss: 3.5780562029685825e-05\n",
      "Epoch 1, Loss: 3.585302329156548e-05\n",
      "Epoch 1, Loss: 3.595334419514984e-05\n",
      "Epoch 1, Loss: 3.63026701961644e-05\n",
      "Epoch 1, Loss: 3.6368459404911846e-05\n",
      "Epoch 1, Loss: 3.664843097794801e-05\n",
      "Epoch 1, Loss: 3.668716817628592e-05\n",
      "Epoch 1, Loss: 3.685514093376696e-05\n",
      "Epoch 1, Loss: 3.701935929711908e-05\n",
      "Epoch 1, Loss: 3.716164792422205e-05\n",
      "Epoch 1, Loss: 3.746919537661597e-05\n",
      "Epoch 1, Loss: 3.762618871405721e-05\n",
      "Epoch 1, Loss: 3.769002796616405e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.772873606067151e-05\n",
      "Epoch 1, Loss: 5.49561463365287e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_5/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 5\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_5/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 5: [153 185  72  99  26   2  66  60 135 155   4 164 168 161  39  49  90 158\n",
      "  12  22]\n",
      "Human score at HITL iteration 5: [0.021493644523574787, 0.012875641562294857, 0.023040252613232767, 0.11763151074059475, 0.09844090925361695, 0.059256555720282024, 0.00504227699641893, 0.01571471718542263, 0.5129612932443736, 0.0014178918021000614, 0.13827291684984752, 0.0025378083861121495, 0.004801889919236833, 0.0001214497749467147, 0.0030604217905346814, 0.039125027712201776, 0.0013377862611739662, 0.00030752663772786473, 0.9270456847675056, 0.012345386885349162]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 11424\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_2/HITL_iteration_5/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 3.2181269489228725e-06\n",
      "Epoch 1, Loss: 4.4071421143598855e-06\n",
      "Epoch 1, Loss: 4.781308234669268e-06\n",
      "Epoch 1, Loss: 6.875437975395471e-06\n",
      "Epoch 1, Loss: 8.225957571994513e-06\n",
      "Epoch 1, Loss: 1.1165546311531216e-05\n",
      "Epoch 1, Loss: 1.196410448756069e-05\n",
      "Epoch 1, Loss: 1.277957926504314e-05\n",
      "Epoch 1, Loss: 1.3787612260784954e-05\n",
      "Epoch 1, Loss: 1.412195706507191e-05\n",
      "Epoch 1, Loss: 1.4307624951470643e-05\n",
      "Epoch 1, Loss: 1.4470817404799163e-05\n",
      "Epoch 1, Loss: 1.4916098734829575e-05\n",
      "Epoch 1, Loss: 1.507470733486116e-05\n",
      "Epoch 1, Loss: 1.5374076610896736e-05\n",
      "Epoch 1, Loss: 1.5453464584425092e-05\n",
      "Epoch 1, Loss: 1.556393544888124e-05\n",
      "Epoch 1, Loss: 1.5961479221004993e-05\n",
      "Epoch 1, Loss: 1.6173355106730014e-05\n",
      "Epoch 1, Loss: 1.6380887245759368e-05\n",
      "Epoch 1, Loss: 1.6793084796518087e-05\n",
      "Epoch 1, Loss: 1.717838313197717e-05\n",
      "Epoch 1, Loss: 1.7468701116740704e-05\n",
      "Epoch 1, Loss: 1.7579201085027307e-05\n",
      "Epoch 1, Loss: 1.7757156456355006e-05\n",
      "Epoch 1, Loss: 1.7935824871528894e-05\n",
      "Epoch 1, Loss: 1.8266633560415357e-05\n",
      "Epoch 1, Loss: 1.861563214333728e-05\n",
      "Epoch 1, Loss: 1.889545819722116e-05\n",
      "Epoch 1, Loss: 1.9274397345725447e-05\n",
      "Epoch 1, Loss: 1.9534410967025906e-05\n",
      "Epoch 1, Loss: 1.9673127098940313e-05\n",
      "Epoch 1, Loss: 1.9823623006232083e-05\n",
      "Epoch 1, Loss: 1.992157194763422e-05\n",
      "Epoch 1, Loss: 2.0182080334052444e-05\n",
      "Epoch 1, Loss: 2.033589407801628e-05\n",
      "Epoch 1, Loss: 2.0458974177017808e-05\n",
      "Epoch 1, Loss: 2.0558523829095066e-05\n",
      "Epoch 1, Loss: 2.064234286081046e-05\n",
      "Epoch 1, Loss: 2.0859755750279874e-05\n",
      "Epoch 1, Loss: 2.0986408344469965e-05\n",
      "Epoch 1, Loss: 2.1237901819404215e-05\n",
      "Epoch 1, Loss: 2.132981171598658e-05\n",
      "Epoch 1, Loss: 2.1582432964351028e-05\n",
      "Epoch 1, Loss: 2.1871783246751875e-05\n",
      "Epoch 1, Loss: 2.1918305719736964e-05\n",
      "Epoch 1, Loss: 2.1987281797919422e-05\n",
      "Epoch 1, Loss: 2.216302527813241e-05\n",
      "Epoch 1, Loss: 2.2266925952862948e-05\n",
      "Epoch 1, Loss: 2.2681480913888663e-05\n",
      "Epoch 1, Loss: 2.281156776007265e-05\n",
      "Epoch 1, Loss: 2.2957799956202507e-05\n",
      "Epoch 1, Loss: 2.3150525521486998e-05\n",
      "Epoch 1, Loss: 2.3198961571324617e-05\n",
      "Epoch 1, Loss: 2.3230400984175503e-05\n",
      "Epoch 1, Loss: 2.3347573005594313e-05\n",
      "Epoch 1, Loss: 2.3544889700133353e-05\n",
      "Epoch 1, Loss: 2.3787048121448606e-05\n",
      "Epoch 1, Loss: 2.395233605057001e-05\n",
      "Epoch 1, Loss: 2.4086628400254995e-05\n",
      "Epoch 1, Loss: 2.433585177641362e-05\n",
      "Epoch 1, Loss: 2.4522305466234684e-05\n",
      "Epoch 1, Loss: 2.4547363864257932e-05\n",
      "Epoch 1, Loss: 2.4660628696437925e-05\n",
      "Epoch 1, Loss: 2.4738896172493696e-05\n",
      "Epoch 1, Loss: 2.500310802133754e-05\n",
      "Epoch 1, Loss: 2.5227840524166822e-05\n",
      "Epoch 1, Loss: 2.5389243091922253e-05\n",
      "Epoch 1, Loss: 2.546995528973639e-05\n",
      "Epoch 1, Loss: 2.559364656917751e-05\n",
      "Epoch 1, Loss: 2.5751949578989297e-05\n",
      "Epoch 1, Loss: 2.5838286092039198e-05\n",
      "Epoch 1, Loss: 2.5945279048755765e-05\n",
      "Epoch 1, Loss: 2.596375998109579e-05\n",
      "Epoch 1, Loss: 2.6234847609885037e-05\n",
      "Epoch 1, Loss: 2.6493260520510375e-05\n",
      "Epoch 1, Loss: 2.656235301401466e-05\n",
      "Epoch 1, Loss: 2.669219975359738e-05\n",
      "Epoch 1, Loss: 2.6873261958826333e-05\n",
      "Epoch 1, Loss: 2.6975692890118808e-05\n",
      "Epoch 1, Loss: 2.730973210418597e-05\n",
      "Epoch 1, Loss: 2.752329601207748e-05\n",
      "Epoch 1, Loss: 2.7652517019305378e-05\n",
      "Epoch 1, Loss: 2.782291267067194e-05\n",
      "Epoch 1, Loss: 2.8035181458108127e-05\n",
      "Epoch 1, Loss: 2.8212212782818824e-05\n",
      "Epoch 1, Loss: 2.832207246683538e-05\n",
      "Epoch 1, Loss: 2.8410366212483495e-05\n",
      "Epoch 1, Loss: 2.868176670745015e-05\n",
      "Epoch 1, Loss: 2.9020207875873893e-05\n",
      "Epoch 1, Loss: 2.9193768568802625e-05\n",
      "Epoch 1, Loss: 2.9272916435729712e-05\n",
      "Epoch 1, Loss: 2.929745096480474e-05\n",
      "Epoch 1, Loss: 2.9422139050439e-05\n",
      "Epoch 1, Loss: 2.9715120035689324e-05\n",
      "Epoch 1, Loss: 3.0025039450265467e-05\n",
      "Epoch 1, Loss: 3.0201728804968297e-05\n",
      "Epoch 1, Loss: 3.026834747288376e-05\n",
      "Epoch 1, Loss: 3.057425783481449e-05\n",
      "Epoch 1, Loss: 3.086724609602243e-05\n",
      "Epoch 1, Loss: 3.123221540590748e-05\n",
      "Epoch 1, Loss: 3.147820825688541e-05\n",
      "Epoch 1, Loss: 3.155633748974651e-05\n",
      "Epoch 1, Loss: 3.163780638715252e-05\n",
      "Epoch 1, Loss: 3.186755930073559e-05\n",
      "Epoch 1, Loss: 3.233164898119867e-05\n",
      "Epoch 1, Loss: 3.2575429941061884e-05\n",
      "Epoch 1, Loss: 3.264758561272174e-05\n",
      "Epoch 1, Loss: 3.2760537578724325e-05\n",
      "Epoch 1, Loss: 3.2939504308160394e-05\n",
      "Epoch 1, Loss: 3.3077514672186226e-05\n",
      "Epoch 1, Loss: 3.3315547625534236e-05\n",
      "Epoch 1, Loss: 3.340620605740696e-05\n",
      "Epoch 1, Loss: 3.359473339514807e-05\n",
      "Epoch 1, Loss: 3.372337232576683e-05\n",
      "Epoch 1, Loss: 3.390235360711813e-05\n",
      "Epoch 1, Loss: 3.409876808291301e-05\n",
      "Epoch 1, Loss: 3.422037843847647e-05\n",
      "Epoch 1, Loss: 3.431507502682507e-05\n",
      "Epoch 1, Loss: 3.441437002038583e-05\n",
      "Epoch 1, Loss: 3.453929093666375e-05\n",
      "Epoch 1, Loss: 3.470137744443491e-05\n",
      "Epoch 1, Loss: 3.483078035060316e-05\n",
      "Epoch 1, Loss: 3.496593126328662e-05\n",
      "Epoch 1, Loss: 3.5104261769447476e-05\n",
      "Epoch 1, Loss: 3.513872070470825e-05\n",
      "Epoch 1, Loss: 3.535873111104593e-05\n",
      "Epoch 1, Loss: 3.5398901673033834e-05\n",
      "Epoch 1, Loss: 3.549982648110017e-05\n",
      "Epoch 1, Loss: 3.5565382859203964e-05\n",
      "Epoch 1, Loss: 3.5739409213420004e-05\n",
      "Epoch 1, Loss: 3.5896307963412255e-05\n",
      "Epoch 1, Loss: 3.604037192417309e-05\n",
      "Epoch 1, Loss: 3.607446706155315e-05\n",
      "Epoch 1, Loss: 3.6279932828620076e-05\n",
      "Epoch 1, Loss: 3.643330273916945e-05\n",
      "Epoch 1, Loss: 3.64976585842669e-05\n",
      "Epoch 1, Loss: 3.6562989407684654e-05\n",
      "Epoch 1, Loss: 3.661370283225551e-05\n",
      "Epoch 1, Loss: 3.6662910133600235e-05\n",
      "Epoch 1, Loss: 3.696477506309748e-05\n",
      "Epoch 1, Loss: 3.7183199310675263e-05\n",
      "Epoch 1, Loss: 3.7227553548291326e-05\n",
      "Epoch 1, Loss: 3.73950315406546e-05\n",
      "Epoch 1, Loss: 3.757267404580489e-05\n",
      "Epoch 1, Loss: 3.775943332584575e-05\n",
      "Epoch 1, Loss: 3.786512388614938e-05\n",
      "Epoch 1, Loss: 3.7909143429715186e-05\n",
      "Epoch 1, Loss: 3.793215728364885e-05\n",
      "Epoch 1, Loss: 3.800360718742013e-05\n",
      "Epoch 1, Loss: 3.813041985267773e-05\n",
      "Epoch 1, Loss: 3.830252535408363e-05\n",
      "Epoch 1, Loss: 3.8388476241379976e-05\n",
      "Epoch 1, Loss: 3.859282878693193e-05\n",
      "Epoch 1, Loss: 3.8784775824751705e-05\n",
      "Epoch 1, Loss: 3.8960264646448195e-05\n",
      "Epoch 1, Loss: 3.9158345316536725e-05\n",
      "Epoch 1, Loss: 3.927329817088321e-05\n",
      "Epoch 1, Loss: 3.931307583115995e-05\n",
      "Epoch 1, Loss: 3.966275107813999e-05\n",
      "Epoch 1, Loss: 3.983550413977355e-05\n",
      "Epoch 1, Loss: 3.989182005170733e-05\n",
      "Epoch 1, Loss: 4.015514423372224e-05\n",
      "Epoch 1, Loss: 4.035691381432116e-05\n",
      "Epoch 1, Loss: 4.045003151986748e-05\n",
      "Epoch 1, Loss: 4.0677863580640405e-05\n",
      "Epoch 1, Loss: 4.085921682417393e-05\n",
      "Epoch 1, Loss: 4.0924205677583814e-05\n",
      "Epoch 1, Loss: 4.097900819033384e-05\n",
      "Epoch 1, Loss: 4.114311741432175e-05\n",
      "Epoch 1, Loss: 4.129933222429827e-05\n",
      "Epoch 1, Loss: 4.140987584833056e-05\n",
      "Epoch 1, Loss: 4.1465944377705455e-05\n",
      "Epoch 1, Loss: 4.153221379965544e-05\n",
      "Epoch 1, Loss: 4.1582752601243556e-05\n",
      "Epoch 1, Loss: 4.172939952695742e-05\n",
      "Epoch 1, Loss: 4.177197115495801e-05\n",
      "Epoch 1, Loss: 4.1833234718069434e-05\n",
      "Epoch 1, Loss: 8.406362030655146e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_1/rank_listnet_model.pth\n",
      "=====================================\n",
      "REINVENT round = 3\n",
      "Creating config file: output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit code: 0\n",
      "Number of SMILES in scaffold_memory.csv:  787\n",
      "----------------------------------\n",
      "HITL iteration = 1\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_1/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 1: [ 61  36  97 149  98  85 185  53   8  58  28   2  32 188 190 135  67 162\n",
      " 133 110]\n",
      "Human score at HITL iteration 1: [0.8878436561003321, 0.2628122024472388, 0.009944762667618356, 0.011495445967819387, 0.9829070330707427, 0.005669686922993082, 0.1144187001515168, 0.02305858909693144, 0.0007731793435334822, 0.1168045526195333, 0.004943923751930015, 6.659543676185125e-05, 0.00039746796088365507, 0.002582139312125012, 0.06332260703407937, 0.869059096966333, 0.0019022346277832172, 0.00023257557657258688, 0.004653245168433133, 5.851077330530557e-05]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 12564\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_1/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 2.8067079256288707e-06\n",
      "Epoch 1, Loss: 9.934432455338538e-06\n",
      "Epoch 1, Loss: 1.2849057384300977e-05\n",
      "Epoch 1, Loss: 1.3704266166314483e-05\n",
      "Epoch 1, Loss: 1.4675541024189442e-05\n",
      "Epoch 1, Loss: 1.5776116924826056e-05\n",
      "Epoch 1, Loss: 1.9661456462927163e-05\n",
      "Epoch 1, Loss: 2.2319429263006896e-05\n",
      "Epoch 1, Loss: 2.592210512375459e-05\n",
      "Epoch 1, Loss: 2.784252865239978e-05\n",
      "Epoch 1, Loss: 2.943812432931736e-05\n",
      "Epoch 1, Loss: 3.045613266294822e-05\n",
      "Epoch 1, Loss: 3.2478797947987914e-05\n",
      "Epoch 1, Loss: 3.31170522258617e-05\n",
      "Epoch 1, Loss: 3.425933391554281e-05\n",
      "Epoch 1, Loss: 3.475901030469686e-05\n",
      "Epoch 1, Loss: 3.5308185033500195e-05\n",
      "Epoch 1, Loss: 3.571782144717872e-05\n",
      "Epoch 1, Loss: 3.60903941327706e-05\n",
      "Epoch 1, Loss: 3.6263496440369636e-05\n",
      "Epoch 1, Loss: 3.6507612094283104e-05\n",
      "Epoch 1, Loss: 3.663677489385009e-05\n",
      "Epoch 1, Loss: 3.698444925248623e-05\n",
      "Epoch 1, Loss: 3.730451862793416e-05\n",
      "Epoch 1, Loss: 3.756812657229602e-05\n",
      "Epoch 1, Loss: 3.7721336411777884e-05\n",
      "Epoch 1, Loss: 3.793559153564274e-05\n",
      "Epoch 1, Loss: 3.830339846899733e-05\n",
      "Epoch 1, Loss: 3.845659375656396e-05\n",
      "Epoch 1, Loss: 3.8599806430283934e-05\n",
      "Epoch 1, Loss: 3.889467188855633e-05\n",
      "Epoch 1, Loss: 3.9094047679100186e-05\n",
      "Epoch 1, Loss: 3.934281994588673e-05\n",
      "Epoch 1, Loss: 3.954196290578693e-05\n",
      "Epoch 1, Loss: 3.9623715565539896e-05\n",
      "Epoch 1, Loss: 3.988208482041955e-05\n",
      "Epoch 1, Loss: 4.006171366199851e-05\n",
      "Epoch 1, Loss: 4.0463222831021994e-05\n",
      "Epoch 1, Loss: 4.0665581764187664e-05\n",
      "Epoch 1, Loss: 4.075074684806168e-05\n",
      "Epoch 1, Loss: 4.089403955731541e-05\n",
      "Epoch 1, Loss: 4.094374889973551e-05\n",
      "Epoch 1, Loss: 4.113946488359943e-05\n",
      "Epoch 1, Loss: 4.136608185945079e-05\n",
      "Epoch 1, Loss: 4.17004557675682e-05\n",
      "Epoch 1, Loss: 4.1854524170048535e-05\n",
      "Epoch 1, Loss: 4.195537621853873e-05\n",
      "Epoch 1, Loss: 4.2214676795993e-05\n",
      "Epoch 1, Loss: 4.2529471102170646e-05\n",
      "Epoch 1, Loss: 4.28151324740611e-05\n",
      "Epoch 1, Loss: 4.3094180000480264e-05\n",
      "Epoch 1, Loss: 4.324637120589614e-05\n",
      "Epoch 1, Loss: 4.349208757048473e-05\n",
      "Epoch 1, Loss: 4.358506703283638e-05\n",
      "Epoch 1, Loss: 4.390542017063126e-05\n",
      "Epoch 1, Loss: 4.403095954330638e-05\n",
      "Epoch 1, Loss: 4.425567021826282e-05\n",
      "Epoch 1, Loss: 4.436485323822126e-05\n",
      "Epoch 1, Loss: 4.459064803086221e-05\n",
      "Epoch 1, Loss: 4.469350824365392e-05\n",
      "Epoch 1, Loss: 4.497169720707461e-05\n",
      "Epoch 1, Loss: 4.551845631795004e-05\n",
      "Epoch 1, Loss: 4.5604610932059586e-05\n",
      "Epoch 1, Loss: 4.5793683966621757e-05\n",
      "Epoch 1, Loss: 4.601565160555765e-05\n",
      "Epoch 1, Loss: 4.631982301361859e-05\n",
      "Epoch 1, Loss: 4.660580452764407e-05\n",
      "Epoch 1, Loss: 4.668105975724757e-05\n",
      "Epoch 1, Loss: 4.690318019129336e-05\n",
      "Epoch 1, Loss: 4.701520811067894e-05\n",
      "Epoch 1, Loss: 4.712498775916174e-05\n",
      "Epoch 1, Loss: 4.725631151814014e-05\n",
      "Epoch 1, Loss: 4.73109248559922e-05\n",
      "Epoch 1, Loss: 4.74156258860603e-05\n",
      "Epoch 1, Loss: 4.779017763212323e-05\n",
      "Epoch 1, Loss: 4.78728543384932e-05\n",
      "Epoch 1, Loss: 4.8044268623925745e-05\n",
      "Epoch 1, Loss: 4.8328322009183466e-05\n",
      "Epoch 1, Loss: 4.84053380205296e-05\n",
      "Epoch 1, Loss: 4.868648829869926e-05\n",
      "Epoch 1, Loss: 4.8799214710015804e-05\n",
      "Epoch 1, Loss: 4.8842106480151415e-05\n",
      "Epoch 1, Loss: 4.8898997192736715e-05\n",
      "Epoch 1, Loss: 4.895989695796743e-05\n",
      "Epoch 1, Loss: 4.914651071885601e-05\n",
      "Epoch 1, Loss: 4.929597344016656e-05\n",
      "Epoch 1, Loss: 4.939063364872709e-05\n",
      "Epoch 1, Loss: 4.944348620483652e-05\n",
      "Epoch 1, Loss: 4.9646172556094825e-05\n",
      "Epoch 1, Loss: 4.974041075911373e-05\n",
      "Epoch 1, Loss: 4.978801007382572e-05\n",
      "Epoch 1, Loss: 4.989615990780294e-05\n",
      "Epoch 1, Loss: 4.995882045477629e-05\n",
      "Epoch 1, Loss: 5.0100235966965556e-05\n",
      "Epoch 1, Loss: 5.0314280088059604e-05\n",
      "Epoch 1, Loss: 5.0390008254908025e-05\n",
      "Epoch 1, Loss: 5.059382237959653e-05\n",
      "Epoch 1, Loss: 5.0841183110605925e-05\n",
      "Epoch 1, Loss: 5.098012479720637e-05\n",
      "Epoch 1, Loss: 5.108720506541431e-05\n",
      "Epoch 1, Loss: 5.122925358591601e-05\n",
      "Epoch 1, Loss: 5.129042256157845e-05\n",
      "Epoch 1, Loss: 5.139751738170162e-05\n",
      "Epoch 1, Loss: 5.147544288774952e-05\n",
      "Epoch 1, Loss: 5.1534407248254865e-05\n",
      "Epoch 1, Loss: 5.160544242244214e-05\n",
      "Epoch 1, Loss: 5.165758193470538e-05\n",
      "Epoch 1, Loss: 5.173362296773121e-05\n",
      "Epoch 1, Loss: 5.179524305276573e-05\n",
      "Epoch 1, Loss: 5.220453022047877e-05\n",
      "Epoch 1, Loss: 5.2361239795573056e-05\n",
      "Epoch 1, Loss: 5.266135121928528e-05\n",
      "Epoch 1, Loss: 5.273753049550578e-05\n",
      "Epoch 1, Loss: 5.2851457439828664e-05\n",
      "Epoch 1, Loss: 5.2946437790524215e-05\n",
      "Epoch 1, Loss: 5.329224222805351e-05\n",
      "Epoch 1, Loss: 5.351119762053713e-05\n",
      "Epoch 1, Loss: 5.3696290706284344e-05\n",
      "Epoch 1, Loss: 5.389024590840563e-05\n",
      "Epoch 1, Loss: 5.421231617219746e-05\n",
      "Epoch 1, Loss: 5.4387848649639636e-05\n",
      "Epoch 1, Loss: 5.466924631036818e-05\n",
      "Epoch 1, Loss: 5.514327494893223e-05\n",
      "Epoch 1, Loss: 5.521727871382609e-05\n",
      "Epoch 1, Loss: 5.5489617807324976e-05\n",
      "Epoch 1, Loss: 5.574249371420592e-05\n",
      "Epoch 1, Loss: 5.595901166088879e-05\n",
      "Epoch 1, Loss: 5.635877460008487e-05\n",
      "Epoch 1, Loss: 5.661678733304143e-05\n",
      "Epoch 1, Loss: 5.687835073331371e-05\n",
      "Epoch 1, Loss: 5.738081381423399e-05\n",
      "Epoch 1, Loss: 5.748096009483561e-05\n",
      "Epoch 1, Loss: 5.766581307398155e-05\n",
      "Epoch 1, Loss: 5.781391519121826e-05\n",
      "Epoch 1, Loss: 5.798094207420945e-05\n",
      "Epoch 1, Loss: 5.822948878630996e-05\n",
      "Epoch 1, Loss: 5.878161027794704e-05\n",
      "Epoch 1, Loss: 5.898308882024139e-05\n",
      "Epoch 1, Loss: 5.93241275055334e-05\n",
      "Epoch 1, Loss: 5.95738529227674e-05\n",
      "Epoch 1, Loss: 5.980266723781824e-05\n",
      "Epoch 1, Loss: 6.0191079683136195e-05\n",
      "Epoch 1, Loss: 6.039861909812316e-05\n",
      "Epoch 1, Loss: 6.065813795430586e-05\n",
      "Epoch 1, Loss: 6.084495544200763e-05\n",
      "Epoch 1, Loss: 6.115729047451168e-05\n",
      "Epoch 1, Loss: 6.132407725090161e-05\n",
      "Epoch 1, Loss: 6.163317448226735e-05\n",
      "Epoch 1, Loss: 6.183004734339193e-05\n",
      "Epoch 1, Loss: 6.207099067978561e-05\n",
      "Epoch 1, Loss: 6.22504303464666e-05\n",
      "Epoch 1, Loss: 6.232934538275003e-05\n",
      "Epoch 1, Loss: 6.265110278036445e-05\n",
      "Epoch 1, Loss: 6.276350177358836e-05\n",
      "Epoch 1, Loss: 6.30328431725502e-05\n",
      "Epoch 1, Loss: 6.328484596451744e-05\n",
      "Epoch 1, Loss: 6.361656414810568e-05\n",
      "Epoch 1, Loss: 6.369024777086452e-05\n",
      "Epoch 1, Loss: 6.373699579853565e-05\n",
      "Epoch 1, Loss: 6.379248225130141e-05\n",
      "Epoch 1, Loss: 6.391633360181004e-05\n",
      "Epoch 1, Loss: 6.414590461645275e-05\n",
      "Epoch 1, Loss: 6.424153980333358e-05\n",
      "Epoch 1, Loss: 6.427639164030552e-05\n",
      "Epoch 1, Loss: 6.436316471081227e-05\n",
      "Epoch 1, Loss: 6.444629980251193e-05\n",
      "Epoch 1, Loss: 6.489613588200882e-05\n",
      "Epoch 1, Loss: 6.495005072792992e-05\n",
      "Epoch 1, Loss: 6.515126733575016e-05\n",
      "Epoch 1, Loss: 6.530324026243761e-05\n",
      "Epoch 1, Loss: 6.558959285030141e-05\n",
      "Epoch 1, Loss: 6.589797703782097e-05\n",
      "Epoch 1, Loss: 6.603977089980617e-05\n",
      "Epoch 1, Loss: 6.616370956180617e-05\n",
      "Epoch 1, Loss: 6.631801807088777e-05\n",
      "Epoch 1, Loss: 6.639717321377248e-05\n",
      "Epoch 1, Loss: 6.651723379036412e-05\n",
      "Epoch 1, Loss: 6.666769331786782e-05\n",
      "Epoch 1, Loss: 6.701258826069534e-05\n",
      "Epoch 1, Loss: 6.723505794070661e-05\n",
      "Epoch 1, Loss: 6.739231321262196e-05\n",
      "Epoch 1, Loss: 6.76000418025069e-05\n",
      "Epoch 1, Loss: 6.787437450839207e-05\n",
      "Epoch 1, Loss: 6.824085721746087e-05\n",
      "Epoch 1, Loss: 6.829987250966951e-05\n",
      "Epoch 1, Loss: 6.838255649199709e-05\n",
      "Epoch 1, Loss: 6.859048880869523e-05\n",
      "Epoch 1, Loss: 6.864414899609983e-05\n",
      "Epoch 1, Loss: 6.867887714179233e-05\n",
      "Epoch 1, Loss: 6.895858678035438e-05\n",
      "Epoch 1, Loss: 6.905595364514738e-05\n",
      "Epoch 1, Loss: 6.91396853653714e-05\n",
      "Epoch 1, Loss: 6.939765444258228e-05\n",
      "Epoch 1, Loss: 6.951463728910312e-05\n",
      "Epoch 1, Loss: 6.959053280297667e-05\n",
      "Epoch 1, Loss: 6.975787255214527e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.00022472521759482335\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_2/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 2\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_2/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 2: [ 95 184  23 151 101 134 105  76  22  59 187  25  15 107  63 128 173 130\n",
      " 191  81]\n",
      "Human score at HITL iteration 2: [0.004365836895902415, 0.000202147565573763, 0.000641826054799399, 0.011290344020938209, 9.388946186224868e-05, 0.11398919161583092, 0.24880497979835076, 0.8008672481070902, 6.426617030847283e-05, 0.007562254759261019, 0.0007049215410369902, 0.06347552377797011, 0.012297955006044442, 7.482046191253079e-05, 0.028110739674265646, 0.001396706195605443, 0.8114713075565998, 0.0024496518682156927, 0.002093711758001343, 0.0022369285662179285]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 13704\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_2/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 4.607325536198914e-06\n",
      "Epoch 1, Loss: 7.084345270413905e-06\n",
      "Epoch 1, Loss: 9.142866474576294e-06\n",
      "Epoch 1, Loss: 1.0907708201557398e-05\n",
      "Epoch 1, Loss: 1.1223564797546715e-05\n",
      "Epoch 1, Loss: 1.1981734132859856e-05\n",
      "Epoch 1, Loss: 1.2210126442369074e-05\n",
      "Epoch 1, Loss: 1.2715543562080711e-05\n",
      "Epoch 1, Loss: 1.2975979188922793e-05\n",
      "Epoch 1, Loss: 1.3151082384865731e-05\n",
      "Epoch 1, Loss: 1.3340635632630438e-05\n",
      "Epoch 1, Loss: 1.3533448509406298e-05\n",
      "Epoch 1, Loss: 1.3692239008378237e-05\n",
      "Epoch 1, Loss: 1.3786688214167953e-05\n",
      "Epoch 1, Loss: 1.3922654034104198e-05\n",
      "Epoch 1, Loss: 1.4163080777507275e-05\n",
      "Epoch 1, Loss: 1.44397490657866e-05\n",
      "Epoch 1, Loss: 1.4547462342306972e-05\n",
      "Epoch 1, Loss: 1.4723409549333155e-05\n",
      "Epoch 1, Loss: 1.4934201317373663e-05\n",
      "Epoch 1, Loss: 1.5214071027003229e-05\n",
      "Epoch 1, Loss: 1.5461380826309323e-05\n",
      "Epoch 1, Loss: 1.5720324881840497e-05\n",
      "Epoch 1, Loss: 1.608118327567354e-05\n",
      "Epoch 1, Loss: 1.6410209354944527e-05\n",
      "Epoch 1, Loss: 1.6503981896676123e-05\n",
      "Epoch 1, Loss: 1.6692203644197434e-05\n",
      "Epoch 1, Loss: 1.695854007266462e-05\n",
      "Epoch 1, Loss: 1.7086960724554956e-05\n",
      "Epoch 1, Loss: 1.7539277905598283e-05\n",
      "Epoch 1, Loss: 1.7833583115134388e-05\n",
      "Epoch 1, Loss: 1.7907274013850838e-05\n",
      "Epoch 1, Loss: 1.8062586605083197e-05\n",
      "Epoch 1, Loss: 1.816459553083405e-05\n",
      "Epoch 1, Loss: 1.8343809642829e-05\n",
      "Epoch 1, Loss: 1.8404687580186874e-05\n",
      "Epoch 1, Loss: 1.862645149230957e-05\n",
      "Epoch 1, Loss: 1.8673541489988565e-05\n",
      "Epoch 1, Loss: 1.889519626274705e-05\n",
      "Epoch 1, Loss: 1.9233870261814445e-05\n",
      "Epoch 1, Loss: 1.935381442308426e-05\n",
      "Epoch 1, Loss: 1.9519713532645255e-05\n",
      "Epoch 1, Loss: 1.958553184522316e-05\n",
      "Epoch 1, Loss: 1.982539106393233e-05\n",
      "Epoch 1, Loss: 2.015800419030711e-05\n",
      "Epoch 1, Loss: 2.049651084234938e-05\n",
      "Epoch 1, Loss: 2.06557524506934e-05\n",
      "Epoch 1, Loss: 2.0739105821121484e-05\n",
      "Epoch 1, Loss: 2.0837462216150016e-05\n",
      "Epoch 1, Loss: 2.1120977180544287e-05\n",
      "Epoch 1, Loss: 2.1211184503044933e-05\n",
      "Epoch 1, Loss: 2.139493153663352e-05\n",
      "Epoch 1, Loss: 2.172392123611644e-05\n",
      "Epoch 1, Loss: 2.186250640079379e-05\n",
      "Epoch 1, Loss: 2.1945757907815278e-05\n",
      "Epoch 1, Loss: 2.2056716261431575e-05\n",
      "Epoch 1, Loss: 2.2675201762467623e-05\n",
      "Epoch 1, Loss: 2.2935186279937625e-05\n",
      "Epoch 1, Loss: 2.316538302693516e-05\n",
      "Epoch 1, Loss: 2.336131001356989e-05\n",
      "Epoch 1, Loss: 2.3477026843465865e-05\n",
      "Epoch 1, Loss: 2.371407754253596e-05\n",
      "Epoch 1, Loss: 2.386766573181376e-05\n",
      "Epoch 1, Loss: 2.4317130737472326e-05\n",
      "Epoch 1, Loss: 2.4484252207912505e-05\n",
      "Epoch 1, Loss: 2.4614833819214255e-05\n",
      "Epoch 1, Loss: 2.4879402189981192e-05\n",
      "Epoch 1, Loss: 2.4983397452160716e-05\n",
      "Epoch 1, Loss: 2.5053435820154846e-05\n",
      "Epoch 1, Loss: 2.5211877073161304e-05\n",
      "Epoch 1, Loss: 2.5402659957762808e-05\n",
      "Epoch 1, Loss: 2.5460394681431353e-05\n",
      "Epoch 1, Loss: 2.5709232431836426e-05\n",
      "Epoch 1, Loss: 2.5918197934515774e-05\n",
      "Epoch 1, Loss: 2.598925493657589e-05\n",
      "Epoch 1, Loss: 2.6024645194411278e-05\n",
      "Epoch 1, Loss: 2.6241767045576125e-05\n",
      "Epoch 1, Loss: 2.646470966283232e-05\n",
      "Epoch 1, Loss: 2.6660381990950555e-05\n",
      "Epoch 1, Loss: 2.683323691599071e-05\n",
      "Epoch 1, Loss: 2.7009846235159785e-05\n",
      "Epoch 1, Loss: 2.7220870833843946e-05\n",
      "Epoch 1, Loss: 2.7345238777343184e-05\n",
      "Epoch 1, Loss: 2.7461283025331795e-05\n",
      "Epoch 1, Loss: 2.7565743948798627e-05\n",
      "Epoch 1, Loss: 2.7921843866351992e-05\n",
      "Epoch 1, Loss: 2.8008813387714326e-05\n",
      "Epoch 1, Loss: 2.814087929436937e-05\n",
      "Epoch 1, Loss: 2.840280649252236e-05\n",
      "Epoch 1, Loss: 2.8670045139733702e-05\n",
      "Epoch 1, Loss: 2.872432378353551e-05\n",
      "Epoch 1, Loss: 2.9121438274160028e-05\n",
      "Epoch 1, Loss: 2.9300128517206758e-05\n",
      "Epoch 1, Loss: 2.954461524495855e-05\n",
      "Epoch 1, Loss: 2.9682960303034633e-05\n",
      "Epoch 1, Loss: 2.994309033965692e-05\n",
      "Epoch 1, Loss: 3.0088252970017493e-05\n",
      "Epoch 1, Loss: 3.0174698622431606e-05\n",
      "Epoch 1, Loss: 3.0465198506135494e-05\n",
      "Epoch 1, Loss: 3.0775081540923566e-05\n",
      "Epoch 1, Loss: 3.094966086791828e-05\n",
      "Epoch 1, Loss: 3.120100882370025e-05\n",
      "Epoch 1, Loss: 3.1352959922514856e-05\n",
      "Epoch 1, Loss: 3.150135307805613e-05\n",
      "Epoch 1, Loss: 3.162916254950687e-05\n",
      "Epoch 1, Loss: 3.1685201975051314e-05\n",
      "Epoch 1, Loss: 3.18813108606264e-05\n",
      "Epoch 1, Loss: 3.225004184059799e-05\n",
      "Epoch 1, Loss: 3.233867755625397e-05\n",
      "Epoch 1, Loss: 3.268567525083199e-05\n",
      "Epoch 1, Loss: 3.2928459404502064e-05\n",
      "Epoch 1, Loss: 3.323046985315159e-05\n",
      "Epoch 1, Loss: 3.3503019949421287e-05\n",
      "Epoch 1, Loss: 3.4020646126009524e-05\n",
      "Epoch 1, Loss: 3.413748345337808e-05\n",
      "Epoch 1, Loss: 3.427865158300847e-05\n",
      "Epoch 1, Loss: 3.471002128208056e-05\n",
      "Epoch 1, Loss: 3.4800868888851255e-05\n",
      "Epoch 1, Loss: 3.4996672184206545e-05\n",
      "Epoch 1, Loss: 3.508468216750771e-05\n",
      "Epoch 1, Loss: 3.537209704518318e-05\n",
      "Epoch 1, Loss: 3.545430809026584e-05\n",
      "Epoch 1, Loss: 3.565697988960892e-05\n",
      "Epoch 1, Loss: 3.574914444470778e-05\n",
      "Epoch 1, Loss: 3.59815385309048e-05\n",
      "Epoch 1, Loss: 3.6228098906576633e-05\n",
      "Epoch 1, Loss: 3.6374112823978066e-05\n",
      "Epoch 1, Loss: 3.65739906555973e-05\n",
      "Epoch 1, Loss: 3.683472459670156e-05\n",
      "Epoch 1, Loss: 3.691870369948447e-05\n",
      "Epoch 1, Loss: 3.707504947669804e-05\n",
      "Epoch 1, Loss: 3.719658707268536e-05\n",
      "Epoch 1, Loss: 3.7378049455583096e-05\n",
      "Epoch 1, Loss: 3.749268944375217e-05\n",
      "Epoch 1, Loss: 3.7552861613221467e-05\n",
      "Epoch 1, Loss: 3.766936424653977e-05\n",
      "Epoch 1, Loss: 3.786609158851206e-05\n",
      "Epoch 1, Loss: 3.802048013312742e-05\n",
      "Epoch 1, Loss: 3.8307218346744776e-05\n",
      "Epoch 1, Loss: 3.8546328141819686e-05\n",
      "Epoch 1, Loss: 3.8827754906378686e-05\n",
      "Epoch 1, Loss: 3.890466905431822e-05\n",
      "Epoch 1, Loss: 3.947684308513999e-05\n",
      "Epoch 1, Loss: 3.964186180382967e-05\n",
      "Epoch 1, Loss: 3.9689301047474146e-05\n",
      "Epoch 1, Loss: 4.000898479716852e-05\n",
      "Epoch 1, Loss: 4.012698627775535e-05\n",
      "Epoch 1, Loss: 4.022787470603362e-05\n",
      "Epoch 1, Loss: 4.030956915812567e-05\n",
      "Epoch 1, Loss: 4.038437327835709e-05\n",
      "Epoch 1, Loss: 4.061192157678306e-05\n",
      "Epoch 1, Loss: 4.108512803213671e-05\n",
      "Epoch 1, Loss: 4.125270061194897e-05\n",
      "Epoch 1, Loss: 4.143377736909315e-05\n",
      "Epoch 1, Loss: 4.1635918023530394e-05\n",
      "Epoch 1, Loss: 4.171964974375442e-05\n",
      "Epoch 1, Loss: 4.2111445509362966e-05\n",
      "Epoch 1, Loss: 4.2452928028069437e-05\n",
      "Epoch 1, Loss: 4.2548359488137066e-05\n",
      "Epoch 1, Loss: 4.27094055339694e-05\n",
      "Epoch 1, Loss: 4.283542511984706e-05\n",
      "Epoch 1, Loss: 4.2937004764098674e-05\n",
      "Epoch 1, Loss: 4.301132867112756e-05\n",
      "Epoch 1, Loss: 4.31961816502735e-05\n",
      "Epoch 1, Loss: 4.329978401074186e-05\n",
      "Epoch 1, Loss: 4.34208704973571e-05\n",
      "Epoch 1, Loss: 4.359854938229546e-05\n",
      "Epoch 1, Loss: 4.3651190935634077e-05\n",
      "Epoch 1, Loss: 4.3710584577638656e-05\n",
      "Epoch 1, Loss: 4.389863897813484e-05\n",
      "Epoch 1, Loss: 4.4227046601008624e-05\n",
      "Epoch 1, Loss: 4.4329557567834854e-05\n",
      "Epoch 1, Loss: 4.440562042873353e-05\n",
      "Epoch 1, Loss: 4.447955871000886e-05\n",
      "Epoch 1, Loss: 4.474713932722807e-05\n",
      "Epoch 1, Loss: 4.483671364141628e-05\n",
      "Epoch 1, Loss: 4.522209201240912e-05\n",
      "Epoch 1, Loss: 4.5547785703092813e-05\n",
      "Epoch 1, Loss: 4.585715942084789e-05\n",
      "Epoch 1, Loss: 4.599826206685975e-05\n",
      "Epoch 1, Loss: 4.614492354448885e-05\n",
      "Epoch 1, Loss: 4.6289256715681404e-05\n",
      "Epoch 1, Loss: 4.6613036829512566e-05\n",
      "Epoch 1, Loss: 4.664684092858806e-05\n",
      "Epoch 1, Loss: 4.684702435042709e-05\n",
      "Epoch 1, Loss: 4.716595867648721e-05\n",
      "Epoch 1, Loss: 4.7345929488074034e-05\n",
      "Epoch 1, Loss: 4.7510133299510926e-05\n",
      "Epoch 1, Loss: 4.769641236634925e-05\n",
      "Epoch 1, Loss: 4.792329127667472e-05\n",
      "Epoch 1, Loss: 4.8130292270798236e-05\n",
      "Epoch 1, Loss: 4.8246001824736595e-05\n",
      "Epoch 1, Loss: 4.8352878366131335e-05\n",
      "Epoch 1, Loss: 4.839553002966568e-05\n",
      "Epoch 1, Loss: 4.843269562115893e-05\n",
      "Epoch 1, Loss: 4.9139656766783446e-05\n",
      "Epoch 1, Loss: 4.934515163768083e-05\n",
      "Epoch 1, Loss: 4.956005432177335e-05\n",
      "Epoch 1, Loss: 4.983332473784685e-05\n",
      "Epoch 1, Loss: 5.0034141167998314e-05\n",
      "Epoch 1, Loss: 5.0292386731598526e-05\n",
      "Epoch 1, Loss: 5.0443959480617195e-05\n",
      "Epoch 1, Loss: 5.065972072770819e-05\n",
      "Epoch 1, Loss: 5.0773545808624476e-05\n",
      "Epoch 1, Loss: 5.084733129478991e-05\n",
      "Epoch 1, Loss: 5.0878348702099174e-05\n",
      "Epoch 1, Loss: 5.113038787385449e-05\n",
      "Epoch 1, Loss: 5.1305141823831946e-05\n",
      "Epoch 1, Loss: 5.151020741323009e-05\n",
      "Epoch 1, Loss: 5.186667840462178e-05\n",
      "Epoch 1, Loss: 5.194868572289124e-05\n",
      "Epoch 1, Loss: 5.214202974457294e-05\n",
      "Epoch 1, Loss: 5.224227788858116e-05\n",
      "Epoch 1, Loss: 5.262799822958186e-05\n",
      "Epoch 1, Loss: 0.00042132247472181916\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_3/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_3/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 3: [146 132 158  68 118 108 125  33 145  45 159 165  86  78   3  54  47  90\n",
      "  19 156]\n",
      "Human score at HITL iteration 3: [0.02627046582450695, 0.0034771538695879877, 0.005005813824014194, 0.0014245106681679003, 0.008895890102583584, 0.003141030401033358, 0.002850085616142974, 0.0981545205955175, 0.0038414241005798014, 0.004060165998143026, 0.012283624808402201, 0.044367812240061866, 0.9413119806227995, 0.8997606981277597, 0.7002131121040605, 0.10959259800159014, 0.19236336689618536, 0.005213221680772978, 0.000834108531664901, 0.22640262707012987]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 14844\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_3/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.6366393538191915e-06\n",
      "Epoch 1, Loss: 2.6208508643321693e-06\n",
      "Epoch 1, Loss: 3.08601011056453e-06\n",
      "Epoch 1, Loss: 3.884946636389941e-06\n",
      "Epoch 1, Loss: 4.266490577720106e-06\n",
      "Epoch 1, Loss: 4.506131517700851e-06\n",
      "Epoch 1, Loss: 7.608010491821915e-06\n",
      "Epoch 1, Loss: 8.103947038762271e-06\n",
      "Epoch 1, Loss: 8.339899068232626e-06\n",
      "Epoch 1, Loss: 1.1836302292067558e-05\n",
      "Epoch 1, Loss: 1.2757089280057698e-05\n",
      "Epoch 1, Loss: 1.406137744197622e-05\n",
      "Epoch 1, Loss: 1.4409182767849416e-05\n",
      "Epoch 1, Loss: 1.4647681382484734e-05\n",
      "Epoch 1, Loss: 1.5704288671258837e-05\n",
      "Epoch 1, Loss: 1.5912002709228545e-05\n",
      "Epoch 1, Loss: 1.6308527847286314e-05\n",
      "Epoch 1, Loss: 1.6598300135228783e-05\n",
      "Epoch 1, Loss: 1.700986467767507e-05\n",
      "Epoch 1, Loss: 1.731979864416644e-05\n",
      "Epoch 1, Loss: 1.751429954310879e-05\n",
      "Epoch 1, Loss: 1.802446786314249e-05\n",
      "Epoch 1, Loss: 1.8188780813943595e-05\n",
      "Epoch 1, Loss: 1.835271541494876e-05\n",
      "Epoch 1, Loss: 1.8487909983377904e-05\n",
      "Epoch 1, Loss: 1.8591097614262253e-05\n",
      "Epoch 1, Loss: 1.8749837181530893e-05\n",
      "Epoch 1, Loss: 1.889175473479554e-05\n",
      "Epoch 1, Loss: 1.9300918211229146e-05\n",
      "Epoch 1, Loss: 1.948688441189006e-05\n",
      "Epoch 1, Loss: 1.9877457816619426e-05\n",
      "Epoch 1, Loss: 2.020889223786071e-05\n",
      "Epoch 1, Loss: 2.0322841010056436e-05\n",
      "Epoch 1, Loss: 2.0565043087117374e-05\n",
      "Epoch 1, Loss: 2.0867293642368168e-05\n",
      "Epoch 1, Loss: 2.10042271646671e-05\n",
      "Epoch 1, Loss: 2.124043385265395e-05\n",
      "Epoch 1, Loss: 2.14370375033468e-05\n",
      "Epoch 1, Loss: 2.1567189833149314e-05\n",
      "Epoch 1, Loss: 2.1665706299245358e-05\n",
      "Epoch 1, Loss: 2.1929437934886664e-05\n",
      "Epoch 1, Loss: 2.2138498025014997e-05\n",
      "Epoch 1, Loss: 2.2201231331564486e-05\n",
      "Epoch 1, Loss: 2.248436794616282e-05\n",
      "Epoch 1, Loss: 2.2662978153675795e-05\n",
      "Epoch 1, Loss: 2.2705229639541358e-05\n",
      "Epoch 1, Loss: 2.303737710462883e-05\n",
      "Epoch 1, Loss: 2.320096973562613e-05\n",
      "Epoch 1, Loss: 2.335188037250191e-05\n",
      "Epoch 1, Loss: 2.3556443920824677e-05\n",
      "Epoch 1, Loss: 2.392125315964222e-05\n",
      "Epoch 1, Loss: 2.4031825887504965e-05\n",
      "Epoch 1, Loss: 2.4184235371649265e-05\n",
      "Epoch 1, Loss: 2.4351596948690712e-05\n",
      "Epoch 1, Loss: 2.454718924127519e-05\n",
      "Epoch 1, Loss: 2.4603665224276483e-05\n",
      "Epoch 1, Loss: 2.48666328843683e-05\n",
      "Epoch 1, Loss: 2.5107401597779244e-05\n",
      "Epoch 1, Loss: 2.5281078706029803e-05\n",
      "Epoch 1, Loss: 2.5525980163365602e-05\n",
      "Epoch 1, Loss: 2.579251304268837e-05\n",
      "Epoch 1, Loss: 2.5984983949456364e-05\n",
      "Epoch 1, Loss: 2.6189052732661366e-05\n",
      "Epoch 1, Loss: 2.639520971570164e-05\n",
      "Epoch 1, Loss: 2.6459674700163305e-05\n",
      "Epoch 1, Loss: 2.689706889213994e-05\n",
      "Epoch 1, Loss: 2.7140966267324984e-05\n",
      "Epoch 1, Loss: 2.747120743151754e-05\n",
      "Epoch 1, Loss: 2.773728920146823e-05\n",
      "Epoch 1, Loss: 2.801889058900997e-05\n",
      "Epoch 1, Loss: 2.832080645021051e-05\n",
      "Epoch 1, Loss: 2.8407237550709397e-05\n",
      "Epoch 1, Loss: 2.8882306651212275e-05\n",
      "Epoch 1, Loss: 2.9095346690155566e-05\n",
      "Epoch 1, Loss: 2.9350478143896908e-05\n",
      "Epoch 1, Loss: 2.9680297302547842e-05\n",
      "Epoch 1, Loss: 2.980622957693413e-05\n",
      "Epoch 1, Loss: 3.006983024533838e-05\n",
      "Epoch 1, Loss: 3.0155526474118233e-05\n",
      "Epoch 1, Loss: 3.0325230909511447e-05\n",
      "Epoch 1, Loss: 3.0439703550655395e-05\n",
      "Epoch 1, Loss: 3.0695213354192674e-05\n",
      "Epoch 1, Loss: 3.079404268646613e-05\n",
      "Epoch 1, Loss: 3.1045063224155456e-05\n",
      "Epoch 1, Loss: 3.125608782283962e-05\n",
      "Epoch 1, Loss: 3.1484880310017616e-05\n",
      "Epoch 1, Loss: 3.1642361136619e-05\n",
      "Epoch 1, Loss: 3.169891715515405e-05\n",
      "Epoch 1, Loss: 3.181369538651779e-05\n",
      "Epoch 1, Loss: 3.21576590067707e-05\n",
      "Epoch 1, Loss: 3.2370830012951046e-05\n",
      "Epoch 1, Loss: 3.248293069191277e-05\n",
      "Epoch 1, Loss: 3.290548920631409e-05\n",
      "Epoch 1, Loss: 3.307811130071059e-05\n",
      "Epoch 1, Loss: 3.3209224056918174e-05\n",
      "Epoch 1, Loss: 3.335557266836986e-05\n",
      "Epoch 1, Loss: 3.342347190482542e-05\n",
      "Epoch 1, Loss: 3.390821802895516e-05\n",
      "Epoch 1, Loss: 3.406942414585501e-05\n",
      "Epoch 1, Loss: 3.439604915911332e-05\n",
      "Epoch 1, Loss: 3.459884464973584e-05\n",
      "Epoch 1, Loss: 3.4721648262348026e-05\n",
      "Epoch 1, Loss: 3.482080501271412e-05\n",
      "Epoch 1, Loss: 3.502182516967878e-05\n",
      "Epoch 1, Loss: 3.529706737026572e-05\n",
      "Epoch 1, Loss: 3.5406694223638624e-05\n",
      "Epoch 1, Loss: 3.56199307134375e-05\n",
      "Epoch 1, Loss: 3.5866651160176843e-05\n",
      "Epoch 1, Loss: 3.609815757954493e-05\n",
      "Epoch 1, Loss: 3.645300603238866e-05\n",
      "Epoch 1, Loss: 3.664234100142494e-05\n",
      "Epoch 1, Loss: 3.6704666854348034e-05\n",
      "Epoch 1, Loss: 3.701972309499979e-05\n",
      "Epoch 1, Loss: 3.726722934516147e-05\n",
      "Epoch 1, Loss: 3.733417543116957e-05\n",
      "Epoch 1, Loss: 3.738213854376227e-05\n",
      "Epoch 1, Loss: 3.764354914892465e-05\n",
      "Epoch 1, Loss: 3.8168655009940267e-05\n",
      "Epoch 1, Loss: 3.834268864011392e-05\n",
      "Epoch 1, Loss: 3.852065128739923e-05\n",
      "Epoch 1, Loss: 3.881391603499651e-05\n",
      "Epoch 1, Loss: 3.8975638744886965e-05\n",
      "Epoch 1, Loss: 3.921699681086466e-05\n",
      "Epoch 1, Loss: 3.9387123251799494e-05\n",
      "Epoch 1, Loss: 3.945916978409514e-05\n",
      "Epoch 1, Loss: 3.97110270569101e-05\n",
      "Epoch 1, Loss: 3.987176751252264e-05\n",
      "Epoch 1, Loss: 4.008200630778447e-05\n",
      "Epoch 1, Loss: 4.023721703561023e-05\n",
      "Epoch 1, Loss: 4.043488297611475e-05\n",
      "Epoch 1, Loss: 4.051020368933678e-05\n",
      "Epoch 1, Loss: 4.05970131396316e-05\n",
      "Epoch 1, Loss: 4.077731864526868e-05\n",
      "Epoch 1, Loss: 4.11078508477658e-05\n",
      "Epoch 1, Loss: 4.159230593359098e-05\n",
      "Epoch 1, Loss: 4.1819010220933706e-05\n",
      "Epoch 1, Loss: 4.209271719446406e-05\n",
      "Epoch 1, Loss: 4.2545572796370834e-05\n",
      "Epoch 1, Loss: 4.2811814637389034e-05\n",
      "Epoch 1, Loss: 4.307017661631107e-05\n",
      "Epoch 1, Loss: 4.315064870752394e-05\n",
      "Epoch 1, Loss: 4.326309863245115e-05\n",
      "Epoch 1, Loss: 4.341469320934266e-05\n",
      "Epoch 1, Loss: 4.4116641220171005e-05\n",
      "Epoch 1, Loss: 4.422319761943072e-05\n",
      "Epoch 1, Loss: 4.43376338807866e-05\n",
      "Epoch 1, Loss: 4.461986100068316e-05\n",
      "Epoch 1, Loss: 4.484570672502741e-05\n",
      "Epoch 1, Loss: 4.4961700041312724e-05\n",
      "Epoch 1, Loss: 4.5393899199552834e-05\n",
      "Epoch 1, Loss: 4.560875822789967e-05\n",
      "Epoch 1, Loss: 4.5653621782548726e-05\n",
      "Epoch 1, Loss: 4.5714929001405835e-05\n",
      "Epoch 1, Loss: 4.5827997382730246e-05\n",
      "Epoch 1, Loss: 4.594315396388993e-05\n",
      "Epoch 1, Loss: 4.608767630998045e-05\n",
      "Epoch 1, Loss: 4.623005224857479e-05\n",
      "Epoch 1, Loss: 4.66686105937697e-05\n",
      "Epoch 1, Loss: 4.678648110711947e-05\n",
      "Epoch 1, Loss: 4.70140075776726e-05\n",
      "Epoch 1, Loss: 4.712839290732518e-05\n",
      "Epoch 1, Loss: 4.7246307076420635e-05\n",
      "Epoch 1, Loss: 4.734772664960474e-05\n",
      "Epoch 1, Loss: 4.751465894514695e-05\n",
      "Epoch 1, Loss: 4.781829920830205e-05\n",
      "Epoch 1, Loss: 4.835709842154756e-05\n",
      "Epoch 1, Loss: 4.842512134928256e-05\n",
      "Epoch 1, Loss: 4.864088259637356e-05\n",
      "Epoch 1, Loss: 4.878957406617701e-05\n",
      "Epoch 1, Loss: 4.9077549192588776e-05\n",
      "Epoch 1, Loss: 4.922568768961355e-05\n",
      "Epoch 1, Loss: 4.942176747135818e-05\n",
      "Epoch 1, Loss: 4.963827086612582e-05\n",
      "Epoch 1, Loss: 4.980970697943121e-05\n",
      "Epoch 1, Loss: 4.995890776626766e-05\n",
      "Epoch 1, Loss: 5.040410906076431e-05\n",
      "Epoch 1, Loss: 5.053263885201886e-05\n",
      "Epoch 1, Loss: 5.067809979664162e-05\n",
      "Epoch 1, Loss: 5.088424222776666e-05\n",
      "Epoch 1, Loss: 5.131080251885578e-05\n",
      "Epoch 1, Loss: 5.148921627551317e-05\n",
      "Epoch 1, Loss: 5.1726572564803064e-05\n",
      "Epoch 1, Loss: 5.1903210987802595e-05\n",
      "Epoch 1, Loss: 5.196249549044296e-05\n",
      "Epoch 1, Loss: 5.251006950857118e-05\n",
      "Epoch 1, Loss: 5.278062599245459e-05\n",
      "Epoch 1, Loss: 5.2811839850619435e-05\n",
      "Epoch 1, Loss: 5.2940558816771954e-05\n",
      "Epoch 1, Loss: 5.2989569667261094e-05\n",
      "Epoch 1, Loss: 5.319206684362143e-05\n",
      "Epoch 1, Loss: 5.35725339432247e-05\n",
      "Epoch 1, Loss: 5.3627452871296555e-05\n",
      "Epoch 1, Loss: 5.3832925914321095e-05\n",
      "Epoch 1, Loss: 5.389157013269141e-05\n",
      "Epoch 1, Loss: 5.41372355655767e-05\n",
      "Epoch 1, Loss: 5.439794040285051e-05\n",
      "Epoch 1, Loss: 5.4574185924138874e-05\n",
      "Epoch 1, Loss: 5.4845404520165175e-05\n",
      "Epoch 1, Loss: 5.494475772138685e-05\n",
      "Epoch 1, Loss: 5.510298069566488e-05\n",
      "Epoch 1, Loss: 5.5163109209388494e-05\n",
      "Epoch 1, Loss: 5.534010415431112e-05\n",
      "Epoch 1, Loss: 5.552308721235022e-05\n",
      "Epoch 1, Loss: 5.5759861425030977e-05\n",
      "Epoch 1, Loss: 5.608485662378371e-05\n",
      "Epoch 1, Loss: 5.6279037380591035e-05\n",
      "Epoch 1, Loss: 5.6396907893940806e-05\n",
      "Epoch 1, Loss: 5.6508615671191365e-05\n",
      "Epoch 1, Loss: 5.664092896040529e-05\n",
      "Epoch 1, Loss: 5.668697849614546e-05\n",
      "Epoch 1, Loss: 5.701903864974156e-05\n",
      "Epoch 1, Loss: 5.715370934922248e-05\n",
      "Epoch 1, Loss: 5.743370275013149e-05\n",
      "Epoch 1, Loss: 5.763577064499259e-05\n",
      "Epoch 1, Loss: 5.7819197536446154e-05\n",
      "Epoch 1, Loss: 5.7982913858722895e-05\n",
      "Epoch 1, Loss: 5.814350151922554e-05\n",
      "Epoch 1, Loss: 5.821717786602676e-05\n",
      "Epoch 1, Loss: 5.830296140629798e-05\n",
      "Epoch 1, Loss: 5.878173396922648e-05\n",
      "Epoch 1, Loss: 5.894934292882681e-05\n",
      "Epoch 1, Loss: 5.903156124986708e-05\n",
      "Epoch 1, Loss: 5.907392187509686e-05\n",
      "Epoch 1, Loss: 5.927048914600164e-05\n",
      "Epoch 1, Loss: 5.946000601397827e-05\n",
      "Epoch 1, Loss: 5.9669480833690614e-05\n",
      "Epoch 1, Loss: 5.980113928671926e-05\n",
      "Epoch 1, Loss: 5.985205643810332e-05\n",
      "Epoch 1, Loss: 5.991145735606551e-05\n",
      "Epoch 1, Loss: 6.0178572311997414e-05\n",
      "Epoch 1, Loss: 6.034619582351297e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.476912337044875e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_4/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 4\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_4/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 4: [167  69  27 150 198 115  17  41 137  89 153  44 181 177  38 183  11 164\n",
      "  62 176]\n",
      "Human score at HITL iteration 4: [0.0027918714983138065, 0.004861064704245512, 0.025881765437378357, 0.0010180986653650363, 0.03847737304155601, 0.0962525879468358, 0.0070405901087830375, 0.004126609211081756, 0.0036520772715325465, 0.05907877715604976, 0.024389186644517762, 0.984190748159112, 0.0010843426326949456, 0.042837858836568946, 0.3311103985359444, 0.06880520645645927, 0.005830188255276822, 0.03244266825730293, 0.04015282189170953, 8.891235089551587e-05]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 15984\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_4/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 8.256829460151494e-07\n",
      "Epoch 1, Loss: 2.2972599253989756e-06\n",
      "Epoch 1, Loss: 2.6276902644895017e-06\n",
      "Epoch 1, Loss: 3.261142410337925e-06\n",
      "Epoch 1, Loss: 3.996952727902681e-06\n",
      "Epoch 1, Loss: 4.394656571093947e-06\n",
      "Epoch 1, Loss: 4.802735929843038e-06\n",
      "Epoch 1, Loss: 5.294343282002956e-06\n",
      "Epoch 1, Loss: 5.498994141817093e-06\n",
      "Epoch 1, Loss: 5.705362127628177e-06\n",
      "Epoch 1, Loss: 6.012574885971844e-06\n",
      "Epoch 1, Loss: 6.474911060649902e-06\n",
      "Epoch 1, Loss: 6.873378879390657e-06\n",
      "Epoch 1, Loss: 7.213093340396881e-06\n",
      "Epoch 1, Loss: 7.600858225487173e-06\n",
      "Epoch 1, Loss: 7.879207259975374e-06\n",
      "Epoch 1, Loss: 8.147151675075293e-06\n",
      "Epoch 1, Loss: 8.434566552750766e-06\n",
      "Epoch 1, Loss: 8.613809768576175e-06\n",
      "Epoch 1, Loss: 8.753180736675858e-06\n",
      "Epoch 1, Loss: 9.009017958305776e-06\n",
      "Epoch 1, Loss: 9.107090590987355e-06\n",
      "Epoch 1, Loss: 9.391093044541776e-06\n",
      "Epoch 1, Loss: 9.722942195367068e-06\n",
      "Epoch 1, Loss: 1.0134383046533912e-05\n",
      "Epoch 1, Loss: 1.0336363629903644e-05\n",
      "Epoch 1, Loss: 1.0650001058820635e-05\n",
      "Epoch 1, Loss: 1.102998066926375e-05\n",
      "Epoch 1, Loss: 1.1355223250575364e-05\n",
      "Epoch 1, Loss: 1.1444019037298858e-05\n",
      "Epoch 1, Loss: 1.1567659385036677e-05\n",
      "Epoch 1, Loss: 1.2042233720421791e-05\n",
      "Epoch 1, Loss: 1.2570191756822169e-05\n",
      "Epoch 1, Loss: 1.2622855138033628e-05\n",
      "Epoch 1, Loss: 1.2841024727094918e-05\n",
      "Epoch 1, Loss: 1.3263597793411463e-05\n",
      "Epoch 1, Loss: 1.3463351933751255e-05\n",
      "Epoch 1, Loss: 1.3747921911999583e-05\n",
      "Epoch 1, Loss: 1.3992328604217619e-05\n",
      "Epoch 1, Loss: 1.4237863069865853e-05\n",
      "Epoch 1, Loss: 1.4528653991874307e-05\n",
      "Epoch 1, Loss: 1.4687648217659444e-05\n",
      "Epoch 1, Loss: 1.4960329281166196e-05\n",
      "Epoch 1, Loss: 1.5091289242263883e-05\n",
      "Epoch 1, Loss: 1.5343772247433662e-05\n",
      "Epoch 1, Loss: 1.602182601345703e-05\n",
      "Epoch 1, Loss: 1.6238402167800814e-05\n",
      "Epoch 1, Loss: 1.6391946701332927e-05\n",
      "Epoch 1, Loss: 1.6669982869643718e-05\n",
      "Epoch 1, Loss: 1.706340117380023e-05\n",
      "Epoch 1, Loss: 1.728736242512241e-05\n",
      "Epoch 1, Loss: 1.7496808141004294e-05\n",
      "Epoch 1, Loss: 1.7620783182792366e-05\n",
      "Epoch 1, Loss: 1.7902115359902382e-05\n",
      "Epoch 1, Loss: 1.8061873561237007e-05\n",
      "Epoch 1, Loss: 1.8158054444938898e-05\n",
      "Epoch 1, Loss: 1.8361170077696443e-05\n",
      "Epoch 1, Loss: 1.849190448410809e-05\n",
      "Epoch 1, Loss: 1.8609454855322838e-05\n",
      "Epoch 1, Loss: 1.8717757484409958e-05\n",
      "Epoch 1, Loss: 1.890533894766122e-05\n",
      "Epoch 1, Loss: 1.9136634364258498e-05\n",
      "Epoch 1, Loss: 1.9387960492167622e-05\n",
      "Epoch 1, Loss: 1.94577150978148e-05\n",
      "Epoch 1, Loss: 1.955824700416997e-05\n",
      "Epoch 1, Loss: 1.972523023141548e-05\n",
      "Epoch 1, Loss: 1.975307532120496e-05\n",
      "Epoch 1, Loss: 1.9978608179371804e-05\n",
      "Epoch 1, Loss: 2.005723217735067e-05\n",
      "Epoch 1, Loss: 2.0211846276652068e-05\n",
      "Epoch 1, Loss: 2.040089020738378e-05\n",
      "Epoch 1, Loss: 2.0780644263140857e-05\n",
      "Epoch 1, Loss: 2.0928782760165632e-05\n",
      "Epoch 1, Loss: 2.1079111320432276e-05\n",
      "Epoch 1, Loss: 2.1188869141042233e-05\n",
      "Epoch 1, Loss: 2.1316045604180545e-05\n",
      "Epoch 1, Loss: 2.1424064470920712e-05\n",
      "Epoch 1, Loss: 2.1661522623617202e-05\n",
      "Epoch 1, Loss: 2.1708103304263204e-05\n",
      "Epoch 1, Loss: 2.1736035705544055e-05\n",
      "Epoch 1, Loss: 2.177502028644085e-05\n",
      "Epoch 1, Loss: 2.1965250198263675e-05\n",
      "Epoch 1, Loss: 2.1990454115439206e-05\n",
      "Epoch 1, Loss: 2.2175685444381088e-05\n",
      "Epoch 1, Loss: 2.226138167316094e-05\n",
      "Epoch 1, Loss: 2.249857789138332e-05\n",
      "Epoch 1, Loss: 2.2865984647069126e-05\n",
      "Epoch 1, Loss: 2.3170447093434632e-05\n",
      "Epoch 1, Loss: 2.3318083549384028e-05\n",
      "Epoch 1, Loss: 2.343906817259267e-05\n",
      "Epoch 1, Loss: 2.3642074665986e-05\n",
      "Epoch 1, Loss: 2.3892724129837006e-05\n",
      "Epoch 1, Loss: 2.4074019165709615e-05\n",
      "Epoch 1, Loss: 2.415676135569811e-05\n",
      "Epoch 1, Loss: 2.4531385861337185e-05\n",
      "Epoch 1, Loss: 2.4805973225738853e-05\n",
      "Epoch 1, Loss: 2.4975226551759988e-05\n",
      "Epoch 1, Loss: 2.514664811315015e-05\n",
      "Epoch 1, Loss: 2.5506749807391316e-05\n",
      "Epoch 1, Loss: 2.5692934286780655e-05\n",
      "Epoch 1, Loss: 2.5730048946570605e-05\n",
      "Epoch 1, Loss: 2.608183422125876e-05\n",
      "Epoch 1, Loss: 2.6601614081300795e-05\n",
      "Epoch 1, Loss: 2.701114135561511e-05\n",
      "Epoch 1, Loss: 2.7302194212097675e-05\n",
      "Epoch 1, Loss: 2.763227530522272e-05\n",
      "Epoch 1, Loss: 2.784251410048455e-05\n",
      "Epoch 1, Loss: 2.8192836907692254e-05\n",
      "Epoch 1, Loss: 2.8471826226450503e-05\n",
      "Epoch 1, Loss: 2.8549242415465415e-05\n",
      "Epoch 1, Loss: 2.8851281967945397e-05\n",
      "Epoch 1, Loss: 2.904597931774333e-05\n",
      "Epoch 1, Loss: 2.9234826797619462e-05\n",
      "Epoch 1, Loss: 2.9507078579626977e-05\n",
      "Epoch 1, Loss: 2.9617862310260534e-05\n",
      "Epoch 1, Loss: 2.9862349038012326e-05\n",
      "Epoch 1, Loss: 3.0094888643361628e-05\n",
      "Epoch 1, Loss: 3.0355418857652694e-05\n",
      "Epoch 1, Loss: 3.057382127735764e-05\n",
      "Epoch 1, Loss: 3.0793395126238465e-05\n",
      "Epoch 1, Loss: 3.0970724765211344e-05\n",
      "Epoch 1, Loss: 3.1101815693546087e-05\n",
      "Epoch 1, Loss: 3.137154271826148e-05\n",
      "Epoch 1, Loss: 3.147606912534684e-05\n",
      "Epoch 1, Loss: 3.159081097692251e-05\n",
      "Epoch 1, Loss: 3.173401637468487e-05\n",
      "Epoch 1, Loss: 3.193959855707362e-05\n",
      "Epoch 1, Loss: 3.207848931197077e-05\n",
      "Epoch 1, Loss: 3.23415151797235e-05\n",
      "Epoch 1, Loss: 3.240650403313339e-05\n",
      "Epoch 1, Loss: 3.257869684603065e-05\n",
      "Epoch 1, Loss: 3.266584826633334e-05\n",
      "Epoch 1, Loss: 3.2763375202193856e-05\n",
      "Epoch 1, Loss: 3.288575680926442e-05\n",
      "Epoch 1, Loss: 3.307950828457251e-05\n",
      "Epoch 1, Loss: 3.32846466335468e-05\n",
      "Epoch 1, Loss: 3.341159754199907e-05\n",
      "Epoch 1, Loss: 3.356063098181039e-05\n",
      "Epoch 1, Loss: 3.3794567571021616e-05\n",
      "Epoch 1, Loss: 3.385578020242974e-05\n",
      "Epoch 1, Loss: 3.4005795896518975e-05\n",
      "Epoch 1, Loss: 3.411289071664214e-05\n",
      "Epoch 1, Loss: 3.443864989094436e-05\n",
      "Epoch 1, Loss: 3.465671761659905e-05\n",
      "Epoch 1, Loss: 3.476726124063134e-05\n",
      "Epoch 1, Loss: 3.488686343189329e-05\n",
      "Epoch 1, Loss: 3.5079945519100875e-05\n",
      "Epoch 1, Loss: 3.530283720465377e-05\n",
      "Epoch 1, Loss: 3.546312655089423e-05\n",
      "Epoch 1, Loss: 3.562230267561972e-05\n",
      "Epoch 1, Loss: 3.572260175133124e-05\n",
      "Epoch 1, Loss: 3.594645386328921e-05\n",
      "Epoch 1, Loss: 3.619466588133946e-05\n",
      "Epoch 1, Loss: 3.642911906354129e-05\n",
      "Epoch 1, Loss: 3.666319389594719e-05\n",
      "Epoch 1, Loss: 3.6803059629164636e-05\n",
      "Epoch 1, Loss: 3.718792868312448e-05\n",
      "Epoch 1, Loss: 3.7320394767448306e-05\n",
      "Epoch 1, Loss: 3.7362653529271483e-05\n",
      "Epoch 1, Loss: 3.743932757060975e-05\n",
      "Epoch 1, Loss: 3.755115903913975e-05\n",
      "Epoch 1, Loss: 3.7750120100099593e-05\n",
      "Epoch 1, Loss: 3.798802208621055e-05\n",
      "Epoch 1, Loss: 3.828844637610018e-05\n",
      "Epoch 1, Loss: 3.83950537070632e-05\n",
      "Epoch 1, Loss: 3.8554535422008485e-05\n",
      "Epoch 1, Loss: 3.866798215312883e-05\n",
      "Epoch 1, Loss: 3.874916728818789e-05\n",
      "Epoch 1, Loss: 3.886899503413588e-05\n",
      "Epoch 1, Loss: 3.907248901668936e-05\n",
      "Epoch 1, Loss: 3.919317532563582e-05\n",
      "Epoch 1, Loss: 3.949498932342976e-05\n",
      "Epoch 1, Loss: 3.954058047384024e-05\n",
      "Epoch 1, Loss: 3.9793376345187426e-05\n",
      "Epoch 1, Loss: 3.9909762563183904e-05\n",
      "Epoch 1, Loss: 4.011279816040769e-05\n",
      "Epoch 1, Loss: 4.020414053229615e-05\n",
      "Epoch 1, Loss: 4.0279075619764626e-05\n",
      "Epoch 1, Loss: 4.056749457959086e-05\n",
      "Epoch 1, Loss: 4.066358815180138e-05\n",
      "Epoch 1, Loss: 4.1046529076993465e-05\n",
      "Epoch 1, Loss: 4.116065247217193e-05\n",
      "Epoch 1, Loss: 4.1280211007688195e-05\n",
      "Epoch 1, Loss: 4.136718780500814e-05\n",
      "Epoch 1, Loss: 4.140884993830696e-05\n",
      "Epoch 1, Loss: 4.1486870031803846e-05\n",
      "Epoch 1, Loss: 4.151945177000016e-05\n",
      "Epoch 1, Loss: 4.2056220991071314e-05\n",
      "Epoch 1, Loss: 4.220708069624379e-05\n",
      "Epoch 1, Loss: 4.2365842091385275e-05\n",
      "Epoch 1, Loss: 4.250033089192584e-05\n",
      "Epoch 1, Loss: 4.270886711310595e-05\n",
      "Epoch 1, Loss: 4.287798219593242e-05\n",
      "Epoch 1, Loss: 4.3090163671877235e-05\n",
      "Epoch 1, Loss: 4.3127642129547894e-05\n",
      "Epoch 1, Loss: 4.3282991100568324e-05\n",
      "Epoch 1, Loss: 4.335865378379822e-05\n",
      "Epoch 1, Loss: 4.3602107325568795e-05\n",
      "Epoch 1, Loss: 4.373914998723194e-05\n",
      "Epoch 1, Loss: 4.390098183648661e-05\n",
      "Epoch 1, Loss: 4.405988147482276e-05\n",
      "Epoch 1, Loss: 4.439395706867799e-05\n",
      "Epoch 1, Loss: 4.454164445633069e-05\n",
      "Epoch 1, Loss: 4.486414400162175e-05\n",
      "Epoch 1, Loss: 4.506614641286433e-05\n",
      "Epoch 1, Loss: 4.52387539553456e-05\n",
      "Epoch 1, Loss: 4.532262391876429e-05\n",
      "Epoch 1, Loss: 4.5591703383252025e-05\n",
      "Epoch 1, Loss: 4.586255818139762e-05\n",
      "Epoch 1, Loss: 4.5923530706204474e-05\n",
      "Epoch 1, Loss: 4.5984073949512094e-05\n",
      "Epoch 1, Loss: 4.6045402996242046e-05\n",
      "Epoch 1, Loss: 4.6117820602376014e-05\n",
      "Epoch 1, Loss: 4.6252367610577494e-05\n",
      "Epoch 1, Loss: 4.6431967348326e-05\n",
      "Epoch 1, Loss: 4.660576087189838e-05\n",
      "Epoch 1, Loss: 4.6649140131194144e-05\n",
      "Epoch 1, Loss: 4.681781865656376e-05\n",
      "Epoch 1, Loss: 4.697321855928749e-05\n",
      "Epoch 1, Loss: 4.701266152551398e-05\n",
      "Epoch 1, Loss: 4.71135281259194e-05\n",
      "Epoch 1, Loss: 4.7153727791737765e-05\n",
      "Epoch 1, Loss: 4.7416040615644306e-05\n",
      "Epoch 1, Loss: 4.756349517265335e-05\n",
      "Epoch 1, Loss: 4.771095700562e-05\n",
      "Epoch 1, Loss: 4.782305768458173e-05\n",
      "Epoch 1, Loss: 4.815963620785624e-05\n",
      "Epoch 1, Loss: 4.8359623178839684e-05\n",
      "Epoch 1, Loss: 4.846049705520272e-05\n",
      "Epoch 1, Loss: 4.8670044634491205e-05\n",
      "Epoch 1, Loss: 4.875918966718018e-05\n",
      "Epoch 1, Loss: 4.878488107351586e-05\n",
      "Epoch 1, Loss: 4.887382237939164e-05\n",
      "Epoch 1, Loss: 4.918548074783757e-05\n",
      "Epoch 1, Loss: 4.974486364517361e-05\n",
      "Epoch 1, Loss: 4.99030647915788e-05\n",
      "Epoch 1, Loss: 5.0110109441448e-05\n",
      "Epoch 1, Loss: 5.036276706960052e-05\n",
      "Epoch 1, Loss: 5.057563976151869e-05\n",
      "Epoch 1, Loss: 5.065323784947395e-05\n",
      "Epoch 1, Loss: 5.086374585516751e-05\n",
      "Epoch 1, Loss: 5.1271606935188174e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.162915476830676e-05\n",
      "Epoch 1, Loss: 5.205912020755932e-05\n",
      "Epoch 1, Loss: 5.2179348131176084e-05\n",
      "Epoch 1, Loss: 5.237026198301464e-05\n",
      "Epoch 1, Loss: 5.2807838073931634e-05\n",
      "Epoch 1, Loss: 5.2873023378197104e-05\n",
      "Epoch 1, Loss: 5.304151272866875e-05\n",
      "Epoch 1, Loss: 7.081993518909258e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_5/rank_listnet_model.pth\n",
      "----------------------------------\n",
      "HITL iteration = 5\n",
      "Loading Rank ListNet model successfully from output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_5/rank_listnet_model.pth\n",
      "Feedback idx at HITL iteration 5: [100  88 161  71 178 102  35  56 131  94 174 144  73 116 143   7  92 163\n",
      "  48 139]\n",
      "Human score at HITL iteration 5: [0.0049682161807580675, 0.049338805672513614, 0.0015639027418600574, 0.46348893138716946, 0.020501166232387215, 0.0471147762899373, 0.007074101640968472, 0.020065508509959393, 0.0032330964970033642, 0.0020078232577957966, 0.0038765365787949767, 0.003311697117623261, 0.09587405764425329, 0.001203597140694213, 0.0013686659901113768, 0.09968394513892363, 6.632921789793992e-05, 0.017007748573987607, 0.004810220720707243, 0.016509791644411458]\n",
      "New queried dataset size: 1140\n",
      "Combined dataset size: 17124\n",
      "Saved augmented training data at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_3/HITL_iteration_5/iteration_combined_data.csv\n",
      "Epoch 1, Loss: 1.4885226846672595e-06\n",
      "Epoch 1, Loss: 1.7728525563143194e-06\n",
      "Epoch 1, Loss: 2.4631735868752003e-06\n",
      "Epoch 1, Loss: 3.0454466468654573e-06\n",
      "Epoch 1, Loss: 3.949360689148307e-06\n",
      "Epoch 1, Loss: 4.508030542638153e-06\n",
      "Epoch 1, Loss: 5.050111212767661e-06\n",
      "Epoch 1, Loss: 5.2576870075426996e-06\n",
      "Epoch 1, Loss: 5.6668504839763045e-06\n",
      "Epoch 1, Loss: 6.026049959473312e-06\n",
      "Epoch 1, Loss: 6.6044594859704375e-06\n",
      "Epoch 1, Loss: 7.14141788193956e-06\n",
      "Epoch 1, Loss: 7.4116833275184035e-06\n",
      "Epoch 1, Loss: 7.667003956157714e-06\n",
      "Epoch 1, Loss: 7.788825314491987e-06\n",
      "Epoch 1, Loss: 7.941685908008367e-06\n",
      "Epoch 1, Loss: 8.24068411020562e-06\n",
      "Epoch 1, Loss: 8.365081157535315e-06\n",
      "Epoch 1, Loss: 8.664050255902112e-06\n",
      "Epoch 1, Loss: 9.032301022671163e-06\n",
      "Epoch 1, Loss: 9.203809895552695e-06\n",
      "Epoch 1, Loss: 9.482850146014243e-06\n",
      "Epoch 1, Loss: 9.762246918398887e-06\n",
      "Epoch 1, Loss: 1.0081705113407224e-05\n",
      "Epoch 1, Loss: 1.0198898962698877e-05\n",
      "Epoch 1, Loss: 1.0368414223194122e-05\n",
      "Epoch 1, Loss: 1.0665848094504327e-05\n",
      "Epoch 1, Loss: 1.0965275578200817e-05\n",
      "Epoch 1, Loss: 1.1058094969484955e-05\n",
      "Epoch 1, Loss: 1.1262600310146809e-05\n",
      "Epoch 1, Loss: 1.1380012438166887e-05\n",
      "Epoch 1, Loss: 1.1519863619469106e-05\n",
      "Epoch 1, Loss: 1.1624812032096088e-05\n",
      "Epoch 1, Loss: 1.1857984645757824e-05\n",
      "Epoch 1, Loss: 1.200669794343412e-05\n",
      "Epoch 1, Loss: 1.2265467375982553e-05\n",
      "Epoch 1, Loss: 1.2344367860350758e-05\n",
      "Epoch 1, Loss: 1.2441807484719902e-05\n",
      "Epoch 1, Loss: 1.2627962860278785e-05\n",
      "Epoch 1, Loss: 1.3082906662020832e-05\n",
      "Epoch 1, Loss: 1.334088301518932e-05\n",
      "Epoch 1, Loss: 1.347289071418345e-05\n",
      "Epoch 1, Loss: 1.3502867659553885e-05\n",
      "Epoch 1, Loss: 1.3757518900092691e-05\n",
      "Epoch 1, Loss: 1.3979632058180869e-05\n",
      "Epoch 1, Loss: 1.4047851436771452e-05\n",
      "Epoch 1, Loss: 1.4088662283029407e-05\n",
      "Epoch 1, Loss: 1.4125478628557175e-05\n",
      "Epoch 1, Loss: 1.4495832147076726e-05\n",
      "Epoch 1, Loss: 1.4640187146142125e-05\n",
      "Epoch 1, Loss: 1.4811972505412996e-05\n",
      "Epoch 1, Loss: 1.5103774785529822e-05\n",
      "Epoch 1, Loss: 1.51978456415236e-05\n",
      "Epoch 1, Loss: 1.5279532817658037e-05\n",
      "Epoch 1, Loss: 1.5415658708661795e-05\n",
      "Epoch 1, Loss: 1.577986404299736e-05\n",
      "Epoch 1, Loss: 1.5930600056890398e-05\n",
      "Epoch 1, Loss: 1.6098725609481335e-05\n",
      "Epoch 1, Loss: 1.633133797440678e-05\n",
      "Epoch 1, Loss: 1.647214958211407e-05\n",
      "Epoch 1, Loss: 1.654627703828737e-05\n",
      "Epoch 1, Loss: 1.6766156477387995e-05\n",
      "Epoch 1, Loss: 1.6839287127368152e-05\n",
      "Epoch 1, Loss: 1.7059617675840855e-05\n",
      "Epoch 1, Loss: 1.7140366253443062e-05\n",
      "Epoch 1, Loss: 1.719751162454486e-05\n",
      "Epoch 1, Loss: 1.7436628695577383e-05\n",
      "Epoch 1, Loss: 1.7769612895790488e-05\n",
      "Epoch 1, Loss: 1.7903774278238416e-05\n",
      "Epoch 1, Loss: 1.8079954315908253e-05\n",
      "Epoch 1, Loss: 1.8240163626614958e-05\n",
      "Epoch 1, Loss: 1.859816984506324e-05\n",
      "Epoch 1, Loss: 1.863062789198011e-05\n",
      "Epoch 1, Loss: 1.8846214516088367e-05\n",
      "Epoch 1, Loss: 1.89626807696186e-05\n",
      "Epoch 1, Loss: 1.9239014363847673e-05\n",
      "Epoch 1, Loss: 1.9316881662234664e-05\n",
      "Epoch 1, Loss: 1.9544197130016983e-05\n",
      "Epoch 1, Loss: 1.97766930796206e-05\n",
      "Epoch 1, Loss: 1.9955739844590425e-05\n",
      "Epoch 1, Loss: 2.0077015506103635e-05\n",
      "Epoch 1, Loss: 2.0645340555347502e-05\n",
      "Epoch 1, Loss: 2.082638820866123e-05\n",
      "Epoch 1, Loss: 2.088870678562671e-05\n",
      "Epoch 1, Loss: 2.096996468026191e-05\n",
      "Epoch 1, Loss: 2.113234222633764e-05\n",
      "Epoch 1, Loss: 2.149050123989582e-05\n",
      "Epoch 1, Loss: 2.156807022402063e-05\n",
      "Epoch 1, Loss: 2.1647887479048222e-05\n",
      "Epoch 1, Loss: 2.17450360651128e-05\n",
      "Epoch 1, Loss: 2.1816151274833828e-05\n",
      "Epoch 1, Loss: 2.1867468603886664e-05\n",
      "Epoch 1, Loss: 2.1961976017337292e-05\n",
      "Epoch 1, Loss: 2.206218778155744e-05\n",
      "Epoch 1, Loss: 2.2283944417722523e-05\n",
      "Epoch 1, Loss: 2.248249074909836e-05\n",
      "Epoch 1, Loss: 2.2559514036402106e-05\n",
      "Epoch 1, Loss: 2.26310730795376e-05\n",
      "Epoch 1, Loss: 2.2701053239870816e-05\n",
      "Epoch 1, Loss: 2.272935671498999e-05\n",
      "Epoch 1, Loss: 2.306469832547009e-05\n",
      "Epoch 1, Loss: 2.313491131644696e-05\n",
      "Epoch 1, Loss: 2.3232139938045293e-05\n",
      "Epoch 1, Loss: 2.3371248971670866e-05\n",
      "Epoch 1, Loss: 2.3459717340301722e-05\n",
      "Epoch 1, Loss: 2.3523585696239024e-05\n",
      "Epoch 1, Loss: 2.362182567594573e-05\n",
      "Epoch 1, Loss: 2.3665110347792506e-05\n",
      "Epoch 1, Loss: 2.369248977629468e-05\n",
      "Epoch 1, Loss: 2.396939817117527e-05\n",
      "Epoch 1, Loss: 2.4143882910721004e-05\n",
      "Epoch 1, Loss: 2.4199282051995397e-05\n",
      "Epoch 1, Loss: 2.4278117052745074e-05\n",
      "Epoch 1, Loss: 2.4406581360381097e-05\n",
      "Epoch 1, Loss: 2.4560446036048234e-05\n",
      "Epoch 1, Loss: 2.488640893716365e-05\n",
      "Epoch 1, Loss: 2.497437526471913e-05\n",
      "Epoch 1, Loss: 2.5334185920655727e-05\n",
      "Epoch 1, Loss: 2.560074790380895e-05\n",
      "Epoch 1, Loss: 2.583461900940165e-05\n",
      "Epoch 1, Loss: 2.596372360130772e-05\n",
      "Epoch 1, Loss: 2.6046880520880222e-05\n",
      "Epoch 1, Loss: 2.6438756322022527e-05\n",
      "Epoch 1, Loss: 2.6695197448134422e-05\n",
      "Epoch 1, Loss: 2.7043395675718784e-05\n",
      "Epoch 1, Loss: 2.727995888562873e-05\n",
      "Epoch 1, Loss: 2.7548259822651744e-05\n",
      "Epoch 1, Loss: 2.7614660211838782e-05\n",
      "Epoch 1, Loss: 2.7691086870618165e-05\n",
      "Epoch 1, Loss: 2.7761852834373713e-05\n",
      "Epoch 1, Loss: 2.786411641864106e-05\n",
      "Epoch 1, Loss: 2.791251608869061e-05\n",
      "Epoch 1, Loss: 2.8166454285383224e-05\n",
      "Epoch 1, Loss: 2.8216149075888097e-05\n",
      "Epoch 1, Loss: 2.8358481358736753e-05\n",
      "Epoch 1, Loss: 2.864033740479499e-05\n",
      "Epoch 1, Loss: 2.877860242733732e-05\n",
      "Epoch 1, Loss: 2.897750528063625e-05\n",
      "Epoch 1, Loss: 2.9029521101620048e-05\n",
      "Epoch 1, Loss: 2.9073613404762e-05\n",
      "Epoch 1, Loss: 2.92605982394889e-05\n",
      "Epoch 1, Loss: 2.943055733339861e-05\n",
      "Epoch 1, Loss: 2.9487229767255485e-05\n",
      "Epoch 1, Loss: 2.9575639928225428e-05\n",
      "Epoch 1, Loss: 2.9607756005134434e-05\n",
      "Epoch 1, Loss: 2.9976908990647644e-05\n",
      "Epoch 1, Loss: 3.005090547958389e-05\n",
      "Epoch 1, Loss: 3.0251452699303627e-05\n",
      "Epoch 1, Loss: 3.049039514735341e-05\n",
      "Epoch 1, Loss: 3.0621908081229776e-05\n",
      "Epoch 1, Loss: 3.075577114941552e-05\n",
      "Epoch 1, Loss: 3.0850285838823766e-05\n",
      "Epoch 1, Loss: 3.095379361184314e-05\n",
      "Epoch 1, Loss: 3.139923501294106e-05\n",
      "Epoch 1, Loss: 3.155377635266632e-05\n",
      "Epoch 1, Loss: 3.1593459425494075e-05\n",
      "Epoch 1, Loss: 3.193529846612364e-05\n",
      "Epoch 1, Loss: 3.200273204129189e-05\n",
      "Epoch 1, Loss: 3.213385207345709e-05\n",
      "Epoch 1, Loss: 3.225270484108478e-05\n",
      "Epoch 1, Loss: 3.2287985959555954e-05\n",
      "Epoch 1, Loss: 3.2320233003702015e-05\n",
      "Epoch 1, Loss: 3.242246020818129e-05\n",
      "Epoch 1, Loss: 3.2775584259070456e-05\n",
      "Epoch 1, Loss: 3.300266689620912e-05\n",
      "Epoch 1, Loss: 3.3242235076613724e-05\n",
      "Epoch 1, Loss: 3.337433736305684e-05\n",
      "Epoch 1, Loss: 3.355660010129213e-05\n",
      "Epoch 1, Loss: 3.3756929042283446e-05\n",
      "Epoch 1, Loss: 3.379613917786628e-05\n",
      "Epoch 1, Loss: 3.401211142772809e-05\n",
      "Epoch 1, Loss: 3.431417280808091e-05\n",
      "Epoch 1, Loss: 3.439471038291231e-05\n",
      "Epoch 1, Loss: 3.457634738879278e-05\n",
      "Epoch 1, Loss: 3.497482248349115e-05\n",
      "Epoch 1, Loss: 3.532232949510217e-05\n",
      "Epoch 1, Loss: 3.5582794225774705e-05\n",
      "Epoch 1, Loss: 3.590466076275334e-05\n",
      "Epoch 1, Loss: 3.597889735829085e-05\n",
      "Epoch 1, Loss: 3.6041761632077396e-05\n",
      "Epoch 1, Loss: 3.6111763620283455e-05\n",
      "Epoch 1, Loss: 3.620707138907164e-05\n",
      "Epoch 1, Loss: 3.622601070674136e-05\n",
      "Epoch 1, Loss: 3.63961371476762e-05\n",
      "Epoch 1, Loss: 3.650081634987146e-05\n",
      "Epoch 1, Loss: 3.670762089313939e-05\n",
      "Epoch 1, Loss: 3.680236841319129e-05\n",
      "Epoch 1, Loss: 3.6953329981770366e-05\n",
      "Epoch 1, Loss: 3.735377686098218e-05\n",
      "Epoch 1, Loss: 3.7547571992035955e-05\n",
      "Epoch 1, Loss: 3.7587124097626656e-05\n",
      "Epoch 1, Loss: 3.766863665077835e-05\n",
      "Epoch 1, Loss: 3.791108611039817e-05\n",
      "Epoch 1, Loss: 3.8110702007543296e-05\n",
      "Epoch 1, Loss: 3.822944563580677e-05\n",
      "Epoch 1, Loss: 3.8398145989049226e-05\n",
      "Epoch 1, Loss: 3.8663245504722e-05\n",
      "Epoch 1, Loss: 3.8910489820409566e-05\n",
      "Epoch 1, Loss: 3.905346238752827e-05\n",
      "Epoch 1, Loss: 3.911875683115795e-05\n",
      "Epoch 1, Loss: 3.936800203518942e-05\n",
      "Epoch 1, Loss: 3.9610757085029036e-05\n",
      "Epoch 1, Loss: 3.9808073779568076e-05\n",
      "Epoch 1, Loss: 4.0004553738981485e-05\n",
      "Epoch 1, Loss: 4.017324681626633e-05\n",
      "Epoch 1, Loss: 4.038991028210148e-05\n",
      "Epoch 1, Loss: 4.045690729981288e-05\n",
      "Epoch 1, Loss: 4.075081233168021e-05\n",
      "Epoch 1, Loss: 4.09721105825156e-05\n",
      "Epoch 1, Loss: 4.10998982260935e-05\n",
      "Epoch 1, Loss: 4.135235940339044e-05\n",
      "Epoch 1, Loss: 4.1469022107776254e-05\n",
      "Epoch 1, Loss: 4.1545863496139646e-05\n",
      "Epoch 1, Loss: 4.167041333857924e-05\n",
      "Epoch 1, Loss: 4.226285818731412e-05\n",
      "Epoch 1, Loss: 4.236715176375583e-05\n",
      "Epoch 1, Loss: 4.24232057412155e-05\n",
      "Epoch 1, Loss: 4.248669574735686e-05\n",
      "Epoch 1, Loss: 4.25548932980746e-05\n",
      "Epoch 1, Loss: 4.2602776375133544e-05\n",
      "Epoch 1, Loss: 4.2695966840256006e-05\n",
      "Epoch 1, Loss: 4.2824423871934414e-05\n",
      "Epoch 1, Loss: 4.302625166019425e-05\n",
      "Epoch 1, Loss: 4.316958074923605e-05\n",
      "Epoch 1, Loss: 4.3260086385998875e-05\n",
      "Epoch 1, Loss: 4.3472988181747496e-05\n",
      "Epoch 1, Loss: 4.357493162387982e-05\n",
      "Epoch 1, Loss: 4.366211942397058e-05\n",
      "Epoch 1, Loss: 4.376803553896025e-05\n",
      "Epoch 1, Loss: 4.4036620238330215e-05\n",
      "Epoch 1, Loss: 4.448041727300733e-05\n",
      "Epoch 1, Loss: 4.4610809709411114e-05\n",
      "Epoch 1, Loss: 4.4660620915237814e-05\n",
      "Epoch 1, Loss: 4.484229430090636e-05\n",
      "Epoch 1, Loss: 4.515884938882664e-05\n",
      "Epoch 1, Loss: 4.5501663407776505e-05\n",
      "Epoch 1, Loss: 4.560958768706769e-05\n",
      "Epoch 1, Loss: 4.574043850880116e-05\n",
      "Epoch 1, Loss: 4.5838256482966244e-05\n",
      "Epoch 1, Loss: 4.589487798511982e-05\n",
      "Epoch 1, Loss: 4.613673081621528e-05\n",
      "Epoch 1, Loss: 4.637784149963409e-05\n",
      "Epoch 1, Loss: 4.649249603971839e-05\n",
      "Epoch 1, Loss: 4.6669454604852945e-05\n",
      "Epoch 1, Loss: 4.6774330257903785e-05\n",
      "Epoch 1, Loss: 4.6927765652071685e-05\n",
      "Epoch 1, Loss: 4.702209116658196e-05\n",
      "Epoch 1, Loss: 4.71270686830394e-05\n",
      "Epoch 1, Loss: 4.716923285741359e-05\n",
      "Epoch 1, Loss: 4.7306311898864806e-05\n",
      "Epoch 1, Loss: 4.748316132463515e-05\n",
      "Epoch 1, Loss: 4.7533991164527833e-05\n",
      "Epoch 1, Loss: 4.7662681026849896e-05\n",
      "Epoch 1, Loss: 4.768846702063456e-05\n",
      "Epoch 1, Loss: 4.7851630370132625e-05\n",
      "Epoch 1, Loss: 4.805428034160286e-05\n",
      "Epoch 1, Loss: 4.8272522690240294e-05\n",
      "Epoch 1, Loss: 4.840736073674634e-05\n",
      "Epoch 1, Loss: 4.8481721023563296e-05\n",
      "Epoch 1, Loss: 4.859793261857703e-05\n",
      "Epoch 1, Loss: 4.8722446081228554e-05\n",
      "Epoch 1, Loss: 4.8769739805720747e-05\n",
      "Epoch 1, Loss: 4.8984758905135095e-05\n",
      "Epoch 1, Loss: 4.909161361865699e-05\n",
      "Epoch 1, Loss: 4.916265606880188e-05\n",
      "Epoch 1, Loss: 4.9396629037801176e-05\n",
      "Epoch 1, Loss: 4.95261701871641e-05\n",
      "Epoch 1, Loss: 8.82446780299991e-05\n",
      "Saved retrained feedback model at output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_4/HITL_iteration_1/rank_listnet_model.pth\n",
      "=====================================\n",
      "REINVENT round = 4\n",
      "Creating config file: output_rank_listnet_R10_T5_Q20_random_s0.0/REINVENT_round_4/config.json.\n",
      "Run REINVENT\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-117a26bfd45a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0msigma_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# noise level for simulated chemist's responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mchoose_top_smiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of top molecules to choose from scaffold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtraining_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# number of epochs for training the model in each HITL iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-11-7bbb64ed65ca>\u001b[0m in \u001b[0;36mrun_HITL_classify\u001b[0;34m(seed, reinvent_dir, reinvent_env, output_dir, feedback_type, base_training_dataset_path, base_testing_dataset_path, model_pretrained_path, model_pretrained_name, num_rounds, num_iters, num_queries, REINVENT_n_steps, batch_size, acquisition, sigma_noise, choose_top_smiles, training_epochs)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mferr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;31m# Execute the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mferr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Check the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exit code:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m    954\u001b[0m                 \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    957\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1020\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1651\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ReinventCommunity/lib/python3.7/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1609\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "! pip install -e \"/home/springnuance/reinvent-hitl/reinvent-scoring\"\n",
    "\n",
    "seed = 42\n",
    "restart = False # If restart is True, we would rerun everything\n",
    "                # If restart is False, we would continue from the latest found HITL_iteration\n",
    "                \n",
    "# change these path variables as required\n",
    "reinvent_dir = os.path.expanduser(\"/home/springnuance/reinvent-hitl/Reinvent\") # We must use absolute path\n",
    "reinvent_env = os.path.expanduser(\"/home/springnuance/miniconda3/envs/ReinventCommunity\") # We must use absolute path\n",
    "\n",
    "# the performance of the initial model should not be good. Specifically, it should work at 0.5 accuracy \n",
    "# If the model is too good, retrain the model to become weaker, we are trying to make the model to learn via HITL\n",
    "\n",
    "feedback_type = \"ranking\" # scoring, comparing, ranking\n",
    "\n",
    "# feedback type as ranking:\n",
    "# Given N molecules, what are the orders of preference of these molecules regarding DRD2?\n",
    "\n",
    "base_training_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_training_data.csv\"\n",
    "base_testing_dataset_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/small_drd2_testing_data.csv\"\n",
    "model_pretrained_path = \"/home/springnuance/reinvent-hitl/Base-Code-Binh/training_Rank_ListNet_model/rank_listnet_model.pth\"\n",
    "model_pretrained_name = \"rank_listnet_model.pth\"\n",
    "\n",
    "num_rounds = 10 # number of rounds, corresponding to R in the paper\n",
    "num_iters = 5 # number of iterations of showing molecules to the human for feedback at each round\n",
    "REINVENT_n_steps = 25 # number of REINVENT optimization steps\n",
    "\n",
    "# WARNING: CHOOSING LARGER BATCH SIZE WOULD EXPONENTIALLY INCREASE THE NUMBER OF COMBINATIONS\n",
    "# BETTER KEEP IT AT 32 OR 64\n",
    "# For example, REINVENT would fail and return exit code -9 if it is 80\n",
    "\n",
    "batch_size = 32 # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "\n",
    "# Please look at the thompson sampling code and fix it!\n",
    "acquisition = \"random\" # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' \n",
    "\n",
    "sigma_noise = 0.0 # noise level for simulated chemist's responses\n",
    "\n",
    "num_queries = 20 # number of molecules, pairs or a set of molecules, depending on the task, \n",
    "                 # shown to the simulated chemist at each HITL_iteration\n",
    "choose_top_smiles = 200 # number of top molecules to choose from scaffold. \n",
    "\n",
    "training_epochs = 1 # number of epochs for training the model in each HITL iteration\n",
    "\n",
    "output_dir = f\"output_rank_listnet_R{num_rounds}_T{num_iters}_Q{num_queries}_{acquisition}_s{sigma_noise}\"\n",
    "\n",
    "run_HITL_classify(\n",
    "        seed, reinvent_dir, reinvent_env, output_dir, \n",
    "        feedback_type, # scoring, comparing, ranking\n",
    "        base_training_dataset_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        base_testing_dataset_path, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_path, # Path to the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        model_pretrained_name, # Name of the pretrained model before REINVENT_round_1/HITL_iteration_1\n",
    "        num_rounds, # number of rounds, corresponding to R in the paper\n",
    "        num_iters, # number of iterations of showing molecules to the human for feedback at each round, corresponding to T in the paper\n",
    "        num_queries, # number of molecules shown to the simulated chemist at each HITL_iteration\n",
    "        REINVENT_n_steps, # number of REINVENT optimization steps\n",
    "        batch_size, # batch size of the reinforcement learning model, or size of scaffold_memory.csv\n",
    "        acquisition, # acquisition: 'uncertainty', 'random', 'thompson', 'greedy' (if None run with no human interaction)\n",
    "        sigma_noise, # noise level for simulated chemist's responses\n",
    "        choose_top_smiles, # number of top molecules to choose from scaffold\n",
    "        training_epochs, # number of epochs for training the model in each HITL iteration\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cc_env_hitl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
