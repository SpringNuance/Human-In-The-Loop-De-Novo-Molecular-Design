{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **How to run this notebook (command-line)?**\n",
    "1. Install the `ReinventCommunity` environment:\n",
    "`conda env create -f environment.yml`\n",
    "2. Activate the environment:\n",
    "`conda activate ReinventCommunity`\n",
    "3. Execute `jupyter`:\n",
    "`jupyter notebook`\n",
    "4. Copy the link to a browser\n",
    "\n",
    "\n",
    "# `REINVENT 3.2`: reinforcement learning demo\n",
    "The aim of this notebook is to illustrate how `REINVENT` can be used for the _de novo_ design of molecules in a *Reinforcement Learning* (RL) setup. The general idea is to start with a (somewhat) focussed prior and to define a (complex) scoring function from a set of building blocks (*components*) to decide which molecules are \"good\" or \"bad\". Each molecule generated by the _agent_ will thus receive a score from 0 to 1 and this feedback is used to train the agent over time, i.e. to focus it on chemical regions of interest for a given project.\n",
    "\n",
    "![](img/REINVENT_RL_mode.png)\n",
    "\n",
    "One of `REINVENT`'s most powerful features is the flexible way in which the scoring function can be defined. By adding together a multitude of different components, the tool is able to generate molecules that are e.g. predicted to be active against a given target, soluble, non-toxic and below a certain molecular weight - all at the same time. More complex components also allow to enrich in molecules that are e.g. active against a given receptor but not against a set of off-targets, i.e. they are pushed for selectivity.\n",
    "\n",
    "In the following sections, we will show how to set up a fairly complex `REINVENT` run that optimizes molecules to be selective against _Aurora_ kinase (we will use one off-target). In addition, we will set further constraints e.g. the number of hydrogen bond donors, all of which will be optimized in parallel.\n",
    "\n",
    "\n",
    "#### Steps to sucessfully apply `REINVENT`:\n",
    "1. Think about the goals and prepare the input\n",
    "  * Often, we will use predictive models of some sort, e.g. activity models. For those, we calculate fingerprints (e.g. `ECFP` descriptors) and map these input features to some response variable, either as a (binary) classification or regression. For this notebook, we supply two models (Random Forest regressors) for Aurora and B-RAF, which can be found in the `data` subfolder of the `REINVENT` repository. A more detailed description is given below, but usually these models are simple `scikit-learn` models with standard algorithms (Random Forest, SVR, ...).\n",
    "  * Sometimes, we want to generate molecules that match a given (sub-)structure, so we need a way to enforce a match. In the opposite scenario, we want to avoid certain matches (e.g. because we want to move out of IP-crowded chemical space). We can define `SMARTS` to achieve both, see details below.\n",
    "  * Some (physico-chemical) properties are very important and should be incorporated during the RL run. We make use of `RDkit`'s implementation of certain descriptors to e.g. ensure that a maximum number of rings is not exceeded.\n",
    "  * Another important factor is the use of an appropriate _prior_, that embodies much of chemistry learned. We supply one in the `data` subfolder (`augmented.prior`) and will also use it to initialize the agent in this example.\n",
    "2. Chose a `JSON` template (or build from scratch) and update:\n",
    "  * The paths to the prior and initial agent.\n",
    "  * The output paths to the _progress.log_ and _results_ folders (logging).\n",
    "  * The scoring function components (add or delete, update paths and parameters, set weights, ...).\n",
    "3. Run `REINVENT`\n",
    "4. Analysis:\n",
    "  * Inspect the output of the run with `tensorboard`\n",
    "  * Look at the molecules generated in the result directory\n",
    "  * Apply *post-processing* where appropriate\n",
    "\n",
    "To proceed, please update the following code block such that it reflects your system's installation and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is /home/springnuance/reinvent-hitl/Reinvent-Community-Binh/notebooks\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# load dependencies\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import tempfile\n",
    "\n",
    "# --------- change these path variables as required\n",
    "\n",
    "print(\"The current working directory is\", os.getcwd())\n",
    "print(os.path.exists(\"../../Reinvent\"))\n",
    "print(os.path.exists(\"../../../miniconda3/envs/ReinventCommunity\"))\n",
    "print(os.path.exists(\"./REINVENT_complete_use_case_DRD2_demo\"))\n",
    "\n",
    "# --------- change these path variables as required\n",
    "\n",
    "reinvent_dir = os.path.expanduser(\"../../Reinvent\")\n",
    "reinvent_env = os.path.expanduser(\"../../../miniconda3/envs/ReinventCommunity\")\n",
    "output_dir = os.path.expanduser(\"./REINVENT_complete_use_case_DRD2_demo\")\n",
    "\n",
    "# --------- do not change\n",
    "# get the notebook's root path\n",
    "try: ipynb_path\n",
    "except NameError: ipynb_path = os.getcwd()\n",
    "\n",
    "# if required, generate a folder to store the results\n",
    "try:\n",
    "    os.mkdir(output_dir)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the configuration\n",
    "`REINVENT` has an entry point that loads a specified `JSON` file on startup. `JSON` is a low-level data format that allows to specify a fairly large number of parameters in a cascading fashion very quickly. The parameters are structured into *blocks* which can in turn contain blocks or simple values, such as *True* or *False*, strings and numbers. In this tutorial, we will go through the different blocks step-by-step, explaining their purpose and potential values for given parameters. Note, that while we will write out the configuration as a `JSON` file in the end, in `python` we handle the same information as a simple `dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dictionary\n",
    "configuration = {\n",
    "    \"version\": 3,                          # we are going to use REINVENT's newest release\n",
    "    \"run_type\": \"reinforcement_learning\",  # other run types: \"sampling\", \"validation\",\n",
    "                                           #                  \"transfer_learning\",\n",
    "                                           #                  \"scoring\" and \"create_model\",\n",
    "    \"model_type\": \"default\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to analyse the results of any run afterwards, it is paramount to *log* intermediare results, e.g. to judge whether the agent has been focussed enough (or too much), whether the learning is going well and so on. On top of this, we also need to make sure the final result (compounds) is deposited appropriately. Thus, we will log these data to two folders and inspect it afterwards with `tensorboard` which is already installed in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add block to specify whether to run locally or not and\n",
    "# where to store the results and logging\n",
    "configuration[\"logging\"] = {\n",
    "    \"sender\": \"http://127.0.0.1\",          # only relevant if \"recipient\" is set to \"remote\"\n",
    "    \"recipient\": \"local\",                  # either to local logging or use a remote REST-interface\n",
    "    \"logging_frequency\": 10,               # log every x-th steps\n",
    "    \"logging_path\": os.path.join(output_dir, \"progress.log\"), # load this folder in tensorboard\n",
    "    \"result_folder\": os.path.join(output_dir, \"results\"),         # will hold the compounds (SMILES) and summaries\n",
    "    \"job_name\": \"Reinforcement learning demo\",                # set an arbitrary job name for identification\n",
    "    \"job_id\": \"demo\"                       # only relevant if \"recipient\" is set to \"remote\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aforementioned blocks are required for any kind of run, but there remains a lot to be specified in terms of reinforcement learning-specific parameters. All of these are on a child-level of `parameters`. Before we specify the scoring function components, let us address all other blocks that are possible.\n",
    "\n",
    "* `diversity_filter`: If the agent becomes very focussed, it tends to produce the similar molecules over and over (because they return high scores). To enrich different scaffolds, we can activate the diversity filter, which will \"bin\" the molecules into groups (scaffolds). Once a given bin is full, all other molecules with the same scaffold will be penalized score-wise, effectively \"pushing\" the agent out of a local minimum in the score landscape thus enriching diversity.\n",
    "* `inception`: Sometimes agents \"linger around\" for a while before they (by chance) happen to pick up a trace and generate interesting compounds. To speed up this very early exploration, we can *incept* a couple of promising molecules as list of `SMILES`.\n",
    "* `reinforcement_learning`: This block holds all the parameters which are specific for the reinforcement running mode (see detailed description in the code). One important question is, which prior and initial agent to use: these are just models that have been trained on a large compound library to ensure they have learned \"basic chemical rules\". While the prior does not change over the course of the training (its feedback will be used to keep the agent in the realm of good chemistry), the agent is updated each *epoch* (step). In this case we have used *augmented* `SMILES` representation of `Chembl` data for both the prior and to initialize the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the \"parameters\" block\n",
    "configuration[\"parameters\"] = {}\n",
    "\n",
    "# add a \"diversity_filter\"\n",
    "configuration[\"parameters\"][\"diversity_filter\"] =  {\n",
    "    \"name\": \"IdenticalMurckoScaffold\",     # other options are: \"IdenticalTopologicalScaffold\", \n",
    "                                           #                    \"NoFilter\" and \"ScaffoldSimilarity\"\n",
    "                                           # -> use \"NoFilter\" to disable this feature\n",
    "    \"nbmax\": 25,                           # the bin size; penalization will start once this is exceeded\n",
    "    \"minscore\": 0.4,                       # the minimum total score to be considered for binning\n",
    "    \"minsimilarity\": 0.4                   # the minimum similarity to be placed into the same bin\n",
    "}\n",
    "\n",
    "# prepare the inception (we do not use it in this example, so \"smiles\" is an empty list)\n",
    "configuration[\"parameters\"][\"inception\"] = {\n",
    "    \"smiles\": [],                          # fill in a list of SMILES here that can be used (or leave empty)\n",
    "    \"memory_size\": 100,                    # sets how many molecules are to be remembered\n",
    "    \"sample_size\": 10                      # how many are to be sampled each epoch from the memory\n",
    "}\n",
    "\n",
    "# set all \"reinforcement learning\"-specific run parameters\n",
    "configuration[\"parameters\"][\"reinforcement_learning\"] = {\n",
    "    \"prior\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"agent\": os.path.join(ipynb_path, \"models/random.prior.new\"), # path to the pre-trained model\n",
    "    \"n_steps\": 125,                        # the number of epochs (steps) to be performed; often 1000\n",
    "    \"sigma\": 128,                          # used to calculate the \"augmented likelihood\", see publication\n",
    "    \"learning_rate\": 0.0001,               # sets how strongly the agent is influenced by each epoch\n",
    "    \"batch_size\": 128,                     # specifies how many molecules are generated per epoch\n",
    "    \"margin_threshold\": 50                 # specify the (positive) margin between agent and prior\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the scoring function\n",
    "Now all that remains to be done is the most tricky step: define a scoring function that allows the agent to identify promising suggestions and discard molecules that are of no interest to the project. It is not necessarily better to build a very complex scoring function (on the contrary it can make it hard for the agent to find appropriate solutions). Always bear in mind that there is a post-processing step at the end, in which you will be able to discard molecules either by eye-inspection or by applying further (probably more expensive) methods you have not used in the reinforcement learning loop. The following example will include fair share of the available scoring function components (added one-by-one), but this is for illustrative purposes only.\n",
    "\n",
    "##### Score transformation\n",
    "Before we start, there is one more topic requiring some explanation: *score transformations*. Remember that every component returns a value between '0' and '1' (higher values meaning \"better\") and all scores together are combined into a *total score* for a given compound (also between '0' and '1'). This is key, as the agent will try to generate molecules with ever increasing scores over the course of training, i.e. the numerical value \"guides\" the agent. However, some components might not naturally return values between '0' or '1' or they might represent the opposite, i.e. '0' being \"good\" rather than \"bad\". This is component-specific and to make it as flexible as possible, we include the specification of a score transformation for each component. We support multiple different functions (`sigmoid`, `reverse_sigmoid` and so on) which have different parameters to allow tweaking them to the desired result. For more details and to see how different parameter values affect the result, we refer to the dedicated notebook which is also part of this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the scoring function definition and add at the end\n",
    "scoring_function = {\n",
    "    \"name\": \"custom_product\",              # this is our default one (alternative: \"custom_sum\")\n",
    "    \"parallel\": False,                     # sets whether components are to be executed\n",
    "                                           # in parallel; note, that python uses \"False\" / \"True\"\n",
    "                                           # but the JSON \"false\" / \"true\"\n",
    "\n",
    "    # the \"parameters\" list holds the individual components\n",
    "    \"parameters\": [\n",
    "\n",
    "    # add component: an activity model\n",
    "    {\n",
    "        \"component_type\": \"predictive_property\", # this is a scikit-learn model, returning\n",
    "                                                 # activity values\n",
    "        \"name\": \"Regression model\",              # arbitrary name for the component\n",
    "        \"weight\": 2,                             # the weight (\"importance\") of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"model_path\": os.path.join(ipynb_path, \"models/Aurora_model.pkl\"),   # absolute model path\n",
    "            \"scikit\": \"regression\",                # model can be \"regression\" or \"classification\"\n",
    "            \"descriptor_type\": \"ecfp_counts\",      # sets the input descriptor for this model\n",
    "            \"size\": 2048,                          # parameter of descriptor type\n",
    "            \"radius\": 3,                           # parameter of descriptor type\n",
    "            \"use_counts\": True,                    # parameter of descriptor type\n",
    "            \"use_features\": True,                  # parameter of descriptor type\n",
    "            \"transformation\": {\n",
    "                \"transformation_type\": \"sigmoid\",  # see description above\n",
    "                \"high\": 9,                         # parameter for sigmoid transformation\n",
    "                \"low\": 4,                          # parameter for sigmoid transformation\n",
    "                \"k\": 0.25                          # parameter for sigmoid transformation\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: enforce the match to a given substructure\n",
    "    {\n",
    "        \"component_type\": \"matching_substructure\", \n",
    "        \"name\": \"Matching substructure\",       # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [\"c1ccccc1CC\"]           # a match with this substructure is required\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: enforce to NOT match a given substructure\n",
    "    {\n",
    "        \"component_type\": \"custom_alerts\",\n",
    "        \"name\": \"Custom alerts\",               # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "        \"specific_parameters\": {\n",
    "            \"smiles\": [                            # specify the substructures (as list) to penalize\n",
    "                \"[*;r8]\",\n",
    "                \"[*;r9]\",\n",
    "                \"[*;r10]\",\n",
    "                \"[*;r11]\",\n",
    "                \"[*;r12]\",\n",
    "                \"[*;r13]\",\n",
    "                \"[*;r14]\",\n",
    "                \"[*;r15]\",\n",
    "                \"[*;r16]\",\n",
    "                \"[*;r17]\",\n",
    "                \"[#8][#8]\",\n",
    "                \"[#6;+]\",\n",
    "                \"[#16][#16]\",\n",
    "                \"[#7;!n][S;!$(S(=O)=O)]\",\n",
    "                \"[#7;!n][#7;!n]\",\n",
    "                \"C#C\",\n",
    "                \"C(=[O,S])[O,S]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#7;!n]\",\n",
    "                \"[#7;!n][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#16;!s]\",\n",
    "                \"[#8;!o][C;!$(C(=[O,N])[N,O])][#8;!o]\",\n",
    "                \"[#16;!s][C;!$(C(=[O,N])[N,O])][#16;!s]\"\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    # add component: calculate the QED drug-likeness score (using RDkit)\n",
    "    {\n",
    "        \"component_type\": \"qed_score\",\n",
    "        \"name\": \"QED Score\",                   # arbitrary name for the component\n",
    "        \"weight\": 1,                           # the weight of the component (default: 1)\n",
    "    }]\n",
    "}\n",
    "configuration[\"parameters\"][\"scoring_function\"] = scoring_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have successfully filled the dictionary and will write it out as a `JSON` file in the output directory. Please have a look at the file before proceeding in order to see how the paths have been inserted where required and the `dict` -> `JSON` translations (e.g. `True` to `true`) have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the configuration file to the disc\n",
    "configuration_JSON_path = os.path.join(output_dir, \"RL_config.json\")\n",
    "with open(configuration_JSON_path, 'w') as f:\n",
    "    json.dump(configuration, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run `REINVENT`\n",
    "Now it is time to execute `REINVENT` locally. Note, that depending on the number of epochs (steps) and the execution time of the scoring function components, this might take a while. As we have only specified a low number of epochs (125) and all components should be fairly quick, this should not take too long in our case though.\n",
    "\n",
    "The command-line execution looks like this:\n",
    "```\n",
    "# activate envionment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# execute REINVENT\n",
    "python <your_path>/input.py <config>.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.exists(\"/home/springnuance/reinvent-hitl/Reinvent-Community-Binh/notebooks/models/Aurora_model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/standard/predictive_property_component.py\", line 31, in _load_model\n",
      "    activity_model = self._load_container(parameters)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/standard/predictive_property_component.py\", line 40, in _load_container\n",
      "    scikit_model = pickle.load(f)\n",
      "ModuleNotFoundError: No module named 'sklearn.ensemble.forest'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"../../Reinvent/input.py\", line 40, in <module>\n",
      "    manager.run()\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/running_modes/manager.py\", line 17, in run\n",
      "    runner = RunningMode(self.run_configuration)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/running_modes/constructors/running_mode.py\", line 18, in __new__\n",
      "    return ReinforcementLearningModeConstructor(configuration)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/running_modes/constructors/reinforcement_learning_mode_constructor.py\", line 44, in __new__\n",
      "    scoring_function = ScoringFunctionFactory(config.scoring_function)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/scoring_function_factory.py\", line 16, in __new__\n",
      "    return cls.create_scoring_function_instance(sf_parameters, scoring_function_registry)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/scoring_function_factory.py\", line 25, in create_scoring_function_instance\n",
      "    return scoring_function(parameters, sf_parameters.parallel)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/function/custom_product.py\", line 14, in __init__\n",
      "    super().__init__(parameters, parallel)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/function/base_scoring_function.py\", line 62, in __init__\n",
      "    self.scoring_components = factory.create_score_components()\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/score_component_factory.py\", line 95, in create_score_components\n",
      "    components = [create_component(component) for component in self._parameters]\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/score_component_factory.py\", line 95, in <listcomp>\n",
      "    components = [create_component(component) for component in self._parameters]\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/score_component_factory.py\", line 89, in create_component\n",
      "    component_instance = component(component_params)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/standard/predictive_property_component.py\", line 16, in __init__\n",
      "    self.activity_model = self._load_model(parameters)\n",
      "  File \"/home/springnuance/reinvent-hitl/Reinvent/reinvent_scoring/scoring/score_components/standard/predictive_property_component.py\", line 34, in _load_model\n",
      "    raise Exception(f\"The loaded file `{model_path}` isn't a valid scikit-learn model\")\n",
      "Exception: The loaded file `/home/springnuance/reinvent-hitl/Reinvent-Community-Binh/notebooks/models/Aurora_model.pkl` isn't a valid scikit-learn model\n"
     ]
    }
   ],
   "source": [
    "# %%capture captured_err_stream --no-stderr\n",
    "\n",
    "# execute REINVENT from the command-line\n",
    "!{reinvent_env}/bin/python {reinvent_dir}/input.py {configuration_JSON_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output to a file, just to have it for documentation\n",
    "with open(os.path.join(output_dir, \"run.err\"), 'w') as file:\n",
    "    file.write(captured_err_stream.stdout)\n",
    "\n",
    "# prepare the output to be parsed\n",
    "list_epochs = re.findall(r'INFO.*?local', captured_err_stream.stdout, re.DOTALL)\n",
    "data = [epoch for idx, epoch in enumerate(list_epochs) if idx in [1, 75, 124]]\n",
    "data = [\"\\n\".join(element.splitlines()[:-1]) for element in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated a total of 125 epochs, let us quickly investigate how the agent fared. Below you see the print-out of the first, one from the middle and the last epoch, respectively. Note, that the fraction of valid `SMILES` is high right from the start (because we use a pre-trained prior). You can see the partial scores for each component for the first couple of compounds, but the most important information is the average score. You can clearly see how it increases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in data:\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse the results\n",
    "In order to analyze the run in a more intuitive way, we can use `tensorboard`:\n",
    "\n",
    "```\n",
    "# go to the root folder of the output\n",
    "cd <your_path>/REINVENT_RL_demo\n",
    "\n",
    "# make sure, you have activated the proper environment\n",
    "conda activate reinvent.v3.2\n",
    "\n",
    "# start tensorboard\n",
    "tensorboard --logdir progress.log\n",
    "```\n",
    "\n",
    "Then copy the link provided to a browser window, e.g. \"http://workstation.url.com:6006/\". The following figures are exmaple plots - remember, that there is always some randomness involved. In `tensorboard` you can monitor the individual scoring function components. What you see is, that all of those depicted went up (and `Fraction_valid_SMILES` was high troughout). Not shown is the predictive model, which did not perform all that well, so you might want to consider a higher weight next time.\n",
    "\n",
    "![](img/individual_components.png)\n",
    "\n",
    "Also the total score increased over time.\n",
    "\n",
    "![](img/total_score.png)\n",
    "\n",
    "It might also be informative to look at the results from the prior (dark blue), the agent (blue) and the augmented likelihood (purple) over time.\n",
    "\n",
    "![](img/likelihood.png)\n",
    "\n",
    "And last but not least, there is a \"Images\" tab available that lets you browse through the compounds generated in an easy way. In the molecules, the substructure matches that were defined to be required are highlighted in red (if present). Also, the total scores are given per molecule.\n",
    "\n",
    "![](img/molecules.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results folder will hold four different files: the agent (pickled), the input JSON (just for reference purposes), the memory (highest scoring compounds in `CSV` format) and the scaffold memory (in `CSV` format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open './REINVENT_complete_use_case_DRD2_demo/results/memory.csv' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head -n 15 {output_dir}/results/memory.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
